[
  {
    "objectID": "Manifestations/B4-optimization.html",
    "href": "Manifestations/B4-optimization.html",
    "title": "50  Optimization and constraint",
    "section": "",
    "text": "50.1 Gradient descent\nThe general approach we will take to the solving phase of optimization problems will be iterative as in Chapter 48. Start with an initial guess for an argmin and then construct a new function that can improve the guess. Applying this improvement function iteratively leads to better and better estimates of the true argmin.\nFor illustration purposes, we will use optimization problems where the objective function has two inputs. Such objective functions can be graphed on paper or a display screen and it is possible to see the action of the iterative improvement process directly. For optimization in problem with many inputs, the improvement can be monitored from the objective function output at each step.\nFigure 50.2 shows a mechanical system consisting of a mass suspended from a fixed mounting by three nonlinear springs.\nFigure 50.2: A mass suspended from three springs.\nThe mass is shown by a black circles. Springs are the zig-zag shapes. The bold bar is the fixed mounting, as if from a beam on the ceiling of a room. The system has an equilibrium configuration where the springs are stressed sufficiently to balance each other left to right and to balance the gravitational force downward on the mass.\nWe want to calculate the equilibrium position. The basic strategy is to model the potential energy of the system, which consists of:\nSince the configuration of the system is set by the coordinate \\((x_1, y_1)\\), the potential energy is a function \\(E(x_1, y_1)\\). For brevity, we will leave out the physics of the formulation of the potential-energy function; shown in Figure 50.3.\nFigure 50.3: The potential energy of the spring-mass system in Figure 50.2.\nThe potential energy function \\(E(x,y)\\) has a bowl-like shape. The bottom of the bowl—the argmin—is near \\((x=1.7, y=-1.3)\\). In terms of Figure 50.2, the equilibrium position is a bit upward and to the right of the position shown in the figure.\nWith a graph of the objective function like Figure 50.3, the solution phase is simple; a graph will do the job. But for more complicated objective functions, with more than 2 inputs, drawing a complete graph is not feasible. For example, in the spring-mass system shown in Figure 50.4, the potential energy function has six inputs: \\(x_1, y_1, x_2, y_2, x_3, y_3\\). In genuine applications of optimization, there are often many more inputs.\nFigure 50.4: A more complicated spring-mass system.\nIn a multi-input optimization problem, we don’t have a picture of the whole objective function. Instead, we are able merely to evaluate the objective function for a single given input at a time. Typically, we have a computer function that implements the objective function and we are free to evaluate it at whatever inputs we care to choose. It is as if, instead of having the whole graph available, the graph is covered with an opaque sheet with a loophole, as in Figure 50.5.\nFigure 50.5: A more realistic view of what we can know about a function.\nWe can see the function only in a small region of the domain and need to use the information provided there to determine which way to move to find the argmin.\nThe situation is analogous to standing on the side of a smooth hill in a dense fog and finding your way to the bottom. The way forward is to figure out which direction is uphill, which you can do directly from your sense of balance by orienting your stance in different ways. Then, if your goal is the top of the hill (argmax) start walking uphill. If you seek a low point (argmin), walk downhill.\nThe mathematical equivalent to sensing which direction is uphill is to calculate the gradient of the objective function. In Chapter 25 we used partial differentiation with respect to each of the input quantities to assemble the gradient vector, denoted \\(\\nabla f() = \\left({\\large \\strut} \\partial_x f(), \\ \\partial_y f()\\right)\\). In terms of Figure 50.5, where we are standing at about \\((x_i=0.8, y_i=-2.3)\\), we would evaluate the each of the partial derivatives in the gradient vector at \\((0.8, -2.3)\\).\nThe gradient points in the steepest direction uphill so, once you know the direction, take a step in that direction to head toward the argmax, or a step in the opposite direction if you seek the argmin. The process of following the gradient toward the top of the hill is called gradient ascent. Correspondingly, following the gradient downhill is gradient descent.\nFigure 50.6: The gradient provides information about the shape of the local function in a convenient form to guide the step to the next locale in your journey toward the argmin or argmax.\nFor humans, the length of a step is fixed by the length of our legs and the size of our feet. The mathematical step has no fixed size. Often, the modeler gains some appreciation for what constitutes a small step from the modeling process. Referring to Figure 50.4 for example you can see that a small increment in \\(x\\) is, say, \\(0.1\\), and similarly for \\(y\\). There is little point in taking an infinitesimal step—that gets you almost nowhere! Instead, be bold and take a finite step. Then, at your new location, calculate the gradient vector again. If it is practically the same as at your earlier position, you can wager on taking a larger step next time. If the new gradient direction is substantially different, you would be well advised to take smaller steps.\nFortunately, a variety of effective ideas for determining step size have been implemented in software and packaged up as algorithms. The modeler need only provide the objective function in a suitable forma starting guess for the inputs.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Optimization and constraint</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-optimization.html#gradient-descent",
    "href": "Manifestations/B4-optimization.html#gradient-descent",
    "title": "50  Optimization and constraint",
    "section": "",
    "text": "Tip\n\n\n\nSpring-mass systems: an example context\nAs our example context for discussing the optimization process, we will consider how to use optimization to calculate the configuration of simple mechanical systems consisting of interconnected springs and masses. Such configuration problems are especially important today in understanding the structure and function of proteins, but we will stick to the simpler context of springs and masses.\n\n\n\n\n\n\n\nthe gravitational potential energy of the mass.\nthe energy stored in stretched or compressed springs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it! 50.2\n\n\n\n\n\n\n\n\n\nTry it! 50.2 Using argM()\n\n\n\nThe R/mosaic function argM() is set up to find argmins and argmaxes using the familiar tilde-formula/domain style of arguments used throughout this book. For instance, the potential energy of the spring-mass system shown in Figure 50.2 is available as mosaicCalc::PE_fun1()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nApplication area 50.1 —Algorithms can implement formulas, but the reverse is not necessarily true.\n\n\n\n\n\n\n\nApplication area 50.1 Formulas and algorithms\n\n\n\nTextbook formulas in physics, chemistry, engineering, and economics often have a root in an optimization problem. Since a formula is the desired result, symbolic differentiation is used in the solution phase. This allows parameters to be represented with symbols rather than as specific numbers. Usually the objective functions involved are simple. And to make the objective functions simple enough for symbolic work, it is common to make approximations, for example by replacing functions like \\(\\sin(x)\\) with \\(x\\) and \\((1+p)^n\\) with \\(1+np\\). But simplifying the objective function should really be considered part of the solution phase rather than the modeling phase.\nNumerical techniques are the most widely used in practice. Optimization is an important operation in both science and management and much human ingenuity has gone into the development of effective algorithms. The modeler rarely if ever needs to reach beyond the software provided in technical computing environments such as R, MATLAB, Mathematica, or the many packages available for Python.\nIn data science and machine learning, often advanced solution-phase software is provided as web services and APIs (application programming interfaces). An example is the Google technology product TensorFlow used to find optimal parameters for functions in the machine technique called “deep learning.”\n\n\n\n\nApplication area 50.2  \n\n\n\n\n\n\n\nApplication area 50.2 Minimum potential energy\n\n\n\nThe potential energy function of the spring-mass system in Figure 50.4 is available as the R/mosaic function PE_fun2(). This potential energy function has six inputs: the \\(x\\) and \\(y\\) coordinates of each of the three masses. The code below shows how to use the R/mosaic argM() function to locate an argmin of the potential energy.\n\nargM(PE_fun2(\n  x1, y1, x2, y2, x3, y3) ~ x1 & y1 & x2 & y2 & x3 & y3, \n  bounds(x1 = 0:3, y1=-3:0, x2=0:3, y2=-3:0, x3=0:3, y3=-3:0))\n## # A tibble: 1 × 7\n##      x1    y1    x2    y2    x3    y3 .output.\n##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 0.800 -2.15  1.60 -3.05  2.40 -2.70    -8.86\n\nThe argM() function reports the final result, the end of the path followed in descending the gradient field. Figure 50.7 gives a movie of the path as it is being followed.\n\n\n\n\n\n\n\n\nFigure 50.7: The path to equilibrium for the 3-body spring-mass system shown in Figure 50.4. The top two frames show a 2-dimensional slice through the 6-dimensional gradient field. The bottom frame translates the current point on the path into a picture of the spring-mass locations.\n\n\n\n\n\nAt the start of the movie, the masses are (absurdly) misplaced and far from their equilibrium position. As system configuration moves downhill toward the argmin of the potential energy function, the masses sort themselves out.\nThe two gradient-field frames show a different two-dimensional slices of the potential energy function which has six inputs. Watch the gradient-fields carefully to see that the field itself is changing as time goes by. All six inputs are changing. At each point in time, we are plotting the gradient field as a function of the two inputs shown on the axes. These stay the same through the whole movie, but the other four inputs are changing as the system moves along the gradient descent path. The last frame shows the gradient field at the final position in six-dimensional space. You can see that the early parts of the path are not aligned with the end-of-path gradient fields, but they were aligned at the earlier time when each point in the path was passed.\nThe familiar tilde-expression format used by argM() and the other R/mosaic functions is suitably compact for function of one or two arguments, but for functions with many inputs it becomes ungainly. For objective functions with many inputs, a different programming style is more appropriate that packages up the multiple inputs into a single, vector input. Since this is not a programming book, we won’t go into the vector-input programming style, but be aware that in professional-level work, learning new tools for programming becomes essential.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Optimization and constraint</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-optimization.html#objectives-and-constraints",
    "href": "Manifestations/B4-optimization.html#objectives-and-constraints",
    "title": "50  Optimization and constraint",
    "section": "50.2 Objectives and Constraints",
    "text": "50.2 Objectives and Constraints\nMany real-world decision-making settings do not fit neatly into the framework of constructing an objective function and then finding the argmin (or argmax). A common situation is having multiple objectives. These objectives often compete and the output of the respective objective functions may not necessarily be directly comparable. For instance, in health care one objective is to save lives, while another is to minimize costs. But lives and money are not directly comparable.\nOften, the original problem statement does not include all of the objectives and the modeler needs to be perceptive to discern important objectives left out of the initial description of the problem. When such missing objectives become apparent, it is necessary to visit the modeling phase of the problem to insert the new objectives. By adopting the right approach to modeling, such situations can be readily handled and, even better, the modeling phase can bring new insight into the real-world problem.\nTo illustrate, let’s returning to the mathematically simplified problem of constructing an optimal cardboard box. Before, we stipulated that the raw cardboard stock has dimension 20 inches by 30 inches. Now we will generalize and work with a piece of cardboard that has edges of length \\(y\\) from which, as before, we will cut out square corners of length \\(x\\) on a side. (See ?fig-box-shape). Our objective is to make a box with the largest possible volume. (This will be an argmax problem.)\n\n\n\n\n\n\n\n\nFigure 50.8: The cardboard cut lines and the eventual shape of the folded box.\n\n\n\n\n\n\n\n\n\n\n\nFigure 50.9: The cardboard cut lines and the eventual shape of the folded box.\n\n\n\n\n\nThe area of the bottom of the box is \\((y - 2x)^2\\) and the box height is \\(x\\). The objective function is the volume of the box, area times height: \\[V(x, y) \\equiv x (y - 2x)^2\\ .\\] There are two inputs, \\(x\\) and \\(y\\), so a simple plot should suffice to find the argmax.\n\n\n\n\n\n\n\n\nFigure 50.10: The volume of the box (in cubic inches) constructed by cutting corners of size \\(x\\)-by\\(x\\) out of a \\(y\\)-by-\\(y\\) piece of cardboard.\n\n\n\n\n\nScanning Figure 50.10 reveals a couple of things that you might not have anticipated. First, the argmax is in the extreme lower-right corner of the graphics frame, not in the center as in previous examples. Second, the argmax in this corner, \\((y=0, x=10)\\) is logically inconsistent with the idea of a cardboard box.\nThe inconsistency stems from an inadmissible value for \\(x\\). For \\(2x &gt; y\\), the bottom of the box would have negative edge length. But because the objective function \\(V(x,y)\\) squares this negative quantity—in the \\((y - 2x)^2\\) term—the output of the objective function does not signal that anything is wrong. The source of the problem is not the objective function formula itself, but neglecting to consider carefully what is the proper practical domain for the function.\nTo make the calculation realistic, we should search for the argmax only in that region of the graphics frame where \\(y &gt; 2x\\). That restriction on the search domain is called a constraint. In this case, the constraint takes the form of an inequality \\(y &gt; 2x\\) so we call it an inequality constraint. (Later, we will work with equality constraints.)\n\n\n\n\n\n\n\n\nFigure 50.11: The inequality constraint that \\(y &gt; 2x\\) renders much of the graphics frame inadmissible as a possible solution. The inadmissible region is shaded in blue. The argmax must be sought in the unshaded region of the frame.\n\n\n\n\n\nWith the \\((x,y)\\)-domain restricted to the values that are physically realistic, we can see that the argmax is still on the edge of the frame, at \\(y=30\\) and \\(x\\approx 5\\), where the volume of the box will be about 1800 in3. This result should cause you pause, since there was nothing in the problem statement that limited \\(y\\) to be 30” or less. If we replotted with a larger domain for \\(y\\), we should see still larger boxes, without any limit.\nThe interpretation of the problem as originally posed is: With enough cardboard we can make a box of any size! Since the goal was to recommend the “best” size, this conclusion is not so useful. The weak conclusion stems from a fault in the problem statement. The statement omitted an important second objective function: use as little cardboard as possible.\nIf using as little cardboard as possible were our sole objective, the optimization problem has an easy-to-find solution: we would make a zero-volume box out of zero-area of cardboard. What we want, somehow, is to make as big a box as possible out of as little cardboard as possible: we have two objectives! In this case, the objectives are in conflict: making a bigger box (good) uses more cardboard (bad).\nCommon sense tells us to balance the two objectives, but how to represent this mathematically? Ideally—note that “ideally” is sometimes far from “realistically” or “productively”—we would know how much box-volume is worth to us and how much cardboard costs, and we could construct an objective function that incorporates both value and cost. For instance, if each cubic inch of volume is worth 1 cent, and each square inch of cardboard costs 3 cents, then the objective function will be the following (with output in cents):\n\\[\\text{Profit}(x,y) \\equiv 1\\, x (y-2x)^2 - 3 y^2\\]\n\n\n\n\n\n\n\n\nFigure 50.12: The “profit” (value minus cost) of the cardboad box (cents).\n\n\n\n\n\nEven with including the cardboard cost in the objective function, we will still want to make \\(y\\) as large as possible. Not much guidance there!\nBut let’s imagine a new factor coming into play. At the meeting where the box-design decisions are being made and where you are presenting your analysis in Figure 50.12, the graphic designer speaks up. “The trending shape for this year is cubic. We want the box, whatever it is size, to be a cube.”\nLuckily, you the modeler can quickly incorporate this into your analysis. To be a cube, the height \\(x\\) of the box has to be the same as the width and depth \\(y - 2x\\). So you can incorporate the designer’s wish into the model of the decision factors by adding a new constraint:\n\\[x = y - 2x \\ \\ \\ \\implies y-3x=0\\ \\ \\ \\ \\text{constraint: box must be cubic}\\] This is called an equality constraint. Figure 50.13 shows the equality constraint in green: to be a cube, \\(x\\) and \\(y\\) must be somewhere along the green line.\n\n\n\n\n\n\n\n\nFigure 50.13: The profit function shown in more detail along with the equality constraint (green) for the box to be cube-shaped.\n\n\n\n\n\nFollow the green path uphill. As \\(x\\) gets larger along the constraint, the output of the objective function grows, reaching a level of 1350 cents when \\((x=15, y=45)\\) at the right border of the graphics frame.\nIt is worth pointing out, for later use, that the be-a-cube constraint is almost parallel to the objective function contours.\n\nApplication area 50.3 —Using a budget optimally.\n\n\n\n\n\n\n\nApplication area 50.3 Budgets\n\n\n\nMany organizations use a budget mechanism to manage their affairs. The organization defines divisions or projects, and each of these is given a dollar budget to stay within. The individual division or project manager can arrange things more or less as she thinks best, so long as she stays within the budget. This is a kind of constraint: a budget constraint.\nSuppose you have been tasked to set up a new factory and given a budget of $5,500,000 to do so. You were given this task because you have a particular expertise in how best to set up the factory, but your design will of course depend on the relative prices of the different inputs to the production process.\nFor simplicity, let’s imagine that there are two main inputs: labor \\(L\\) and capital/equipment \\(K\\). It would be silly to spend all the budget on labor and none on capital; the workers would have no tools to work with. Similarly, capital without labor has no productive value. The best design for the factory will be a mix of labor and capital.\nSince the purpose of the factory is to make things for sale, a good objective function will be the sales value of the output produced by the factory. Economists have a favored form for production functions of this sort, a power-law called the Cobb-Douglas function. The essential insight behind the Cobb-Douglas function is that doubling both capital and labor (as if you built a second factory alongside the first) should double production. The Cobb-Douglas form for production as a function of capital and labor is \\[Q(L, K) = p b L^a K^{1-a}\\ .\\] You will use your expertise to set the values of the \\(a\\) and \\(b\\) parameters. The price \\(p\\) of each unit of output will be set by the market: Let’s assume for planning purposes that it is \\(p - \\$450\\) per unit. Suppose you have determined that \\(a=0.3\\) and \\(b=40\\) are appropriate. This production function is shown in Figure 50.14.\n\n\n\n\n\n\n\n\nFigure 50.14: A Cobb-Douglas production function for factory output with \\(p=100\\), \\(b=40\\) and \\(a=0.3\\). (Output units in millions of dollars).\n\n\n\n\n\nAs you can see from Figure 50.14, the more labor and the more capital you use, the higher the production. Notice that the production function itself does not have an argmax interior to the domain being plotted. It is one of those “more is better” situations.\nSuppose that labor costs $6000 per person-month. Capital, in units of production stations, costs $13,000 per unit. Your budget constraint reflects the total cost of capital and labor: \\(6000 \\cdot L + 15000 \\cdot K \\leq 5500000\\). This constraint is graphed in Figure 50.15.\n\n\n\n\n\n\n\n\nFigure 50.15: The production function for factory output with the budget constraint shown in green.\n\n\n\n\n\nAny mixture of labor and capital that falls outside the green zone stays within your budget. What’s the best mixture? The one that gives the largest production. You can read this off the graph, \\(L\\approx 650\\) person-months and \\(K\\approx 125\\) workstations which gives slightly more than $7 million dollars in production.\nThe argmax is right on the frontier of the constraint region. Put into more operational terms: You will want to spend your entire budget to maximize production. This is hardly a surprise to anyone who has to work within a budget. Knowing that you’re going to use the whole budget, you might as well have found the argmax by walking along the constraint frontier from left to right. As you start near \\(K=250\\) and \\(L=380\\), the path you walk goes uphill in terms of the production function. The path continues uphill until you reach the argmax. Near the argmax, the path is level. After the path crosses the argmax, it is leading downhill. At the argmax, the production function contours are parallel to the constraint boundary.\nYou might like to think of this in terms of bicycling along a path in hilly terrain. (The hill is shown in Figure 50.15 as the contours, the path is the boundary of the green area, running diagonally from top left to bottom right in the graph.) When you reach the local high point on the path, you may not be at the top of the hill. But you will be on a flat spot on the path, meaning that the path is parallel to the contour of the hill at that point.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Optimization and constraint</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-optimization.html#constraint-cost",
    "href": "Manifestations/B4-optimization.html#constraint-cost",
    "title": "50  Optimization and constraint",
    "section": "50.3 Constraint cost",
    "text": "50.3 Constraint cost\nOptimization techniques have an important role to play as aids to human decision making. Let’s see how the mathematical representation of a constraint as a function can facilitate the human decision-making process.\nIn the previous section, the box designer’s request that the box be cubic was translated into an equality constraint, \\(y-3x=0\\), shown as the green line in Figure 50.13. The skilled modeler can bring additional power to the analysis by translating that constraint, \\(y-3x=0\\) into a function, for example \\[\\text{Equation:}\\ \\  \\ y - 3x = 0\\ \\ \\longrightarrow\\ \\ \\ \\text{Function:}\\ \\ \\text{cube-box}(x, y) = y / 3x\\ .\\] Any \\((x^+, y^+)\\) that produces \\(\\text{cube-box}(x^+, y^+) = 1\\) is a pair that satisfies the constraint. In other words, the equality constraint amounts the 1-contour of the cube_box() function.\nTranslating the constraint into a function provides the opportunity to reframe the situation from the mandate, “the box must be a cube,” into a question, “How cubic-like is the box?” If the value of \\(\\text{cube-box}(x,y) &gt; 1\\), the box is flatter than a cube; something in the direction of a pizza box. If \\(\\text{cube-box}(x,y) &lt; 1\\) the box is taller than a cube, as if flowers were being shipped in it.}\nThe constraint-to-function translated situation is shown in Figure 50.16:\n\n\n\n\n\n\n\n\nFigure 50.16: Zooming in on the objective function Profit() and showing the function version of the constraint, cube_box() using \\(\\color{magenta}{\\text{magenta}}\\) contours, with the heavy green line being the contour at cube_box(x,y)=1.\n\n\n\n\n\nEarlier, we saw that if restricted to inputs on the contour \\(\\text{cube-box}(x,y) = 1\\), the optimal output value of Profit() is about $13.50. Now we have a broader picture. For instance, suppose we allow a “little” deviation in box shape from a cube, say, cube_box(x,y) = 1.05. If we allowed this, the value of the Profit() function could be increased from $13.50 to about $22.50 .\nWhether the $9 increase in value justifies the deviation from a cube by 5% is a matter of judgement. We don’t have an immediate way to translate the output of cube_box() into the same units as the output of profit(). The two different units are said to be incommensurate, meaning that they cannot be directly compared. Nonetheless, we now have a basis for a conversation. It might go like this:\nModeler to Designer: I realize that from your perspective, a cube is the optimal shape for the box.\nDesigner: Right. Cubes are in fashion this year. Last year it was the Golden Ratio.\nModeler: It might sound surprising, but we find that so long as you are close to the optimal, it does not much matter if you are exactly on it. How close to a perfect cube would be good enough?\nDesigner: What’s really important is that the box be perceived as a cube in our sales material. I think that most customers would think “cube” so long as the edge lengths are within about 15% of one another.\nModeler: That’s very helpful. Let’s see if I can translate that into the cube_box() function.\n[Modeler does some scribbling while mumbling to himself. “\\(y-2x\\) is the base width and depth of the box, and \\(x\\) is the height of the box. So if \\(y-2x = 1.15 x\\) then \\(y = 3.15 x\\). \\(\\text{cube-box}(x, 3.15 x) = 1.05\\).]\nModeler: [to Designer] The 15% deviation corresponds to an output of 1.05 from \\(\\text{cube-box}()\\).\nModeler: [To product manager] Making that change in shape increases profit per box from $13.50 to $22.50.\nProduct manager: Good job! How about a 30% deviation? That let’s us get up to about $33 in profit.\nDesigner: But it would make the box shaped like a brick! Bricks are so 1990s!\nModeler: It sounds like a 15% deviation would be about right.\nMaking the constraint negotiable by representing it with a function, broadens the scope of the discussion and points to new ways of improving the result.\n\nApplication area 50.4 — Finding an optimal mixture of capital and labor.\n\n\n\n\n\n\n\nApplication area 50.4 Factory production\n\n\n\nLet’s return to a previous example about determining optimal levels of labor and capital in a factory. In that example, the objective function was the money value of the product produced. There was also a budget constraint. Translating the budget constraint into a function, which we will call expenditure(K, L), we have \\(\\text{expenditure}(K, L) = 6000 L + 13000 K\\). Our budget amounts to enforcing \\(\\text{expenditure}(K, L) = \\$5,500,000\\).\nA manager presented with a budget knows that she should work within the constraints of that budget. Mathematically, however, it is easy to imagine the budget being changed, either relaxed or tightened. This mathematical possibility provides the means to extract new information that can be helpful in making decisions at a higher level, that is, above the rank of the manager. This can be helpful to higher management—the people who are responsible for seeing the bigger picture.\nFigure 50.17 show the production function plotted along with the expenditure function. The budget constraint corresponds to a single output level of the expenditure function, that is, a single contour of the expenditure function. Other contours correspond to different values for the budget constraints. Such a graph makes it easy to calculate the consequences for relaxing (or tightening) the constraint.\n\n\n\n\n\n\n\n\nFigure 50.17: The production function for factory output (blue, curved lines) and the labor/capital expenditure function (magenta, straight lines). Contour labels are in millions of dollars. Contour levels for expenditure (magenta: 3.1, 3.9, 4.6, etc.) were selected so that the magenta contours are nearly tangent to the blue factory-output contours. This makes it easy to see the K/L position for optimal factory output for each of the indicated expenditure levels.\n\n\n\n\n\nWith the budget fixed at $5.5 million—that is, on the $5.5-million contour of the expenditure function—the maximum production was $7.1 million.\nWhat happens if we pretend that the budget level was different? Doing so is a matter of looking at a different contour of the expenditure function. For example, if the budget had been smaller, say only $5 million, then production also goes down, to $6.5 million. On the other hand, if we had the means to increase the budget to $6 million, production would go up to $7.7 million.\nIn this example we see that an increase in budget of $500K produces an increase in production worth $600K. It might seem logical that it is worth raising the budget to harvest the extra production, but that is not necessarily the case. To see why, recall that we use constraints such as the budget constraint in this problem to represent a real-world situation where there are multiple objectives, not just the particular objective represented by the objective function. There is a budget in the first place because there are other, competing uses for the money. For instance, the money might be better spent in some other product line that is even more profitable. Or perhaps higher management, taking a long-term strategic view, would prefer to spend the funds on research and development.\nThe point of exploring theoretical changes in the budget is to provide information to the higher-level decision makers, the people who set the budget as opposed to the managers who have to work within the budget. The format that most non-technical people would find accessible is simple: a $500K increase in the budget will result in $600K greater production.\nIn mathematical presentations, this same information is often formatted differently, as a ratio called the Lagrange multiplier. The Lagrange multiplier in this example would be 600/500, that is, 1.2. There is no intrinsic advantage of the Lagrange multiplier format over the common sense format, but the Lagrange multiplier is the format used in many textbooks, so it is worthwhile to know the nomenclature. Some economists have a more evocative name for the ratio: the shadow price of the constraint. Thus, the theoretical exploration of relaxing the constraint provides a straightforward way to put a cost on the constraint. This gives a reasonable way to determine the value of something when there is no direct market for it.\nAn important example of a shadow price comes in the setting of life-saving interventions. For example, increasing spending on highway safety can save lives. If $7.5 billion in increased expenditures saves 1000 lives, the shadow price is $7.5 M per life. People who misinterpret the constraint-to-function methodology often think that it is about cravenly putting a money value on life. In reality, the method merely reveals the money value on life implicit in decisions such as budget allocations. Knowing that the shadow price is $7.5 M does not say what the value of life should be. But it provides a mechanism for comparing different uses for the money. For instance, if the shadow price for increased regulation of toxic industrial chemicals is $11.3 M per life, the relative shadow prices provide an indication that budget money might reasonably be shifted from chemical regulation to highway safety. Economists and epidemiologists who undertake such calculations reveal that the mixture of spending on different life-preserving interventions is far from optimal.\n\n\n\n\n\n\n\n\nTip\n\n\n\nGenerations of calculus students have been taught a method of mathematical optimization in the presence of constraints that involves positing a Lagrange multiplier, typically written as \\(\\lambda\\), and carrying out a series of differentiations followed by equation solving to find an argmax, which simultaneously provides a numerical value for \\(\\lambda\\). It is easier to understand the motivation behind this by considering the gradient of the objective function and the gradient of the constraint function. If the goal is, say, to maximize production and simultaneously minimize expenditures, we would want to walk up the production gradient and down the expenditure gradient.\nFigure 50.18 shows two gradient fields, one for the production function in the factory-design example and one for expenditure. (The negative of the expenditure gradient is shown, since the goal is to keep expenditures small.)\n\n\n\n\n\n\n\n\nFigure 50.18: The production and expenditure functions displayed as gradient fields. Expenditure is brown, production is magenta.\n\n\n\n\n\nAt each point in the graphics frame, the two gradient vectors form an angle. For example, near the point labeled (a) the angle is roughly 140 degrees, while near (b) the angle is 180 degrees.\nAny value of \\(K\\) and \\(L\\) where the angle is less than 180 degrees is sub-optimal or dominated by some other choice of \\(K\\) and \\(L\\). For instance, near label (a), you could improve both production and expenditures by moving to the southeast. When the angle is 180 degrees, the objective and constraint functions are in complete opposition to one another; any movement in favor of one comes at the cost in the other.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Optimization and constraint</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-optimization.html#note-other-optimization-algorithms",
    "href": "Manifestations/B4-optimization.html#note-other-optimization-algorithms",
    "title": "50  Optimization and constraint",
    "section": "50.4 Note: Other optimization algorithms",
    "text": "50.4 Note: Other optimization algorithms\nContemporary work often involves problems with tens, hundreds, thousands, or even millions of inputs. Even in such large problems, the mechanics of finding the corresponding gradient vector are straightforward. Searching through a high-dimensional space, however, is not generally a task that can be accomplished using calculus tools. Instead, starting in the 1940s, great creativity has been applied to develop algorithms with names like linear programming, quadratic programming, dynamic programming, etc. many of which are based on ideas from linear algebra such as the qr.solve() algorithm that you will meet in Block 5, or ideas from statistics and statistical physics that incorporate randomness as an essential component. An entire field, operations research, focuses on setting up and solving such problems. Building appropriate algorithms requires deep understanding of several areas of mathematics. But using the methods is mainly a matter of knowing how to set up the problem and communicate the objective function, constraints, etc. to a computer.\nPurely as an example, let’s examine the operation of an early algorithmic optimization method: Nelder-Mead, dating from the mid-1960s. (There are better, faster methods now, but they are harder to understand.)\nNelder-Mead is designed to search for maxima of objective functions with \\(n\\) inputs. The video shows an example with \\(n=2\\) in the domain of a contour plot of the objective function. Of course, you can simply scan the contour plot by eye to find the maxima and minima. The point here is to demonstrate the Nelder-Mead algorithm.\nStart by selecting \\(n+1\\) points on the domain that are not colinear. When \\(n=2\\), the \\(2+1\\) points are the vertices of a triangle. The set of points defines a simplex, which you can think of as a region of the domain that can be fenced off by connecting the vertices.\nEvaluate the objective function at the vertices of the simplex. One of the vertices will have the lowest score for the output of the objective. From that vertex, project a line through the midpoint of the fence segment defined by the other \\(n\\) vertices. In the video, this is drawn using dashes. Then try a handful of points along that line, indicated by the colored dots in the video. One of these will have a higher score for the objective function than the vertex used to define the line. Replace that vertex with the new, higher-scoring point. Now you have another simplex and can repeat the process. The actual algorithm has additional rules to handle special cases, but the gist of the algorithm is simple.\n\n\n\n\n\n\nVideo 50.1: A demonstration of successive steps in the Nelder-Mead optimization algorithm. Based on the objective function’s values at the three vertices in the previous triangle, a new triangle is formed by discarding the worst of the previous vertices and adding a new vertex in the direction of improvement. Source: Miles Chen, Department of Statistics, UCLA",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Optimization and constraint</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html",
    "href": "Linear-combinations/B5-Vectors.html",
    "title": "29  Vectors",
    "section": "",
    "text": "29.1 Length & direction\nA vector is a mathematical idea deeply rooted in everyday physical experience. Geometrically, a vector is simply an object consisting only of length and direction.\nA pencil is a physical metaphor for a vector, but a pencil has other non-vector qualities such as diameter, color, and an eraser. And, being a physical object, a pencil has a position in space.\nA line segment has an orientation but no forward or backward direction. In contrast, a vector has a unique direction: like an arrow, one end is the tip and the other the tail. In the pencil metaphor, the writing end is the tip; the eraser is the tail.\nVectors are always embedded in a vector space. Our physical stand-ins for vectors, the pencils, were photographed on a tabletop: a two-dimensional space. Naturally, pencils are embedded in everyday three-dimensional space. (The tabletop is a kind of two-dimensional subspace of three-dimensional space.)\nVectors embedded in three-dimensional space are central to physics and engineering. Quantities such as force, acceleration, and velocity are not simple numerical quantities but vectors with magnitude (that is, length) and direction. For instance, the statement, “The plane’s velocity is 450 miles per hour to the north-north-west,” is perfectly intelligible to most people, describing magnitude and direction. Note that the plane’s velocity vector does not specify the plane’s location; vectors have only the two qualities of magnitude and direction.\nThe gradients that we studied with partial differentiation (Chapter 25) are vectors. A gradient’s direction points directly uphill; its magnitude tells how steep the hill is.\nVectors often represent a change in position, that is, a step or displacement in the sense of “step to the left” or “step forward.” As we will see, constructing instructions for reaching a target is a standard mathematical task. Such instructions have a form like, “take three and a half steps along the green vector, then turn and take two steps backward along the yellow vector.” An individual vector describes a step of a specific length in a particular direction.\nVectors are a practical tool to keep track of relative motion. For instance, consider the problem of finding an aircraft heading and speed to intercept another plane that is also moving. Figure 29.3, a US Navy training movie from the 1950s, shows how to perform such calculations with paper and pencil.\nNowadays, the computer performs such calculations. On the computer, vectors are represented not by pencils (!) but by columns of numbers. For instance, two numbers will do for a vector embedded in two-dimensional space and three for a vector embedded in three-dimensional space. From these numbers, simple arithmetic can produce the vector magnitude and direction.\nRepresenting a vector as a set of numbers requires the imposition of a framework: a coordinate system. In Figure 29.4, the vector (shown by the green pencil) lies in a two-dimensional coordinate system. The two coordinates assigned to the vector are the difference between the tip and the tail along each coordinate direction. In the figure, there are 20 units horizontally and 16 units vertically, so the vector is \\((20, 16)\\).\nBy convention, when we write a vector as a set of coordinate numbers, we write the numbers in a column. For instance, the vector in Figure 29.4, which we will call \\(\\vec{green}\\), is written numerically as:\n\\[\\vec{green} \\equiv \\left[\\begin{array}{c}20\\\\16\\end{array}\\right]\\] In more advanced linear algebra, the distinction between a column vector (like \\(\\vec{green}\\)) and a row vector (like \\(\\left[20 \\ 16\\right]\\)) is important. For our purposes in this block, we need only column vectors.\nIn physics and engineering, vectors describe positions, velocities, acceleration, forces, momentum, and other functions of time or space. In mathematical notation, a vector-valued function can be written \\(\\vec{v}(t)\\). It is common to perform calculus operations such differentiation, writing it as \\(\\partial_t \\vec{v}(t)\\). It is sometimes easier to grasp a vector-valued function by writing it as a column of scalar-valued functions: \\[\\vec{v}(t) = \\left[\\begin{array}{c}v_x(t)\\\\v_y(t)\\\\v_z(t)\\end{array}\\right]\\] where the \\(x\\), \\(y\\), and \\(z\\) refer to the axes of the coordinate system.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Vectors</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#length-direction",
    "href": "Linear-combinations/B5-Vectors.html#length-direction",
    "title": "29  Vectors",
    "section": "",
    "text": "Figure 29.1: Three pencils, but just two vectors. The yellow and blue pencils have the same length and direction, so they are the same vector. A pencil has a position, but vectors do not. The green pencil shares the same direction but has a different length, so it differs from the blue/yellow vector.\n\n\n\n\n\n\n\n\n\n \n \n\n\n\nFigure 29.2: Two different vectors. They have the same length and are parallel but point in opposite directions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 29.3: A 1958 US Navy training film on calculations with relative motion. Available at https://youtu.be/j197C0XuNUA\n\n\n\n\n\n\n\n\n\n\n\nFigure 29.4: Representing a vector as a set of numbers requires reference to a coordinate system, shown here as graph paper.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it! 29.1\n\n\n\n\n\n\n\n\n\nTry it! 29.1 Creating column vectors\n\n\n\nConstruct column vectors with the rbind() function, as in\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nCommas separate the arguments—the coordinate numbers—in the same way as any other R function.\nLater in this block, we will use data frames to define vectors. We will introduce the R syntax for that when we need it.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Vectors</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#the-nth-dimension",
    "href": "Linear-combinations/B5-Vectors.html#the-nth-dimension",
    "title": "29  Vectors",
    "section": "29.2 The nth dimension",
    "text": "29.2 The nth dimension\nIn many applications, especially those involving data, vectors have more than three components. Indeed, you will soon be working with vectors with hundreds of components. Services like Google search rely on vector calculations with millions of vectors, each having millions of components.\nLiving as we do in a palpably three-dimensional space and with senses and brains evolved for use in three dimensions, it is hard and maybe even impossible to grasp high-dimensional spaces.\nA lovely 1884 book, Flatland features the inhabitants of a two-dimensional world. The central character in the story, named Square, receives a visitor, Sphere. Sphere is from the three-dimensional world which embeds Flatland. Only with difficulty can Square assemble a conception of the totality of Sphere from the appearing, growing, and vanishing of Sphere’s intersection with the flat world. (Among other things, Flatland is a parody of humanity’s rigid thinking: Square’s attempt to convince Sphere that his three-dimensional world might be embedded in a four-dimensional one leads to rejection and disgrace. Sphere thinks he knows everything.)\n\n\n\n\n\n\nFigure 29.5: Flatland, a movie based on the 1884 book of the same name\n\n\n\nTo use high-dimensional vectors, represent them as a column of numbers.\n\\[\\left[\\begin{array}{r}6.4\\\\3.0\\\\-2.5\\\\17.3\\end{array}\\right]\\ \\ \\ \\left[\\begin{array}{r}-14.2\\\\-6.9\\\\18.0\\\\1.5\\\\-0.3\\end{array}\\right]\\ \\ \\ \\left[\\begin{array}{r}5.3\\\\-9.6\\\\84.1\\\\5.7\\\\-11.3\\\\4.8\\end{array}\\right]\\ \\ \\ \\cdots\\ \\ \\ \\left.\\left[\\begin{array}{r}7.2\\\\-4.4\\\\0.6\\\\-4.1\\\\4.7\\\\\\vdots\\ \\ \\\\-7.3\\\\8.3\\end{array}\\right]\\right\\} n\\]\nSensible people may see mathematical ostentation in promoting simple columns of numbers into “vectors in high-dimensional space.” But doing so lets us draw the analogy between data and familiar geometrical concepts: lengths, angles, alignment, etc. Operations that are mysterious as a long sequence of arithmetic steps become concrete when seen as geometry.\nThere is nothing science-fiction-like about so-called “high-dimensional” spaces; they don’t correspond to a physical place. Nevertheless, many-component vectors often appear in advanced physics. Famously, the Theory of Relativity involves 4-dimensional space-time. The vector representing the state of an ordinary particle contains the position and velocity, \\((x, y, z, v_x, v_y, v_z)\\), as well as angular velocity: nine dimensions. In statistics, engineering, and statistical mechanics, the term degrees of freedom is the preferred alternative to “dimension.” Another example: computer-controlled machine tools have 5 degrees of freedom (or more). There is a cutting tool with an \\(x, y, z\\) position and orientation. (If ever you start to freak out about the idea of a 10-dimensional space, close your eyes and remember that this is only shorthand for the set of arrays with ten elements.)",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Vectors</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#geometry-arithmetic",
    "href": "Linear-combinations/B5-Vectors.html#geometry-arithmetic",
    "title": "29  Vectors",
    "section": "29.3 Geometry & arithmetic",
    "text": "29.3 Geometry & arithmetic\nThree mathematical tasks are essential to working with vectors:\n\nMeasure the length of a vector.\nMeasure the angle between two vectors.\nCreate a new vector by scaling a vector. Scaling makes the new vector longer or shorter and may reverse the orientation.\n\nWe have simple geometrical tools for undertaking these tasks: a ruler measures length, and a protractor measures angles. Along with pen and paper, these tools let us draw new vectors of any specified length.\nThe geometrical perspective is helpful for many purposes, but often we need to work with vectors using computers. For this, we use the numerical representation of vectors.\nThis section introduces the arithmetic of vectors. With this arithmetic in hand, we can carry out the above three tasks (and more!) on vectors that consist of a column of numbers. And while we can’t import a ruler, protractor, or paper into high-dimensional space, arithmetic is easy to do, regardless of dimension.\nTo scale a vector \\(\\vec{w}\\) means more or less to change the vector’s length. A good mental image for scaling sees the vector as a step or displacement in the direction of \\(\\vec{w}\\). Scaling means to go on a simple walk, taking one step after the other in the same direction as the \\(\\vec{w}\\). We write a scaled vector by placing a number in front of the name of the vector. \\(3 \\vec{w}\\) is a short walk of three steps; \\(117 \\vec{w}\\) is a considerably longer walk; \\(-5 \\vec{w}\\) means to take five steps backward. You can also take fraction steps: \\(0.5 \\vec{w}\\) is half a step, \\(19.3 \\vec{w}\\) means to take 19 steps followed by a 30% step. Scaling a vector by \\(-1\\) means flipping the vector tip-for-tail; this does not change the length, just the orientation.\nArithmetically, scaling a vector is accomplished simply by multiplying each of the vector’s components by the same number. Two illustrate, consider vectors \\(\\vec{v}\\) and \\(\\vec{w}\\), each with \\(n\\) components. (We use \\(\\vdots\\) to indicate components we haven’t bothered to write out.)\n\\[\\vec{v} \\equiv \\left[\\begin{array}{r}6\\\\2\\\\-4\\\\\\vdots\\\\1\\\\8\\end{array}\\right]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\vec{w} \\equiv \\left[\\begin{array}{r}-3\\\\1\\\\-5\\\\\\vdots\\\\2\\\\5\\end{array}\\right]\\] To scale a vector by 3 is accomplished by multiplying each component by 3\n\\[3\\, \\vec{v} = 3\\left[\\begin{array}{r}6\\\\2\\\\-4\\\\\\vdots\\\\1\\\\8\\end{array}\\right] = \\left[\\begin{array}{r}18\\\\6\\\\-12\\\\\\vdots\\\\3\\\\24\\end{array}\\right]\\] Vector scaling is perfectly ordinary multiplication applied component by component, that is, *** componentwise ***.\nScaling involves a number (the “scalar”) and a single vector. Other sorts of multiplication involve two or more vectors.\nThe dot product is one sort of multiplication of one vector with another. The dot product between \\(\\vec{v}\\) and \\(\\vec{w}\\) is written \\[\\vec{v} \\bullet \\vec{w}\\].\nThe arithmetic of the dot product involves two steps:\n\nMultiply the two vectors componentwise. For instance: \\[\\underset{\\Large \\vec{v}}{\\left[\\begin{array}{r}6\\\\2\\\\-4\\\\\\vdots\\\\1\\\\8\\end{array}\\right]}\\  \\underset{\\Large \\vec{w}}{\\left[\\begin{array}{r}-3\\\\1\\\\-5\\\\\\vdots\\\\2\\\\5\\end{array}\\right]} = \\left[\\begin{array}{r}-18\\\\2\\\\20\\\\\\vdots\\\\2\\\\40 \\end{array}\\right]\\]\nSum the elements in the componentwise product. For the component-wise product of \\(\\vec{v}\\) and \\(\\vec{w}\\), this will be \\(-18 + 2 + 20 + \\cdots +2 + 40\\). The resulting sum is an ordinary scalar quantity; a dot product takes two vectors as inputs and produces a scalar as an output.\n\n\n\n\n\n\n\n\n\nTry it! 29.2\n\n\n\n\n\n\n\n\n\nTry it! 29.2 Infix notation\n\n\n\nR/mosaic provides a beginner-friendly function for computing a dot product. To mimic the use of the dot, as in \\(\\vec{v} \\bullet \\vec{w}\\), the function will be invoked using infix notation. You have a lot of infix notation experience, even if you have never heard the term. Some examples:\n3 + 2       7 / 4      6 - 2      9 * 3     2 ^ 4\nInfix notation is distinct from the functional notation that you are also familiar with, for instance sin(2) or makeFun(x^2 ~ x).\nYou can, if you like, invoke the +, -, *, /, and ^ operations using functional notation. Nobody does this because the commands are so ugly:\n\n`+`(3, 2)\n## [1] 5\n\n`/`(7, 4)\n## [1] 1.75\n\n`-`(6, 2)\n## [1] 4\n\n`*`(9, 3)\n## [1] 27\n\n`^`(2, 4)\n## [1] 16\n\nThe R language makes it possible to define new infix operators, but there is a catch. The new operators must always have a name that begins and ends with the % symbol, for example, %&gt;% or %*% or %dot%.\nHere is an example of using %dot% to calculate the dot product of two vectors embedded in five-dimensional space:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe vectors combined with %dot% must both have the same number of elements. Otherwise, an error message will result, as here:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe have not yet shown you the use of the dot product in applications. At this point, remember that a dot product is not ordinary multiplication but a two-stage operation of pairwise multiplication followed by summation.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Vectors</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#sec-vector-length",
    "href": "Linear-combinations/B5-Vectors.html#sec-vector-length",
    "title": "29  Vectors",
    "section": "29.4 Vector lengths",
    "text": "29.4 Vector lengths\nThe arithmetic used to calculate the length of a vector is based on the Pythagorean theorem. For a vector \\(\\vec{u} = \\left[\\begin{array}{c}4\\\\3\\end{array}\\right]\\) the vector is the hypotenuse of a right triangle with legs of length 4 and 3 respectively. Therefore, \\[\\|\\vec{u}\\| = \\sqrt{4^2 + 3^2} = 5\\ .\\] For vectors with more than two components, follow the same pattern: sum the squares of the components, then take the square root.\nCompute the length of a vector \\(\\vec{u}\\) using the dot product: \\[\\|\\vec{u}\\| = \\sqrt{\\strut\\vec{u} \\bullet \\vec{u}}\\ .\\] Although length has an obvious physical interpretation, in many areas of science, including statistics and quantum physics, the square length is a more fundamental quantity. The square length of \\(\\vec{u}\\) is simply \\(\\|\\vec{u}\\|^2 = \\vec{u}\\bullet \\vec{u}\\).\n\n\n\n\n\n\n\n\n\n?tip-vector-length Calculating vector length\n\n\n\nConsider the two vectors \\[\\vec{u} \\equiv \\left(\\begin{array}{c}3\\\\4\\end{array}\\right) \\  \\  \\ \\mbox{and}  \\ \\ \\ \\vec{w} \\equiv \\left(\\begin{array}{c}1\\\\1\\\\1\\\\1\\end{array}\\right)\n\\]\nThe length of \\(\\vec{u}\\) is \\(|| \\vec{u} || = \\sqrt{\\strut 3^2 + 4^2} = \\sqrt{\\strut 25} = 5\\).\nThe length of \\(\\vec{w}\\) is \\(|| \\vec{w} || = \\sqrt{\\strut 1^2 + 1^2 + 1^2 + 1^2} = \\sqrt{\\strut 4} = 2\\).\n\n\n\nApplication area 29.1 —Linear geometry and statistics\n\n\n\n\n\n\n\nApplication area 29.1 Statistical modeling\n\n\n\nIn statistics, the many applications of linear algebra often involve a simple constant vector, which we will write \\(\\vec{1}\\). It is simply a column vector of 1s, \\[\\vec{1} \\equiv \\left[\\begin{array}{c}1\\\\1\\\\1\\\\\\vdots\\\\1\\\\1\\\\ \\end{array}\\right]\\ .\\] Common statistical calculations can be expressed compactly in vector notation. For example, if \\(\\vec{x}\\) is an \\(n\\)-dimensional vector, then the mean of the components of \\(\\vec{x}\\), which is often written \\(\\bar{x}\\), is \\[\\bar{x} \\equiv \\frac{1}{n}\\  \\vec{x} \\bullet \\vec{1}\\ .\\] The symbol \\(\\bar{}\\) is pronounced “bar”, and \\(\\bar{x}\\) is pronounced “x-bar.”.\nAnother commonly used statistic is the variance of the components of a vector \\(\\vec{x}\\). Calculating the variance is more complicated than the mean: \\[\\text{var}(x) \\equiv \\frac{1}{n-1}\\  (\\vec{x} - \\bar{x}) \\bullet (\\vec{x} - \\bar{x})\\ .\\] The quantity \\(\\vec{x} - \\bar{x}\\) is an example of scalar subtraction, which is done on a component-wise basis. For instance, with \\[\\vec{x} = \\left[\\begin{array}{r}1\\\\2\\\\3\\\\4\\\\\\end{array}\\right]\\] then \\(\\bar{x} = 2.5\\). This being the case, \\[\\vec{x} - \\bar{x} = \\left[\\begin{array}{c}-1.5\\\\-0.5\\\\\\ 0.5\\\\\\ 1.5\\\\\\end{array}\\right]\\ ,\\] with the variance of \\(\\vec{x}\\) being \\[\\frac{1}{4-1} \\left[\\begin{array}{r}-1.5\\\\-0.5\\\\0.5\\\\1.5\\\\\\end{array}\\right] \\bullet \\left[\\begin{array}{r}-1.5\\\\-0.5\\\\0.5\\\\1.5\\\\\\end{array}\\right] = \\frac{5}{3}\\ .\\]",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Vectors</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#sec-angles-dot-product",
    "href": "Linear-combinations/B5-Vectors.html#sec-angles-dot-product",
    "title": "29  Vectors",
    "section": "29.5 Angles",
    "text": "29.5 Angles\nAny two vectors of the same dimension have an angle between them. Vectors have only two properties: length and direction. To find the angle between two vectors, pick up one vector and relocate its “tail” to meet the tail of the other vector.\nMeasure the angle between two vectors the short way round: between 0 and 180 degrees. Any larger angle, say 260 degrees, will be identified with its circular complement: 100 degrees is the complement of a 260-degree angle.\nIn 2- and 3-dimensional spaces, we can measure the angle between two vectors using a protractor: arrange the two vectors tail to tail, align the baseline of the protractor with one of the vectors and read off the angle marked by the second vector.\nIt is also possible to measure the angle using arithmetic. Suppose we have vectors \\(\\vec{v}\\) and \\(\\vec{w}\\) embedded in the same dimensional space. That is, \\(\\vec{v}\\) and \\(\\vec{w}\\) have the same number of components:\n\\[\\vec{v} = \\left[\\begin{array}{c}v_1\\\\v_2\\\\\\vdots\\\\v_n\\\\\\end{array}\\right]\\ \\ \\ \\text{and}\\ \\ \\ \\vec{w} = \\left[\\begin{array}{c}w_1\\\\w_2\\\\\\vdots\\\\w_n\\\\\\end{array}\\right]\\ ,\\]\nUsing the dot-product and length notation, we can write the formula for the cosine of the angle between two vectors as \\[\\cos(\\theta) \\equiv \\frac{\\vec{v}\\cdot\\vec{w}}{\\|\\vec{v}\\|\\ \\|\\vec{w}\\|}\\ .\\]\n\n\n\n\n\n\nTip\n\n\n\nRemember that the dot-product-based formula above gives the cosine of the angle between the two vectors. It turns out that in many applications, cosine is what’s needed. If you insist on knowing the angle \\(\\theta\\) rather than \\(\\cos(\\theta)\\), the trigonometric function \\(\\arccos()\\) will do the job. For instance, if \\(\\theta\\) is such that \\(\\cos(\\theta) = 0.6\\), compute the angle in degrees with\n\nacos(0.6)*180/pi\n## [1] 53.1301\n\nThe trigonometric functions in R (and in most other languages) do calculations with angles in units of radians. Multiplication by 180/pi converts radians to degrees. Figure 29.6 shows a graph of converting \\(\\cos(\\theta)\\) to \\(\\theta\\) in degrees.\n\n\n\n\n\n\n\n\nFigure 29.6: The \\(\\arccos()\\) function (acos() in R) converts \\(\\cos(\\theta)\\) to \\(\\theta\\).\n\n\n\n\n\n\n\n\nApplication area 29.2 —Another example of how geometry and statistics have much in common.\n\n\n\n\n\n\n\nApplication area 29.2 “Correlation” is an angle\n\n\n\nWhat does the angle \\(\\theta\\) between two vectors tell us?\nThe angle quantifies the alignment of the vectors. An angle of 0 tells us the vectors point in the same direction, and an angle of 180 degrees means that the vectors point in exactly opposing directions. Either of these—0 or 180 degrees—indicates that the two vectors are perfectly aligned. Such alignment means that appropriate scalar multiplication can make the two vectors equal.\nAngles such as 5 or 175 degrees indicate that the two vectors are mostly aligned but imperfectly. When the angle is 90 degrees—a right angle—the two vectors are perpendicular.\nThe vector alignment has an important meaning in terms of data. Suppose the two vectors are two columns in a data frame: two different variables. In statistics, the correlation coefficient, denoted \\(r\\), is a simple way to describe the relationship between two variables. A non-zero correlation indicates a connection between two variables. For instance, among children, height and age are correlated. Since height increases along with age (for children), the two variables are said to be positively correlated. The largest possible correlation is \\(r=1\\).\nA negative correlation means that one variable decreases as the other increases. Temperature and elevation are negatively correlated; temperature goes down as elevation goes up. The most negative possible correlation is \\(r=-1\\).\nA zero correlation indicates no simple (linear) relationship between the two variables. Zero correlation occurs when the variables are orthogonal, a term described in Section 29.6.\nSeeing columns in a data frame as vectors, the correlation coefficient \\(r\\) is exactly the cosine of the angle between the vectors. However, when Francis Galton invented the correlation coefficient in the 1880s, he did not describe it in these terms. Instead, he used arithmetic directly, producing formulas with which many generations of statistics students have struggled. Those students might have done better in statistics if \\(r\\) had been called alignment and measured in degrees.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Vectors</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#sec-orthogonality",
    "href": "Linear-combinations/B5-Vectors.html#sec-orthogonality",
    "title": "29  Vectors",
    "section": "29.6 Orthogonality",
    "text": "29.6 Orthogonality\nTwo vectors are said to be orthogonal when the angle between them is 90 degrees. In everyday speech, we call a 90-degree angle a “right angle.” The word “orthogonal” is a literal translation of “right angle.” (The syllable “gon” indicates an angle, as in the five-angled pentagon or six-angled hexagon. “Ortho” means “right” or “correct,” as in “orthodox” (right beliefs) or “orthodontics” (right teeth) or “orthopedic” (right feet).)\nTwo vectors are at right angles—we prefer “orthogonal” since “right” has many meanings not related to angles—when the dot product between them is zero.\n\n\n\n\n\n\n\n\n\n?tip-ortho1 Orthogonality 1\n\n\n\nFind a vector that is orthogonal to \\(\\left[\\strut\\begin{array}{r}1\\\\2\\end{array}\\right]\\).\nThe arithmetic trick is to reverse the order of the components and put a minus sign in front of one of them, so \\(\\left[\\strut\\begin{array}{r}-2\\\\1\\end{array}\\right]\\).\nWe can confirm the orthogonality by calculating the dot product: \\(\\left[\\begin{array}{c}-2\\\\\\ 1\\end{array}\\right] \\cdot \\left[\\strut\\begin{array}{r}1\\\\2\\end{array}\\right] = -2\\times1 + 1 \\times 2 = 0\\).\nIn R, write this as\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n\n?tip-ortho1 Orthogonality 2\n\n\n\nFind a vector orthogonal to \\(\\left[\\strut\\begin{array}{r}1\\\\2\\\\3\\end{array}\\right]\\).\nWe have a little more scope here. A simple approach is to insert a zero component in the new vector and then use the two-dimensional trick to fill in the remaining components.\nFor instance, starting with \\(\\left[\\strut\\begin{array}{r}0\\\\\\_\\\\ \\_\\end{array}\\right]\\) the only non-zero components of the dot product will involve the 2 and 3 of the original vector. So \\(\\left[\\strut\\begin{array}{r}0\\\\ -3\\\\ 2\\end{array}\\right]\\) is orthogonal. Or, if we start with \\(\\left[\\strut\\begin{array}{r}\\_\\\\0\\\\\\_\\end{array}\\right]\\) we would construct \\(\\left[\\strut\\begin{array}{r}-3\\\\ 0\\\\ 1\\end{array}\\right]\\).",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Vectors</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-projection.html",
    "href": "Linear-combinations/B5-projection.html",
    "title": "31  Projection & residual",
    "section": "",
    "text": "31.1 Projection terminology\nIn a typical vector decomposition task, the setting determines the relevant direction or subspace. The decomposition is accomplished by projecting the vector onto that direction or subspace. The word “projection” may bring to mind the casting of shadows on a screen in the same manner as an old-fashioned slide projector or movie projector. The light source and focusing lens generate parallel rays that arrive perpendicular to the screen. A movie screen is two-dimensional, a subspace defined by two vectors. Imagining those two vectors to be collected into matrix \\(\\mathit{A}\\), the idea is to decompose \\(\\vec{b}\\) into a component that lies in the subspace defined by \\(\\mathit{A}\\) and another component that is perpendicular to the screen. That perpendicular component is what we have been calling \\(\\vec{r}\\) while the vector \\(\\hat{b}\\) is the projection of \\(\\vec{b}\\) onto the screen. To make it easier to keep track of the various roles played by \\(\\vec{b}\\), \\(\\hat{b}\\), \\(\\vec{r}\\), and \\(\\mathit{A}\\), we will give these vectors English-language names. 1\nProjection is the process of finding, from all the vectors in the model subspace, the particular vector \\(\\hat{b}\\) that is as close as possible to the target vector \\(\\vec{b}\\). To state things another way: projection is the process of finding the model vector that makes the residual vector as short as possible.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Projection & residual</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#projection-terminology",
    "href": "Linear-combinations/B5-projection.html#projection-terminology",
    "title": "31  Projection & residual",
    "section": "",
    "text": "\\(\\vec{b}\\) the target vector\n\\(\\hat{b}\\) the model vector\n\\(\\vec{r}\\) the residual vector\n\\(\\mathit{A}\\) the model space (or “model subspace”)\n\n\n\n\n\n\n\n\n\n\nTry it! 31.1\n\n\n\n\n\n\n\n\n\nTry it! 31.1 Projecting in 3 dimensions\n\n\n\nThe interactive graphic shows a solved projection problem in 3-dimensional space. The figure can be rotated or set spinning, which makes it much easier to interpret the diagram as a three-dimensional object.\n\n\n\n\nIn addition to the target vector \\(\\vec{b}\\) and the vectors \\(\\vec{u}\\) and \\(\\vec{b}\\) that constitute the matrix \\(\\mathit{A}\\), the diagram includes a translucent plane marking \\(span(\\mathit{A})\\). The goal of projection is, given \\(\\vec{b}\\) and \\(\\mathit{A}\\), to find the model vector (shown in light green). Once the model vector \\(\\vec{x}\\) is known, the residual vector is easy to calculate \\[\\vec{r} \\equiv \\vec{b} - \\hat{b}\\ .\\] Another approach to the problem is to find the residual vector \\(r\\) first, then use that to find the model vector as \\[\\hat{b} \\equiv \\vec{b} - \\vec{r}\\ .\\]\nInterpreting such three-dimensional diagrams on a static printed page can be difficult. Being able to interact with the diagrams helps a lot. For instance, to see that the translucent plane in ?fig-b-onto-u-v2 contains \\(\\vec{u}\\) and \\(\\vec{v}\\), rotate the diagram to look edge-on at the plane so that the plane appears as a line on the screen. At such times, vectors \\(\\vec{u}\\) and \\(\\vec{v}\\) disappear. There is no component to \\(\\vec{u}\\) and \\(\\vec{v}\\) that sticks out from the plane; they are entirely embedded in the plane.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Projection & residual</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#sec-proj-single-vector",
    "href": "Linear-combinations/B5-projection.html#sec-proj-single-vector",
    "title": "31  Projection & residual",
    "section": "31.2 Projection onto a single vector",
    "text": "31.2 Projection onto a single vector\nAs we said, projection involves a vector \\(\\vec{b}\\) and a matrix \\(\\mathit{A}\\) that defines the model space. We will start with the simplest case, where \\(\\mathit{A}\\) has only one column. That column is, of course, a vector. We will call that vector \\(\\vec{a}\\), so the projection problem is to project \\(\\vec{b}\\) onto the subspace spanned by \\(\\vec{a}\\).\nFigure 31.3 diagrams the situation of projecting the target vector \\(\\vec{b}\\) onto the model space \\(\\vec{a}\\).\n\n\n\n\n\n\n\n\nFigure 31.3: The geometry of projecting \\(\\vec{b}\\) onto \\(\\vec{a}\\) to produce the model vector \\(\\hat{b}\\).\n\n\n\n\n\nThe angle between \\(\\vec{a}\\) and \\(\\vec{b}\\) is labelled \\(\\theta\\). As shown in Section 29.5, calculating an angle such as \\(\\theta\\) from \\(\\vec{b}\\) and \\(\\vec{a}\\) with a dot product:\n\\[\\cos(\\theta) = \\frac{\\vec{b} \\bullet \\vec{a}}{\\len{b}\\, \\len{a}}\\ .\\] Knowing \\(\\theta\\) and \\(\\len{b}\\), you can calculate the length of the model vector \\(\\hat{b}\\): \\[\\len{s} = \\len{b} \\cos(\\theta) = \\vec{b} \\bullet \\vec{a} / \\len{a}\\ .\\]\nScaling \\(\\vec{a}\\) by \\(\\len{a}\\) would produce a vector oriented in the model subspace, but it would have the wrong length: length \\(\\len{a} \\len{s}\\). So we need to divide \\(\\vec{a}\\) by \\(\\len{a}\\) to get a unit length vector oriented along \\(\\vec{a}\\):\n\\[\\text{model vector:}\\ \\ \\hat{b} = \\left[\\vec{b} \\bullet \\vec{a}\\right] \\,\\vec{a} / {\\len{a}^2} = \\frac{\\vec{b} \\bullet \\vec{a}}{\\vec{a} \\bullet \\vec{a}}\\  \\vec{a}.\\] . \n\n\n\n\n\n\n\n\nTry it! 31.2\n\n\n\n\n\n\n\n\n\nTry it! 31.2 Projecting one vector onto another\n\n\n\nIn R/mosaic, calculate the projection of \\(\\vec{b}\\) onto \\(\\vec{a}\\) using %onto%. For instance\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHaving found \\(\\hat{b}\\), the residual vector \\(\\vec{r}\\) can be calculated as \\(\\vec{b}- \\hat{b}\\).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe two properties that a projection satisfies are:\n\nThe residual vector is perpendicular to each and every vector in \\(\\mathit{A}\\). Since in this example, \\(\\mathit{A}\\) contains only the one vector \\(\\vec{a}\\), we need only look at \\(\\vec{r} \\cdot \\vec{a}\\) and confirm that it is zero.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nThe residual vector plus the model vector exactly equals the target vector. Since we computed r &lt;- b - s, we know this must be true, but still …\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIf the difference between two vectors is zero for every coordinate, the two vectors must be identical.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Projection & residual</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#projection-onto-a-set-of-vectors",
    "href": "Linear-combinations/B5-projection.html#projection-onto-a-set-of-vectors",
    "title": "31  Projection & residual",
    "section": "31.3 Projection onto a set of vectors",
    "text": "31.3 Projection onto a set of vectors\nAs we have just seen, projecting a target \\(\\vec{b}\\) onto a single vector is a matter of arithmetic. Now we will expand the technique to project the target vector \\(\\vec{b}\\) onto multiple vectors collected into a matrix \\(\\mathit{A}\\). Whereas in Section 31.2 we used trigonometry to find the component of \\(\\vec{b}\\) aligned with the single vector \\(\\vec{a}\\), now we have to deal with multiple vectors at the same time. The result will be the component of \\(\\vec{b}\\) aligned with the subspace sponsored by \\(\\mathit{A}\\).\nIn one situation, projection is easy: when the vectors in \\(\\mathit{A}\\) are mutually orthogonal. In this situation, carry out several one-vector-at-a-time projections: \\[\n\\vec{p_1} \\equiv \\modeledby{\\vec{b}}{\\vec{v_1}}\\ \\ \\ \\ \\\n\\vec{p_2} \\equiv \\modeledby{\\vec{b}}{\\vec{v_2}}\\ \\ \\ \\ \\\n\\vec{p_3} \\equiv \\modeledby{\\vec{b}}{\\vec{v_3}}\\ \\ \\ \\ \\\n\\text{and so on}\\] The projection of \\(\\vec{b}\\) onto \\(\\mathit{A}\\) will be the sum \\(\\vec{p_1} + \\vec{p2} + \\vec{p3}\\).\n\n\n\n\n\n\n\n\n\nTry it! 31.3 Projecting a vector onto a subspace\n\n\n\nConsider the following matrix \\(\\mathit{A}\\) made up of mutually orthogonal vectors:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTo confirm that v1, v2, and v3 are mutually orthogonal, calculate the dot product between any two of them and observe that, in each case, the result is zero.\nNow construct the one-at-a-time projections:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTo find the projection of \\(\\vec{b}\\) onto the subspace spanned by \\(\\mathit{A}\\), add up the one-at-a-time projections:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow we will confirm that b_on_A is the projection of b onto A. The strategy is to construct the residual from the projection.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAll that is needed is to confirm that the residual is perpendicular to each and every vector in A:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n31.4 A becomes Q\nNow that we have a satisfactory method for projecting \\(\\vec{b}\\) onto a matrix \\(\\mathit{A}\\) consisting of mutually orthogonal vectors, we need to develop a method for the projection when the vectors in \\(\\mathit{A}\\) are not mutually orthogonal. The big picture here is that we will construct a new matrix \\(\\mathit{Q}\\) that spans the same space as \\(\\mathit{A}\\) but whose vectors are mutually orthogonal. We will construct \\(\\mathit{Q}\\) out of linear combinations of the vectors in \\(\\mathit{A}\\), so we can be sure that \\(span(\\mathit{Q}) = span(\\mathit{A})\\).\nWe introduce the process with an example involving vectors in a 4-dimensional space. \\(\\mathit{A}\\) will be a matrix with two columns, \\(\\vec{v_1}\\) and \\(\\vec{v_2}\\). Here is the setup for the example vectors and model matrix:\n\nb &lt;- rbind(1,1,1,1)\nv1 &lt;- rbind(2,3,4,5)\nv2 &lt;- rbind(-4,2,4,1)\nA &lt;- cbind(v1, v2)\n\nWe start the construction of the \\(\\mathit{Q}\\) matrix by pulling in the first vector in \\(\\mathit{A}\\). We will call that vector \\(\\vec{q_1}\\)\n\nq1 &lt;- v1\n\nThe next \\(\\mathit{Q}\\) vector will be constructed to be perpendicular to \\(\\vec{q_1}\\) but still in the subspace spanned by \\(\\left[{\\Large\\strut}\\vec{v_1}\\ \\ \\vec{v_2}\\right]\\). We can guarantee this will be the case by making the \\(\\mathit{Q}\\) vector entirely as a linear combination of \\(\\vec{v_1}\\) and \\(\\vec{v_2}\\).\n\nq2 &lt;- v2 %perp% v1\n\nSince \\(\\vec{q_1}\\) and \\(\\vec{q_2}\\) are orthogonal and define the same subspace as \\(\\mathit{A}\\), we can construct the projection of \\(\\vec{b}\\) onto \\(\\vec{A}\\) by adding up the projections of \\(\\vec{b}\\) onto the individual vectors in \\(\\mathit{Q}\\), like this:\n\nbhat &lt;- (b %onto% q1) + (b %onto% q2)\n\nTo confirm that this calculation of \\(\\widehat{\\strut b}\\) is correct, construct the residual vector and show that it is perpendicular to every vector in \\(\\mathit{Q}\\) (and therefore in \\(\\mathit{A}\\), which spans the same space).\n\nr &lt;- b - bhat\nr %dot% v1\n## [1] 1.110223e-15\nr %dot% v2\n## [1] 2.220446e-16\n\nNote that we defined \\(\\vec{r} = \\vec{b} - \\widehat{\\strut b}\\), so it is guaranteed that \\(\\vec{r} + \\widehat{\\strut b}\\) will equal \\(\\vec{b}\\).\nThis process can be extended to any number of vectors in \\(\\mathit{A}\\). Here is the algorithm for constructing \\(\\mathit{Q}\\):\n\nTake the first vector from \\(\\mathit{A}\\) and call it \\(\\vec{q_1}\\).\nTake the second vector from \\(\\mathit{A}\\) and find the residual from projecting it onto \\(\\vec{q_1}\\). This residual will be \\(\\vec{q_2}\\). At this point, the matrix \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\) consists of mutually orthogonal vectors.\nTake the third vector from \\(\\mathit{A}\\) and project it onto \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\). We can do this because we already have an algorithm for projecting a vector onto a matrix with mutually orthogonal columns. Call the residual from this projection \\(\\mathit{q_3}\\). It will be orthogonal to the vectors in \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\), so all three of the q vectors we’ve created are mutually orthogonal.\nContinue onward, taking the next vector in \\(\\mathit{A}\\), projecting it onto the q-vectors already assembled, and finding the residual from that projection.\nRepeat step (iv) until all the vectors in \\(\\mathit{A}\\) have been handled.\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n?thm-project-in-10 Projecting in 10-dimensional space\n\n\n\nProject a \\(\\vec{b}\\) that lives in 10-dimensional space onto the subspace sponsored by five vectors that are not mutually orthogonal:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nConfirm using dot products that the v-vectors are not mutually orthogonal.\nNow to construct the vectors in \\(\\mathit{Q}\\).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSince Q consists of mutually orthogonal vectors, the projection of b onto Q can be made one vector at a time.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nTry it! 31.3",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Projection & residual</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#a-becomes-q",
    "href": "Linear-combinations/B5-projection.html#a-becomes-q",
    "title": "31  Projection & residual",
    "section": "31.4 A becomes Q",
    "text": "31.4 A becomes Q\nNow that we have a satisfactory method for projecting \\(\\vec{b}\\) onto a matrix \\(\\mathit{A}\\) consisting of mutually orthogonal vectors, we need to develop a method for the projection when the vectors in \\(\\mathit{A}\\) are not mutually orthogonal. The big picture here is that we will construct a new matrix \\(\\mathit{Q}\\) that spans the same space as \\(\\mathit{A}\\) but whose vectors are mutually orthogonal. We will construct \\(\\mathit{Q}\\) out of linear combinations of the vectors in \\(\\mathit{A}\\), so we can be sure that \\(span(\\mathit{Q}) = span(\\mathit{A})\\).\nWe introduce the process with an example involving vectors in a 4-dimensional space. \\(\\mathit{A}\\) will be a matrix with two columns, \\(\\vec{v_1}\\) and \\(\\vec{v_2}\\). Here is the setup for the example vectors and model matrix:\n\nb &lt;- rbind(1,1,1,1)\nv1 &lt;- rbind(2,3,4,5)\nv2 &lt;- rbind(-4,2,4,1)\nA &lt;- cbind(v1, v2)\n\nWe start the construction of the \\(\\mathit{Q}\\) matrix by pulling in the first vector in \\(\\mathit{A}\\). We will call that vector \\(\\vec{q_1}\\)\n\nq1 &lt;- v1\n\nThe next \\(\\mathit{Q}\\) vector will be constructed to be perpendicular to \\(\\vec{q_1}\\) but still in the subspace spanned by \\(\\left[{\\Large\\strut}\\vec{v_1}\\ \\ \\vec{v_2}\\right]\\). We can guarantee this will be the case by making the \\(\\mathit{Q}\\) vector entirely as a linear combination of \\(\\vec{v_1}\\) and \\(\\vec{v_2}\\).\n\nq2 &lt;- v2 %perp% v1\n\nSince \\(\\vec{q_1}\\) and \\(\\vec{q_2}\\) are orthogonal and define the same subspace as \\(\\mathit{A}\\), we can construct the projection of \\(\\vec{b}\\) onto \\(\\vec{A}\\) by adding up the projections of \\(\\vec{b}\\) onto the individual vectors in \\(\\mathit{Q}\\), like this:\n\nbhat &lt;- (b %onto% q1) + (b %onto% q2)\n\nTo confirm that this calculation of \\(\\widehat{\\strut b}\\) is correct, construct the residual vector and show that it is perpendicular to every vector in \\(\\mathit{Q}\\) (and therefore in \\(\\mathit{A}\\), which spans the same space).\n\nr &lt;- b - bhat\nr %dot% v1\n## [1] 1.110223e-15\nr %dot% v2\n## [1] 2.220446e-16\n\nNote that we defined \\(\\vec{r} = \\vec{b} - \\widehat{\\strut b}\\), so it is guaranteed that \\(\\vec{r} + \\widehat{\\strut b}\\) will equal \\(\\vec{b}\\).\nThis process can be extended to any number of vectors in \\(\\mathit{A}\\). Here is the algorithm for constructing \\(\\mathit{Q}\\):\n\nTake the first vector from \\(\\mathit{A}\\) and call it \\(\\vec{q_1}\\).\nTake the second vector from \\(\\mathit{A}\\) and find the residual from projecting it onto \\(\\vec{q_1}\\). This residual will be \\(\\vec{q_2}\\). At this point, the matrix \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\) consists of mutually orthogonal vectors.\nTake the third vector from \\(\\mathit{A}\\) and project it onto \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\). We can do this because we already have an algorithm for projecting a vector onto a matrix with mutually orthogonal columns. Call the residual from this projection \\(\\mathit{q_3}\\). It will be orthogonal to the vectors in \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\), so all three of the q vectors we’ve created are mutually orthogonal.\nContinue onward, taking the next vector in \\(\\mathit{A}\\), projecting it onto the q-vectors already assembled, and finding the residual from that projection.\nRepeat step (iv) until all the vectors in \\(\\mathit{A}\\) have been handled.\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n?thm-project-in-10 Projecting in 10-dimensional space\n\n\n\nProject a \\(\\vec{b}\\) that lives in 10-dimensional space onto the subspace sponsored by five vectors that are not mutually orthogonal:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nConfirm using dot products that the v-vectors are not mutually orthogonal.\nNow to construct the vectors in \\(\\mathit{Q}\\).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSince Q consists of mutually orthogonal vectors, the projection of b onto Q can be made one vector at a time.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Projection & residual</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#footnotes",
    "href": "Linear-combinations/B5-projection.html#footnotes",
    "title": "31  Projection & residual",
    "section": "",
    "text": "The motivation for these names will become apparent in later chapters.↩︎",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Projection & residual</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html",
    "href": "Linear-combinations/B5-target-problem.html",
    "title": "32  The target problem",
    "section": "",
    "text": "32.1 Linear equations\nThe focus of interest will be the familiar task\n\\[\\ \\ \\ \\ \\ \\ \\text{given}\\ \\ a x = b\\,,\\ \\ \\text{find}\\ \\ x\\ .\\] All algebra students learn that \\(x = b/a\\), with the proviso that if \\(a = 0\\), “there is no solution.”\nA somewhat more advanced algebra task is to work with “simultaneous linear equations,” for example: \\[\\ \\ \\ \\text{given}\\ \\ \\ \\begin{array}{rrrcr}\n3 x & + & 2 y & = & 7\\\\\n-1&+&y&=&4\\end{array}\n\\ \\ \\ \\ \\text{find}\\ \\ x\\,\\&\\,y\\ .\n\\]\nSolving simultaneous linear equations is hard. It involves more arithmetic than \\(ax = b\\) and requires the student to make good choices how to take linear combinations of the two equations to reduce the problem to two equations, one with \\(x\\) as the only unknown and one with \\(y\\). Also, the “there is no solution” proviso is not easy to state, so you cannot know at a glance whether there is indeed a solution.\nThe simultaneous linear equation problem can be more compactly written using matrix and vector notation. \\[\\begin{array}{rrrcr}3x & + &2y & = & 7\\\\-1&+&y&=&4\\end{array} \\ \\ \\text{is the same as}\\ \\ \\left[\\begin{array}{r}3\\\\-1\\end{array}\\right] x + \\left[\\begin{array}{r}2\\\\1\\end{array}\\right] y =\n\\left[\\begin{array}{r}7\\\\4\\end{array}\\right] \\] You can see the vector form as a linear combination of two vectors. Collecting these two vectors into a matrix \\(\\mathit{A}\\), and similarly writing \\(x\\, \\text{and}\\, y\\) as the scalar components of a vector \\(\\vec{x}\\) gives \\[\\left[\\begin{array}{rr}3&2\\\\-1&1\\end{array}\\right]\\ \\vec{x} = \\left[\\begin{array}{r}7\\\\4\\end{array}\\right]\\] Which can be expressed as \\(\\mathit{A} \\vec{x} = \\vec{b}\\).\nA student, recognizing the similarity of \\(\\mathit{A}\\vec{x} = \\vec{b}\\) to \\(a x = b\\) would reasonably suggest the solution \\(\\vec{x} = \\vec{b}/ \\mathit{A}\\). Such a student might be instructed, “No, you cannot do this.” A better response would be, “Good. Now tell me what you mean by \\(\\vec{b}/\\mathit{A}\\)?”\nModern practice often calls for solving \\(\\mathit{A}\\vec{x} = \\vec{b}\\) in settings where a traditional algebra teacher might say, as for \\(0 x = b\\) that “there is no solution.”\nTo illustrate such a setting, recall the problems from Section 11.3 of finding the linear combination of the functions \\(f(\\mathtt{time})=1\\) and \\(g(\\mathtt{time}) = e^{-0.019 \\mathtt{time}}\\) that best matches the CoolingWater data:\ntime\ntemp\n\n\n\n\n0\n98.2\n\n\n1\n94.4\n\n\n2\n91.4\n\n\n... 222 rows in total ...\n\n\n\n\n\n\n220\n25.9\n\n\n221\n25.8\nWe seek scalars \\(C\\) and \\(D\\) such that the function \\(C f(\\mathtt{time}) + D g(\\mathtt{time})\\) gives the best possible match to temp.\nWe can compactly write the problem of finding the best linear combination into matrix form by evaluating \\(f()\\) and \\(g()\\) at the values listed in the time column: \\[\\underbrace{\\left[\\begin{array}{rr}1&1.0000\\\\1&0.9812\\\\1&0.9627\\\\\\vdots\\\\1&0.0153\\\\1&0.0150\\end{array}\\right]}_{\\!\\!\\!\\!\\!\\!\\!\\!{\\large\\mathit{A}} = \\left[\\strut f(\\mathtt{time})\\,,\\ \\ \\ g(\\mathtt{time})\\right]} \\underbrace{\\left[\\begin{array}{r}C\\\\D\\end{array}\\right]}_{\\large\\vec{x}} \\ \\text{is the best match to}\\  \\underbrace{\\left[\\begin{array}{r}\\mathtt{98.2}\\\\\\mathtt{94.4}\\\\\\mathtt{91.4}\\\\\\vdots\\\\\\mathtt{25.9}\\\\\\mathtt{25.8}\\end{array}\\right]}_{\\large\\vec{b}}\\]\nRegrettably, the classical algebraicists did not propose a rule for “is the best match to.” Replacing “is the best match to” with \\(=\\) is not literally correct since “there is no solution” that makes the equality literally true.\nWe will use the term target problem to name the task of finding \\(\\vec{x}\\) such that \\(\\mathit{A} \\vec{x}\\) is the best possible match to \\(\\vec{b}\\). This term is motivated by the idea that \\(\\vec{b}\\) is a target, and we seek to use the resources in \\(\\mathit{A}\\) to get as close as possible to the target: choose \\(\\vec{x}\\) such that \\(\\mathit{A} \\vec{x}\\) falls as closely as possible to the target.\nTo address the practical problem in the notation of algebra theory, people write \\[\\mathit{A} \\vec{x} = \\vec{b} - \\vec{r}\\] where \\(\\vec{r}\\) is a vector specially selected to path up \\(\\mathit{A} \\vec{x} = \\vec{b}\\) so that when the best-matching \\(C\\) and \\(D\\) are found, there will be a literal equality solution to \\(\\mathit{A} \\vec{x} = \\vec{b} - \\vec{r}\\).\nAt first glance, \\(\\mathit{A} \\vec{x} = \\vec{b} - \\vec{r}\\) might seem intractable: How are we to find \\(\\vec{r}\\). The answer is that \\(\\vec{r}\\) will be the solution to the projection problem \\(\\vec{b}\\sim\\mathit{A}\\). When \\(\\vec{r}\\) is selected this way, \\(\\vec{r}\\) will be the shortest possible vector that can do the matching up. In other words, by choosing \\(\\vec{r} = \\vec{b} \\sim \\mathit{A}\\) we are implementing the following definition of “is the best match to”: “the best match is the one with the smallest length \\(\\vec{r}\\).”\nIt is remarkable that one can find \\(\\vec{r}\\) even without knowing \\(\\vec{x}\\). That is why we introduced and solved the projection problem before taking on the target problem.\nThe part of the target problem that we have still to figure out is how, given \\(\\vec{r}\\), to find \\(\\vec{x}\\). But even at this point you can see that \\(\\mathit{A}\\vec{x} = \\vec{b} - \\vec{r}\\) must have a solution, since \\(\\vec{b} - \\vec{r}\\) is exactly the model vector \\(\\hat{b}\\) which, as we saw in Chapter 31), must lie in \\(span{\\mathit{A}}\\).",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>The target problem</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html#visualization-in-a-two-dimensional-subspace",
    "href": "Linear-combinations/B5-target-problem.html#visualization-in-a-two-dimensional-subspace",
    "title": "32  The target problem",
    "section": "32.2 Visualization in a two-dimensional subspace",
    "text": "32.2 Visualization in a two-dimensional subspace\nTo help you create a mental model of the geometry of the target problem, we will solve it graphically for a two dimensional subspace. That is, we will solve \\(\\left[\\vec{u}, \\vec{v}\\right] \\vec{x} = \\vec{b}\\). For simplicity, the vectors \\(\\vec{u}\\), \\(\\vec{v}\\) and \\(\\vec{b}\\) will have two components. This means that there is no need to project \\(\\vec{b}\\) onto the subspace; it is already there (so long as \\(\\vec{u}\\) and \\(\\vec{v}\\) have different directions. )\nYou may already have encountered the step (ii) technique in your childhood reading. The problem appears in Robert Louis Stevenson’s famous novel, Treasure Island. The story is about the discovery of a treasure map indicating the location of buried treasure on the eponymous Island. There is a red X on the map labelled “bulk of treasure here,” but that is hardly sufficient to guide the dig for treasure. After all, every buried treasure needs some secret to protect it. On the back of the map is written a cryptic clue to the precise location:\n\nTall tree, Spy-glass shoulder, bearing a point to the N. of N.N.E.\nSkeleton Island E.S.E. and by E.\nTen feet.\n\nSkeleton Island is marked on the map, as is Spy-glass Hill. The plateau marked by the red X “was dotted thickly with pine-trees of varying height. Every here and there, one of a different species rose forty or fifty feet clear above its neighbors.” But which of these was the “tall tree” mentioned in the clue?\n\n\n\n\n\n\n\n\nFigure 32.1: The map of Treasure Island. The heading ‘E.S.E. and by E.’ is marked with a solid black line starting at Skeleton Island. The heading ‘N. of N.N.E.’ is marked by dotted lines, one of which is positioned to point at the shoulder of Spy-glass Hill. Where the bearing from Skeleton Island meets the bearing to Spy-glass Hill will be the Tall tree.\n\n\n\n\n\nWith your new-found background in vectors, you will no doubt recognize that “N. of N.N.E” is the direction of a vector as is “E.S.E. and by E.” Pirate novels seem always to use the length unit of “pace,” which we will use here as well. The target is the shoulder of Spy-glass Hill. Or, in vector terms, \\(\\vec{b}\\) is the vector with Skeleton Island as the tail and the should of Spy-glass Hill as the tip. The vectors are \\(\\vec{u} = \\text{N. of N.N.E.}\\) and \\(\\vec{v} = \\text{E.S.E. and by E.}\\) We need to \\[\\text{solve} \\ \\ \\underbrace{\\left[\\vec{u}, \\vec{v}\\right]}_{\\Large\\strut\\mathit{A}} \\underbrace{\\small\\left[\\begin{array}{c}C\\\\D\\end{array}\\right]}_{\\Large\\vec{x}} = \\vec{b}\\ \\ \\text{for}\\ \\ {\\small\\left[\\begin{array}{c}C\\\\D\\end{array}\\right]}\\ .\\]\nLong John Silver, obviously an accomplished mathematician, starts near Skeleton Island, moving on along the vector that keeps Skeleton Island to the compass bearing one point east of east-south-east. While on the march, he keeps a telescope trained on the shoulder of Spy-glass Hill. When that telescope points one point north of north-north-east, they are in the vicinity of a tall tree. That is the tree matching the clue.\nThe vectors in Treasure Island were perpendicular to one another, that is, mutually orthogonal. The more general situation is that the vectors in \\(\\mathit{A}\\) will be somewhat aligned with one another: not mutually orthogonal. Figure 32.2 illustrates the situation: \\(\\vec{v}\\) is not perpendicular to \\(\\vec{u}\\). The task, still, is to find a linear combination of \\(\\vec{u}\\) and \\(\\vec{v}\\) that will match \\(\\vec{b}\\). The diagram shows the \\(\\vec{u}\\) vector and the subspace aligned with \\(\\vec{u}\\), and similarly for \\(\\vec{v}\\)\n\n\n\n\n\n\nFigure 32.2: The telescope method of solving projection onto two vectors.\n\n\n\nThe algorithm is based in Long John Silver’s technique. Pick either \\(\\vec{u}\\) or \\(\\vec{v}\\), it does not matter which. In the diagram, we’ve picked \\(\\vec{v}\\). Align your telescope with that vector. Now march along the other vector, \\(\\vec{u}\\), carefully keeping the telescope on the bearing aligned with \\(\\vec{v}\\). From the diagram, you can see that when you’ve marched to \\(\\frac{1}{2} \\vec{u}\\), the telescope does not yet have \\(\\vec{b}\\) in view. Similarly, at \\(1 \\vec{u}\\), the target \\(\\vec{b}\\) isn’t yet visible. Marching a little further, to about \\(1.6 \\vec{u}\\) brings you to the point in the \\(\\vec{u}\\)-subspace where the target falls into view. This tells us that the coefficient on \\(\\vec{u}\\) will be 1.6.\nTo find the coefficient on \\(\\vec{v}\\), you will need to march along the line of the telescope, taking steps of size \\(\\|\\vec{v}\\|\\). In the diagram, we’ve marked the march with copies of \\(\\vec{v}\\) to make the counting easier. We will need to march opposite the direction of \\(\\vec{v}\\), so the coefficient will be negative. Taking 2.8 steps of size \\(\\|\\vec{v}\\|\\) brings us to the target. Thus:\n\\[\\vec{b} = 1.6 \\vec{u} - 2.8 \\vec{v}\\ .\\]\nTo handle vectors in spaces where telescopes are not available, we need an arithmetic algorithm. In R, that algorithm is packaged up as qr.solve(). We will pick this up again the next section.\n\nIn 3-dimensional space, visualization of the solution to the target problem is possible, at least for those who have the talent of rotating three-dimensional objects in their head. For the rest of us, a physical model can help; take three pencils labeled \\(\\vec{u}\\), \\(\\vec{v}\\), and \\(\\vec{b}\\) and bury their tails in a small ball of putty. (Chemistry molecular construction kits are a good alternative.)\nIn case putty, pencils, or a molecular model kit are not available, use the interactive diagram in Figure 32.3. This diagram also includes \\(\\hat{b}\\) and \\(\\vec{r}\\) with the hope that this will guide you into orienting the diagram appropriately to see where the solution comes from.\n\n\n\n\n\n\n\n\n\nFigure 32.3: Showing the relative orientation of the three vectors \\(\\\\vec{u}\\), \\(\\\\vec{v}\\) and \\(\\\\vec{b}\\). Drag the image to rotate it.\n\n\n\n\\(\\vec{u}\\) and \\(\\vec{v}\\) are fixed in length. However, their lengths will appear to change as you rotate the space. This might be called the “gun-barrel” effect; a tube looks very short when you look down its longitudinal axis, but looks longer when you look at it from the side. Rotate the space until both \\(\\vec{u}\\) and \\(\\vec{v}\\) reach their maximum apparent length. The viewpoint that accomplishes this is looking downward perpendicularly onto the \\(\\left[\\vec{u},\\vec{v}\\right]\\)-plane. In this orientation, you will be looking down the barrel of the \\(\\vec{r}\\) gun. Vector \\(\\vec{b}\\) is not in that plane, as you can confirm by rotating the plot a bit out of the \\(\\left[\\vec{u},\\vec{v}\\right]\\)-plane. Returning to the perspective looking down perpendicularly on the place, you can see how \\(\\vec{b}\\) corresponds to \\(\\hat{b}\\), the point in the plane where the projection of \\(\\vec{b}\\) will fall.\nTo find the scalar multiplier on \\(\\vec{v}\\), rotate the space until the vector \\(\\vec{u}\\) is pointing straight toward you. You will see only the arrowhead of \\(\\vec{u}\\). Vectors \\(\\vec{v}\\) and \\(\\hat{b}\\) will appear parallel to each other, but that is because you are looking at the plane edge on. In this orientation, \\(\\hat{b}\\) will appear just a little longer than \\(\\vec{v}\\), perhaps 1.2 times longer. So 1.2 is the scalar multiplier on \\(\\vec{v}\\).\nTo figure out the scalar multiplier on \\(\\vec{u}\\), follow the same procedure as in the previous paragraph, but looking down the barrel of \\(\\vec{v}\\). From this perspective, \\(\\vec{u}\\) appears longer than \\(\\hat{b}\\); the scalar multiplier on \\(\\vec{u}\\) will be about 0.9. In terms of \\(\\mathit{A} \\vec{x} = \\hat{b}\\), the solution is \\[\\vec{x} = \\left[\\begin{array}{r}0.9\\\\1.2\\end{array}\\right]\\ .\\]",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>The target problem</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html#properties-of-the-solution",
    "href": "Linear-combinations/B5-target-problem.html#properties-of-the-solution",
    "title": "32  The target problem",
    "section": "32.3 Properties of the solution",
    "text": "32.3 Properties of the solution\nAs you might expect, there is a known solution to the target problem. We will start by using a computer implementation of this solution to demonstrate some simple properties of the solution. As an example, we will use three vectors \\(\\vec{u}\\), \\(\\vec{v}\\), and \\(\\vec{w}\\) in a 5-dimensional space as the “screen” to be projected onto, and another vector \\(\\vec{b}\\) as the object being projected.\nThe matrix \\(\\mathit{A}\\) is: \\[{\\mathbf A} \\equiv \\left[\\strut \\begin{array}{ccc}|&|&|\\\\\\vec{u} & \\vec{v} & \\vec{w}\\\\|&|&|\\end{array}\\right]\\]\nFor the sake of example, we will make up some vectors. In your own explorations, you can change them to anything you like.\n\n# the three vectors\nu &lt;- rbind(6, 4, 9, 3, 1)\nv &lt;- rbind(1, 5,-2, 0, 7)\nw &lt;- rbind(3,-5, 2, 8, 4)\nA &lt;- cbind(u, v, w)\n# the target\nb &lt;- rbind(8, 2,-5, 7, 0)\n\nThe operator %onto% model vector and from that we can calculate the residual vector.\n\ns &lt;- b %onto% A \nr &lt;- b - s\n\nThose two simple commands constitute a complete solution to the projection problem, where see seek to model vector and the residual vector.\nIn the target problem we want more: How to express \\(\\hat{b}\\) as a linear combination of the columns in \\(\\mathit{A}\\). At the risk of being repetitive, this means finding \\(\\color{magenta}{\\vec{x}}\\) in \\[\\mathit{A}\\ \\color{magenta}{\\large\\vec{x}} = \\vec{b}\\] where \\(\\mathit{A}\\) and \\(\\vec{b}\\) are given.\nThe function qr.solve() finds \\(\\vec{x}\\).\n\nx &lt;- qr.solve(A, b)\n\n\n##            [,1]\n## [1,] 0.03835171\n## [2,] 0.33478133\n## [3,] 0.48849968\n\nHow can we confirm that this really is the solution to the target problem for this set of vectors? Easy! Just multiply \\(\\mathit{A}\\) by the \\(\\vec{x}\\) that we found. The result should be the target vector \\(\\hat{b}\\):\n\nA %*% x\n##            [,1]\n## [1,]  2.0303906\n## [2,] -0.6151849\n## [3,]  0.6526021\n## [4,]  4.0230526\n## [5,]  4.3358197\ns\n##            [,1]\n## [1,]  2.0303906\n## [2,] -0.6151849\n## [3,]  0.6526021\n## [4,]  4.0230526\n## [5,]  4.3358197\n\n\n\n\n\n\n\nTip\n\n\n\nYou should add qr.solve() to your computational toolbox of R functions.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>The target problem</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html#application-of-the-target-problem",
    "href": "Linear-combinations/B5-target-problem.html#application-of-the-target-problem",
    "title": "32  The target problem",
    "section": "32.4 Application of the target problem",
    "text": "32.4 Application of the target problem\nIn Section 32.1 we translated into vector/matrix form the problem, originally stated in Block 1, of finding the best linear combination of \\(f(\\mathtt{time}) \\equiv 1\\) and \\(g(\\mathtt{time}) \\equiv e^{-0.019 \\mathtt{time}}\\). Let’s solve that problem now.\n\nEarlier we introduced rbind() for the purpose of making column vectors, as in\n\nrbind(3,7,-1)\n##      [,1]\n## [1,]    3\n## [2,]    7\n## [3,]   -1\n\nNow we will work with columns of data stored in the CoolingWater data frame. A good way to extract a column from a data frame is using the with() function. For instance,\n\nb &lt;- with(CoolingWater, temp)\ntime &lt;- with(CoolingWater, time)\nA &lt;- cbind(1, exp(-0.019 * time))\nhead(A)\n##      [,1]      [,2]\n## [1,]    1 1.0000000\n## [2,]    1 0.9811794\n## [3,]    1 0.9627129\n## [4,]    1 0.9445941\n## [5,]    1 0.9268162\n## [6,]    1 0.9093729\n\nNotice that cbind() automatically translated 1 into the vector of all ones.\nWe are all set up to solve the target problem:\n\nx &lt;- qr.solve(A, b)\n\n\n## [1] 25.92024 61.26398\n\nHow good an answer is the x calculated by qr.solve()? Judge for yourself!\n\ngf_point(temp ~ time, data = CoolingWater, size=0) %&gt;%\n  slice_plot(25.92 + 61.26*exp(-0.019*time) ~ time,\n             color=\"blue\")\n\n\n\n\n\n\n\n\nYou may recall from Block 1 the explanation for the poor match between the model and the data for early times: that the water cooled quickly when poured into the cool mug, but the mug-with-water cooled much slower into the room air.\nLet’s augment the model by adding another vector with a much faster exponential cooling, say, \\(e^{-0.06 \\mathtt{time}}\\).\n\nnewA &lt;- cbind(A, exp(-0.06*time))\nqr.solve(newA, b)\n## [1] 26.82297 53.27832 12.67486\n\n\ngf_point(temp ~ time, data = CoolingWater, size=0) %&gt;%\n  slice_plot(26.82 + 53.28*exp(-0.019*time) +\n               12.67*exp(-0.06*time) ~ time,\n             color=\"green\")",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>The target problem</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-stat-modeling.html",
    "href": "Linear-combinations/B5-stat-modeling.html",
    "title": "33  Statistical modeling and R2",
    "section": "",
    "text": "33.1 How good a model?\nThere are so many ways to construct a linear-combination model from a data frame—all the different combinations of columns plus possibly interaction terms and other transformations—that it is natural to ask, “What’s the best model?”\nAs always, “best” depends on the purpose for your model is to be used. This requires thought on the part of the modeler. One method you will often encounter is called R-squared and written R2.\nThe basic question addressed by R2 is: How much of the variation in the response variable b is accounted for by the columns of the matrix A. The standard way to measure the “amount of variation” in a variable is the variance. In R, you calculate that with\nWe can also look at the variation in the model vector, \\(\\hat{b}\\).\nR2 is simply the ratio of these two variances:\nThis result, 31.7%, is interpreted as the fraction of the variance in the response variable that is accounted for by the model. Near synonyms for “accounted for” are “explained by” or “can be attributed to.”\nIn the same spirit, we can ask how much of the variance in the response variable is unexplained or unaccounted for by the explanatory variables . To answer this, look at the size of the residual:\nNotice that the amount of variance explained, 68.3%, plus the amount remaining unexplained, 31.7%, add up to 100%. This is no accident. The additivity is why statisticians use the variance as a measure of variability.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Statistical modeling and R^2^</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-stat-modeling.html#how-good-a-model",
    "href": "Linear-combinations/B5-stat-modeling.html#how-good-a-model",
    "title": "33  Statistical modeling and R2",
    "section": "",
    "text": "Please enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Statistical modeling and R^2^</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-stat-modeling.html#machine-learning",
    "href": "Linear-combinations/B5-stat-modeling.html#machine-learning",
    "title": "33  Statistical modeling and R2",
    "section": "33.2 Machine learning",
    "text": "33.2 Machine learning\nIf you pay attention to trends, you will know about advances in artificial intelligence and the many claims—some hype, some not—about how it will change everything from animal husbandry to warfare. Services such as Google Translate are based on artificial intelligence, as are many surveillance technologies. (Whether the surveillance is for good or ill is a serious matter.)\nSkills in artificial intelligence are currently a ticket to lucrative employment.\nLike so many things, “artificial intelligence” is a branding term. In fact, what all the excitement is about is not mostly artificial intelligence at all. The advances, by and large, have come over 50 years of development in a field called “statistical learning” or “machine learning,” depending on whether the perspective is from statistics or computer science.\nA major part of the mathematical foundation of statistical (or “machine”) learning is linear algebra. Many workers in “artificial intelligence” are struggling to catch up because they never took linear algebra in college or, if they did, they took a proof-oriented course that didn’t cover the elements of linear algebra that are directly applicable. We are trying to do better in this course.\nSo if you’re diligent, and continue your studies to take actual statistical/machine learning courses, you will find yourself at the top of the heap. Even xkcd, the beloved techno-comic, gets in on the act, as this cartoon reveals:\n\n\n\n\n\n\n\n\n\nLook carefully below the paddle and you will see the Greek letter “lambda”, \\(\\lambda\\). You will meet the linear algebra concept signified by \\(\\lambda\\)—eigenvalues and eigenvectors—in Block 6.\n\n\n\n\n\n\nTip\n\n\n\nWe’ve been using the R/mosaic function df2matrix() to construct the A and b matrices used in linear model from data. This is mainly for convenience: we need a way to carry out the calculations that lets you see the x vector, and calculate the model vector and the residual in the way described in Chapter 32.\nIn practice, statistical modelers use other software. The most famous of these in R is the lm() family of functions. This does all the work of creating the b vector and the A matrix, QR solving, etc. We call it a “family” of functions because the output of lm() is not simply the vector of coefficients x but includes many other features that support statistical inference on the models created.\nIn a statistics course using R, you are very likely to encounter lm(). You will never hear about df2matrix() outside of this book.",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Statistical modeling and R^2^</span>"
    ]
  },
  {
    "objectID": "Linear-combinations/B5-stat-modeling.html#footnotes",
    "href": "Linear-combinations/B5-stat-modeling.html#footnotes",
    "title": "33  Statistical modeling and R2",
    "section": "",
    "text": "Amazingly, this work attracted little attention until after 1900, when Mendel’s laws were rediscovered by the botanists de Vries, Correns, and von Tschermak.↩︎",
    "crumbs": [
      "BLOCK III. Vectors and linear combinations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Statistical modeling and R^2^</span>"
    ]
  },
  {
    "objectID": "Accumulation/35-integration.html",
    "href": "Accumulation/35-integration.html",
    "title": "36  Integration",
    "section": "",
    "text": "36.1 Net change\nPerhaps it goes without saying, but once you have the CAPITAL LETTER function, e.g. \\(F(t)\\), you can evaluate that function at any input that falls into the domain of \\(F(t)\\). If you have a graph of \\(F(t)\\) versus \\(t\\), just position your finger on the horizontal axis at input \\(t_1\\), then trace up to the function graph, then horizontally to the vertical axis where you can read off the value \\(F(t_1)\\). If you have \\(F()\\) in the form of a computer function, just apply \\(F()\\) to the input \\(t_1\\).\nIn this regard, \\(F(t)\\) is like any other function.\nHowever, in using and interpreting the \\(F(t)\\) that we constructed by anti-differentiating \\(f(t)\\), we have to keep in mind the limitations of the anti-differentiation process. In particular, any function \\(f(t)\\) does not have a unique anti-derivative function. If we have one anti-derivative, we can always construct another by adding some constant: \\(F(t) + C\\) is also an anti-derivative of \\(f(t)\\).\nBut we have a special purpose in mind when calculating \\(F(t_1)\\). We want to figure out from \\(F(t)\\) how much of the quantity \\(f(t)\\) has accumulated up to time \\(t_1\\). For example, if \\(f(t)\\) is the rate of increase in fuel (that is, the negative of fuel consumption), we want \\(F(t_1)\\) to be the amount of fuel in our tank at time \\(t_1\\). That cannot happen. All we can say is that \\(F(t_1)\\) is the amount of fuel in the tank at \\(t_1\\) give or take some unknown constant C.\nInstead, the correct use of \\(F(t)\\) is to say how much the quantity has changed over some interval of time, \\(t_0 \\leq t \\leq t_1\\). This “change in the quantity” is called the net change in \\(F()\\). To calculate the net change in \\(F()\\) from \\(t_0\\) to \\(t_1\\) we apply \\(F()\\) to both \\(t_0\\) and \\(t_1\\), then subtract:\n\\[\\text{Net change in}\\ F(t) \\ \\text{from}\\ t_0 \\ \\text{to}\\ t_1 :\\\\= F(t_1) - F(t_0)\\] ::: {#try-accumulate-force style=“display: none;”} ::: ::: {.callout-important icon=false} ## ?try-accumulate-force Momentum, force, energy Suppose you have already constructed the rate-of-change function for momentum \\(m()\\) and implemented it as an R function m(). For instance, \\(m(t)\\) might be the amount of force at any instant \\(t\\) of a car, and \\({\\mathbf M}(t)\\) is the force accumulated over time, better known as momentum. We will assume that the input to m() is in seconds, and the output is in kg-meters-per-second-squared, which has the correct dimension for force.\nYou want to find the amount of force accumulated between time \\(t=2\\) and \\(t=5\\) seconds.\nTo make use of this quantity, you will need to know its dimension and units. For this example, where the dimension [\\(m(t)\\)] is M L T\\(^{-2}\\), and [\\(t\\)] = T, the dimension [\\({\\mathbf M}(t)\\)] will be M L T\\(^{-1}\\). In other words, if the output of \\(m(t)\\) is kg-meters-per-second-squared, then the output of \\(V(t)\\) must be kg- meters-per-second. :::",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "Accumulation/35-integration.html#net-change",
    "href": "Accumulation/35-integration.html#net-change",
    "title": "36  Integration",
    "section": "",
    "text": "Please enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "Accumulation/35-integration.html#the-definite-integral",
    "href": "Accumulation/35-integration.html#the-definite-integral",
    "title": "36  Integration",
    "section": "36.2 The “definite” integral",
    "text": "36.2 The “definite” integral\nWe have described the process of calculating a net change from the lower-case function \\(f(t)\\) in terms of two steps:\n\nConstruct \\(F(t) = \\int f(t) dt\\).\nEvaluate \\(F(t)\\) at two inputs, e.g. \\(F(t_2) - F(t_1)\\), giving a net change, which we will write as \\({\\cal F}(t_1, t_2) = F(t_2) - F(t_1)\\).\n\nAs a matter of notation, the process of going from \\(f(t)\\) to the net change is written as one statement. \\[{\\cal F}(t_1, t_2) = F(t_2) - F(t_1) = \\int_{t_1}^{t_2} f(t) dt\\]\nThe punctuation \\[\\int_{t_1}^{t_2} \\_\\_\\_\\_ dt\\] captures in one construction both the anti-differentiation step (\\(\\int\\_\\_dt\\)) and the evaluation of the anti-derivative at the two bound \\(t_2\\) and \\(t_1\\).\nSeveral names are used to describe the overall process. It is important to become familiar with these.\n\n\\(\\int_a^b f(t) dt\\) is called a definite integral of \\(f(t)\\).\n\\(a\\) and \\(b\\) are called, respectively, the lower bound of integration and the upper bound of integration, although given the way we draw graphs it might be better to call them the “left” and “right” bounds, rather than lower and upper.\nThe pair \\(a, b\\) is called the bounds of integration.\n\nAs always, it pays to know what kind of thing is \\({\\cal F}(t_1, t_2)\\). Assuming that \\(t_1\\) and \\(t_2\\) are fixed quantities, say \\(t_1 = 2\\) seconds and \\(t_2 = 5\\) seconds, then \\({\\cal F}(t_1, t_2)\\) is itself a quantity. The dimension of that quantity is [\\(F(t)\\)] which in turn is [\\(f(t)\\)]\\(\\cdot\\)[\\(t\\)]. So if \\(f(t)\\) is fuel consumption in liters per second, then \\(F(t)\\) will have units of liters, and \\({\\cal F}(t_1, t_2)\\) will also have units of liters.\nRemember also an important distinction:\n\n\\(F(t) = \\int f(t) dt\\) is a function whose output is a quantity.\n\\(F(t_2) - F(t_1) = \\int_{t_1}^{t_2} f(t) dt\\) is a quantity, not a function.\n\nOf course, \\(f(t)\\) is a function whose output is a quantity. In general, the two functions \\(F(t)\\) and \\(f(t)\\) produce outputs that are different kinds of quantities. For instance, the output of \\(F(t)\\) is liters of fuel while the output of \\(f(t)\\) is liters per second: fuel consumption. Similarly, the output of \\(S(t)\\) is dollars, while the output of \\(s(t)\\) is dollars per day.\nThe use of the term definite integral suggests that there might be something called an indefinite integral, and indeed there is. “Indefinite integral” is just a synonym for “anti-derivative.” In this book we favor the use of anti-derivative because it is too easy to leave off the “indefinite” and confuse an indefinite integral with a definite integral. Also, “anti-derivative” makes it completely clear what is the relationship to “derivative.”\nSince 1700, it is common for calculus courses to be organized into two divisions:\n\nDifferential calculus, which is the study of derivatives and their uses.\nIntegral calculus, which is the study of anti-derivatives and their uses.\n\nMathematical notation having been developed for experts rather than for students, very small typographical changes are often used to signal very large changes in meaning. When it comes to anti-differentiation, there are two poles of fixed meaning and then small changes which modify the meaning. The poles are:\n\nAnti-derivative: \\(\\int f(t) dt\\), which is a function whose output is a quantity.\nDefinite integral \\(\\int_a^b f(t) dt\\), which is a quantity, plain and simple.\n\nBut you will also see some intermediate forms:\n\n\\(\\int_a^t f(t) dt\\), which is a function with input \\(t\\).\n\\(\\int_a^x f(t) dt\\), which is the same function as in (a) but with the input name \\(x\\) being used.\n\\(\\int_t^b f(t) dt\\), which is a function with input \\(t\\).\nLess commonly, \\(\\int_x^t f(t) dt\\) which is a function with two inputs, \\(x\\) and \\(t\\). The same is true of \\(\\int_x^y f(t) dt\\) and similar variations.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "Accumulation/35-integration.html#initial-value-of-the-quantity",
    "href": "Accumulation/35-integration.html#initial-value-of-the-quantity",
    "title": "36  Integration",
    "section": "36.3 Initial value of the quantity",
    "text": "36.3 Initial value of the quantity\nRecall that we are interested in a real quantity \\({\\mathbf F}(t)\\), but we only know \\(f(t)\\) and from that can calculate an anti-derivative \\(F(t)\\). The relationship between them is \\[{\\mathbf F}(t) = F(t) + C\\] where \\(C\\) is some fixed quantity that we cannot determine directly from \\(f(t)\\).\nStill, even if we cannot determine \\(C\\), there is one way we can use \\(F(t)\\) to make definite statements about \\({\\mathbf F}(t)\\). Consider the net change from \\(t_1\\) to \\(t_2\\) in the real quantity \\({\\mathbf F}\\). This is \\[{\\mathbf F}(t_2) - {\\mathbf F}(t_1) =  \\left[F(t_2) + C\\right] - \\left[F(t_1) + C\\right] = F(t_2) - F(t_1)\\] In other words, just knowing \\(F(t)\\), we can make completely accurate statements about net changes in the value of \\({\\mathbf F}(t)\\).\nLet’s develop our understanding of this unknown constant \\(C\\), which is called the constant of integration. To do so, watch the movie in Figure 36.1 showing the process of constructing the anti-derivative \\[F(t) = \\int_2^t f(t) dt\\ .\\]\n\n\n\n\n\n\n\n\nFigure 36.1: Constructing the anti-derivative \\(F(t)\\) by reading the slope from \\(f(t)\\) and using that slope to extend the picture of \\(F()\\)\n\n\n\n\n\n\nFocus first on the top graph. The function we are integrating, \\(f(t)\\), is known before we carry out the integration, so it is shown in the top graph.\n\n\\(f(t)\\) is the rate of increase in \\(F(t)\\) (or \\({\\mathbf F}(t)\\) for that matter). From the graph, you can read using the vertical axis the value of \\(f(t)\\) for any input \\(t\\). But since \\(f(t)\\) is a rate of increase, we can also depict \\(f(t)\\) as a slope. That slope is being drawn as a \\(\\color{magenta}{\\text{magenta}}\\) arrow. Notice that when \\(f(t)\\) is positive, the arrow slopes upward and when \\(f(t)\\) is negative, the arrow slopes downward. The steepness of the arrow is the value of \\(f(t)\\), so for inputs where the value of \\(f(t)\\) is far from zero the arrow is steeper than for values of \\(f(t)\\) that are near zero.\n\nNow look at both graphs, but concentrate just on the arrows in the two graphs. They are always the same: carbon copies of one another.\nFinally the bottom graph. We are starting the integral at \\(t_1=2\\). Since nothing has yet been accumulated, the value \\(F(t_1 = 2) = 0\\). From (1) and (2), you know the arrow shows the slope of \\(F(t)\\). So as \\(F(t&gt;2)\\) is being constructed the arrow guides the way. When the slope arrow is positive, \\(F(t)\\) is growing. When the slope arrow is negative, \\(F(t)\\) is going down.\n\nIn tallying up the accumulation of \\(f(t)\\), we started at time \\(t=2\\) and with \\(F(t=2) = 0\\). This makes sense, since nothing can be accumulated over the mere instant of time from \\(t=2\\) to \\(t=2\\). On the other hand, it was our choice to start at \\(t=2\\). We might have started at another value of \\(t\\) such as \\(t=0\\) or \\(t=-5\\) or \\(t=-\\infty\\). If so, then the accumulation of \\(f(t)\\) up to \\(t=2\\) would likely have been something other than zero.\nBut what if we knew an actual value for \\({\\mathbf F}(2)\\). This is often the case. For instance, before taking a trip you might have filled up the fuel tank. The accumulation of fuel consumption only tells you how much fuel has been used since the start of the trip. But if you know the starting amount of fuel, by adding that to the accumulation you will know instant by instant how much fuel is in the tank. In other words, \\[{\\mathbf F}(t) = {\\mathbf F}(2) + \\int_2^t f(t) dt\\ .\\] This is why, when we write an anti-derivative, we should always include mention of some constant \\(C\\)—the so-called constant of integration—to remind us that there is a difference between the \\(F(t)\\) we get from anti-differentiation and the \\({\\mathbf F}(t)\\) of the function we are trying to reconstruct. That is, \\[{\\mathbf F}(t) = F(t) + C = \\int f(t) dt + C\\ .\\] We only need to know \\({\\mathbf F}(t)\\) at one point in time, say \\(t=0\\), to be able to figure out the value of \\(C\\): \\[C = {\\mathbf F}(0) - F(0)\\ .\\]\nAnother way to state the relationship between the anti-derivative and \\({\\mathbf F}(t)\\) is by using the anti-derivative to accumulate \\(f(t)\\) from some starting point \\(t_0\\) to time \\(t\\). That is: \\[{\\mathbf F}(t) \\ =\\  {\\mathbf F}(t_0) + \\int_{t_0}^t f(t)\\, dt\\  = \\\n{\\mathbf F}(t_0) + \\left({\\large\\strut}F(t) - F(t_0)\\right)\\]\n\n\n\n\n\n\nCalculus history—Galileo in Pisa\n\n\n\nAn oft-told legend has Galileo at the top of the Tower of Pisa around 1590. The legend illustrates Galileo’s finding that a light object (e.g. a marble) and a heavy object (e.g. a ball) will fall at the same speed. Galileo published his mathematical findings in 1638 in Discorsi e Dimostrazioni Matematiche, intorno a due nuove scienze. (English: Discourses and Mathematical Demonstrations Relating to Two New Sciences)\nIn 1687, Newton published his world-changingPhilosophiae Naturalis Principia Mathematica. (English: Mathematical Principles of Natural Philosophy)\nLet’s imagine the ghost of Galileo returned to Pisa in 1690 after reading Newton’s Principia Mathematica. In this new legend, Galileo holds a ball still in his hand, releases it, and figures out the position of the ball as a function of time.\nAlthough Newton famously demonstrated that gravitational attraction is a function of the distance between to objects, he also knew that at a fixed distance—the surface of the Earth—gravitational acceleration was constant. So Galileo was vindicated by Newton. But, although gravitational acceleration is constant from top to bottom of the Tower of Pisa, Galileo’s ball was part of a more complex system: a hand holding the ball still until release. Acceleration of the ball versus time is therefore approximately a Heaviside function:\n\\(\\text{accel}(t) \\equiv \\left\\{\\begin{array}{rl}0 & \\text{for}\\ t \\leq 3\\\\\n{-9.8}  & \\text{otherwise}\\end{array}\\right.\\)\n\naccel &lt;- makeFun(ifelse(t &lt;= 3, 0, -9.8) ~ t)\n\nAcceleration is the derivative of velocity. We can construct a function \\(V(t)\\) as the anti-derivative of acceleration, but the real-world velocity function will be \\[{\\mathbf V}(t) = {\\mathbf V}(0) + \\int_0^t \\text{accel}(t) dt\\]\n\nV_from_antiD &lt;- antiD(accel(t) ~ t)\nV &lt;- makeFun(V0 + (V_from_antiD(t) - V_from_antiD(0)) ~ t, V0 = 0)\n\nIn the computer expression, the parameter V0 stands for \\({\\mathbf V}(0)\\). We’ve set it equal to zero since, at time \\(t=0\\), Galileo was holding the ball still.\nVelocity is the derivative of position, but the real-world velocity function will be the accumulation of velocity from some starting time to time \\(t\\), plus the position at that starting time: \\[x(t) \\equiv x(0) + \\int_0^t V(t) dt\\] We can calculate \\(\\int V(t) dt\\) easily enough with antiD(), but the function \\(x(t)\\) involves evaluating that anti-derivative at times 0 and \\(t\\):\n\nx_from_antiD &lt;- antiD(V(t) ~ t)\nx &lt;- makeFun(x0 + (x_from_antiD(t) - x_from_antiD(0)) ~ t, x0 = 53)\n\nWe’ve set the parameter x0 to be 53 meters, the height above the ground of the top balcony on which Galileo was standing for the experiment.\n\n\n\n\n\n\n\n\nFigure 36.2: The acceleration, velocity, and position of the ball as a function of time in Galileo’s Tower of Pisa experiment. The ball is released at time \\(t_0\\).\n\n\n\n\n\n\n\nIn the (fictional) account of the 1690 experiment, we had Galileo release the ball at time \\(t=0\\). That is a common device in mathematical derivations, but in a physical sense it is entirely arbitrary. Galileo might have let go of the ball at any other time, say, \\(t=3\\) or \\(t=14:32:05\\).\nA remarkable feature of integrals is that it does not matter what we use as the lower bound of integration, so long as we set the initial value to correspond to that bound.\n\n\n\n\n\n\nWhy \\(\\int f(x) dx\\) instead of \\(\\int f(t) dt\\)?\n\n\n\nFor a while you were writing integrals like this: \\(\\int_a^b f(t) dt\\). Then you replaced \\(b\\) with the input name \\(t\\) to get \\(\\int_a^t f(t) dt\\). But then you switched everything up by writing \\(\\int_a^t f(x) dx\\). Is that the same as \\(\\int_a^t f(t) dt\\)? If so, why do you get to replace the \\(t\\) with \\(x\\) in some places but not in others?\nRecall from Chapter 2 that the names used for inputs to a function definition don’t matter so long as they are used consistently on the left and right sides of \\(\\equiv\\). For instance, all these are the same function:\n\n\\(f(x) \\equiv m x + b\\)\n\\(g(t) \\equiv m t + b\\)\n\\(h(\\text{wind}) \\equiv m \\text{wind} + b\\)\n\nNow think about the integral \\(\\int_a^b f(t) dt\\): \\[\\int_a^b f(t) dt = F(b) - F(a)\\ .\\]\nOn the left-hand side, the input name \\(t\\) is prominent, appearing in two places: \\(f(\\color{magenta}{t}) d\\color{magenta}{t}\\). But \\(t\\) is nowhere on the right-hand side. We could have equally well written this as \\(\\int_a^b f(x) dx\\) or \\(\\int_a^b f(\\text{wind}) d\\text{wind}\\). The name we use for the input to \\(f()\\) does not matter so long as it is consistent with the name used in the \\(d\\_\\_\\) part of the notation. Often, the name placed in the blanks in \\(\\int f(\\_\\_) d\\_\\_\\) is called a dummy variable.\nWriting \\(\\int_a^t f(t) dt\\) is perfectly reasonable, but many authors dislike the multiple appearance of \\(t\\). So they write something like \\(\\int_a^t f(x) dx\\) instead.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "Accumulation/35-integration.html#integrals-from-bottom-to-top",
    "href": "Accumulation/35-integration.html#integrals-from-bottom-to-top",
    "title": "36  Integration",
    "section": "36.4 Integrals from bottom to top",
    "text": "36.4 Integrals from bottom to top\nThe bounds of integration appear in different arrangements. None of these are difficult to derive from the basic forms:\n\nThe relationship between an integral and its corresponding anti-derivative function: \\[\\int_a^b f(x) dx = F(b) - F(a)\\] This relationship has a fancy-sounding name: the second fundamental theorem of calculus.\nThe accumulation from an initial-value \\[{\\mathbf F}(b)\\  =\\  {\\mathbf F}(a) + \\int_a^b f(x) dx\\  = \\ {\\mathbf F}(a) + F(b) - F(a)\\] For many modeling situations, \\(a\\) and \\(b\\) are fixed quantities, so \\(F(a)\\) and \\(F(b)\\) are also quantities; the output of the anti-derivative function at inputs \\(a\\) and \\(b\\). But either the lower-bound or the upper-bound can be input names, as in \\[\\int_0^t f(x) dx = F(t) - F(0)\\]\n\nNote that \\(F(t)\\) is not a quantity but a function of \\(t\\).\nOn occasion, you will see forms like \\(\\int_t^0 f(x)dx\\). You can think of this in either of two ways:\n\nThe accumulation from a time \\(t\\) less than 0 up until 0.\nThe reverse accumulation from 0 until time \\(t\\).\n\nReverse accumulation can be a tricky concept because it violates everyday intuition. Suppose you were harvesting a row of ripe strawberries. You start at the beginning of the row—position zero. Then you move down the row, picking strawberries and placing them in your basket. When you have reached position \\(B\\) your basket holds the accumulation \\(\\int_0^B s(x)\\, dx\\), where \\(s(x)\\) is the lineal density of strawberries—units: berries per meter of row.\nBut suppose you go the other way, starting with an empty basket at position \\(B\\) and working your way back to position 0. Common sense says your basket will fill to the same amount as in the forward direction, and indeed this is the case. But integrals work differently. The integral \\(\\int_B^0 s(x) dx\\) will be the negative of \\(\\int_0^B s(x) dx\\). You can see this from the relationship between the integral and the anti-derivative: \\[\\int_B^0 s(x) dx \\ = \\ S(0) - S(B) \\ =\\ -\\left[{\\large\\strut}S(B) - S(0)\\right]\\ = \\ -\\int_0^B s(x) dx\\]\nThis is not to say that there is such a thing as a negative strawberry. Rather, it means that harvesting strawberries is similar to an integral in some ways (accumulation) but not in other ways. In farming, harvesting from 0 to \\(B\\) is much the same as harvesting from \\(B\\) to 0, but integrals don’t work this way.\nAnother property of integrals is that the interval between bounds of integration can be broken into pieces. For instance:\n\\[\\int_a^c f(x) dx \\ = \\ \\int_a^b f(x) dx + \\int_b^c f(x) dx\\] You can confirm this by noting that \\[\\int_a^b f(x) dx + \\int_b^c f(x) dx \\ = \\ \\left[{\\large\\strut}F(b) - F(a)\\right] + \\left[{\\large\\strut}F(c) - F(b)\\right] = F(c) - F(a) \\ = \\ \\int_a^c f(x) dx\\ .\\]\nFinally, consider this function of \\(t\\): \\[\\partial_t \\int_a^t f(x) dx\\ .\\] First, how do we know it is a function of \\(t\\)? \\(\\int_a^t f(x) dx\\) is a definite integral and has the value \\[\\int_a^t f(x) dx = F(t) - F(a)\\  .\\] Following our convention, \\(a\\) is a parameter and stands for a specific numerical value, so \\(F(a)\\) is the output of \\(F()\\) for a specific input. But according to convention \\(t\\) is the name of an input. So \\(F(t)\\) is a function whose output depends on \\(t\\). Differentiating the function \\(F(t)\\), as with every other function, produces a new function.\nSecond, there is a shortcut for calculating \\(\\partial_t \\int_a^t f(x) dx\\): \\[\\partial_t \\int_a^t f(x) dx\\ =\\ \\partial_t \\left[{\\large\\strut}F(t) - F(a)\\right]\\ .\\] Since \\(F(a)\\) is a quantity and not a function, \\(\\partial_t F(a) = 0\\). That simplies things. Even better, we know that the derivative of \\(F(t)\\) is simply \\(f(t)\\): that is just the nature of the derivative/anti-derivative relationship between \\(f(t)\\) and \\(F(t)\\). Put together, we have: \\[\\partial_t \\int_a^t f(x) dx\\ =\\ f(t)\\ .\\]\nThis complicated-looking identity has a fancy name: the first fundamental theorem of calculus.\n\n\n\n\n\n\nMath out of the World: Backtracking the stars\n\n\n\nIn the 1920s, astronomers and cosmologists questioned the idea that the large-scale universe is static and unchanging. This traditional belief was undermined both by theory (e.g. General Relativity) and observations. The most famous of these were collected and published by Edwin Hubble, starting in 1929 and continuing over the next decade as improved techniques and larger telescopes became available. In recent years, with the availability of the space telescope named in honor of Hubble data has expanded in availability and quality. Figure 36.3 shows a version of Hubble’s 1929 graph based on contemporary data.\n\n\n\n\n\n\n\n\nFigure 36.3: The relationship between velocity and distance of stars, using contemporary data in the same format at Edwin Hubble’s 1929 publication.\n\n\n\n\n\nEach dot in Figure 36.3 is an exploding star called a supernova. The graph shows the relationship between the distance of the star from our galaxy and the outward velocity of that star. The velocities are large, \\(3 \\times 10^4 = 30,000\\) km/s is about one-tenth the speed of light. Similarly, the distances are big; 600 Mpc is the same as 2 billion light years or \\(1.8 \\times 10^{22} \\text{km}\\). The slope of the line in Figure 36.3 is \\(\\frac{3.75 \\times 10^4\\, \\text{km/s}}{1.8 \\times 10^{22}\\, \\text{km}} = 2.1 \\times 10^{-18}\\, \\text{s}^{-1}\\). For ease of reading, we will call this slope \\(\\alpha\\) and therefore the velocity of a start distance \\(D\\) from Earth is \\[v(D) \\equiv \\alpha D\\ .\\]\nEarlier in the history of the universe each star was a different distance from Earth. We will call this function \\(D(t)\\), distance as a function of time in the universe.\nThe distance travelled by each star from time \\(t\\) (billions of years ago) to the present is \\[\\int_t^\\text{now} v(t) dt  = D_\\text{now} - D(t)\\] which can be re-arranged to give \\[D(t) = D_\\text{now} - \\int_t^\\text{now} v(t) dt .\\] Assuming that \\(v(t)\\) for each star has remained constant at \\(\\alpha D_\\text{now}\\), the distance travelled by each star since time \\(t\\) depends on its current distance like this: \\[\\int_t^\\text{now} v(t) dt = \\int_t^\\text{now} \\left[ \\alpha D_\\text{now}\\right]\\, dt = \\alpha D_\\text{now}\\left[\\text{now} - t\\right]\\] Thus, the position of each star at time \\(t\\) is \\[D(t) = D_\\text{now} - \\alpha D_\\text{now}\\left[\\text{now} - t\\right] = D(t)\\] or, \\[D(t) = D_\\text{now}\\left({\\large\\strut} 1-\\alpha \\left[\\text{now} - t\\right]\\right)\\]\nAccording to this model, there was a common time \\(t_0\\) when when all the stars were at the same place: \\(D(t_0) = 0\\). This happened when \\[\\text{now} - t_0 = \\frac{1}{\\alpha} = \\frac{1}{2.1 \\times 10^{-18}\\, \\text{s}^{-1}} = 4.8 \\times 10^{17} \\text{s}\\ .\\] It seems fair to call such a time, when all the stars where at the same place at the same time, as the origin of the universe. If so, \\(\\text{now} - t_0\\) corresponds to the age of the universe and our estimate of that age is \\(4.8\\times 10^{17}\\text{s}\\). Conventionally, this age is reported in years. To get that, we multiply by the flavor of one that turns seconds into years: \\[\\frac{60\\, \\text{seconds}}{1\\, \\text{minute}} \\cdot \\frac{60\\, \\text{minutes}}{1\\, \\text{hour}} \\cdot \\frac{24\\, \\text{hours}}{1\\, \\text{day}} \\cdot \\frac{365\\, \\text{days}}{1\\, \\text{year}} = 31,500,000 \\frac{\\text{s}}{\\text{year}}\\] The grand (but hypothetical) meeting of the stars therefore occurred \\(4.8 \\times 10^{17} \\text{s} / 3.15 \\times 10^{7} \\text{s/year} = 15,000,000,000\\) years ago. Pretty crowded to have all the mass in the universe in one place at the same time. No wonder they call it the Big Bang!",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "Accumulation/35-integration.html#footnotes",
    "href": "Accumulation/35-integration.html#footnotes",
    "title": "36  Integration",
    "section": "",
    "text": "Momentum is velocity times mass. Newton’s Second Law of Motion stipulates that force equals the rate of change of momentum.↩︎",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Integration</span>"
    ]
  },
  {
    "objectID": "Accumulation/36-functions.html",
    "href": "Accumulation/36-functions.html",
    "title": "37  Functions as vectors",
    "section": "",
    "text": "37.1 Dot product for functions\nGiven two functions, \\(f(t)\\) and \\(g(t)\\) defined over some domain \\(D\\), we will compute the dot product of the functions as a sum of the product of the two functions, that is: \\[f(t) \\bullet g(t) \\equiv \\int_{D} f(t)\\,g(t)\\,dt\\ .\\] ::: {#try-function-length style=“display: none;”} ::: ::: {.callout-important icon=false} ## ?try-function-length Function length Suppose that our two functions are \\(\\text{one}(t) \\equiv 1\\) and \\(\\text{identity}(t) \\equiv t\\) on the domain \\(0 \\leq t \\leq 1\\). Find the length of each function and the included angle between them.\nThe left panel of Figure 37.1 shows the functions \\(f(t) \\equiv t^2\\) and \\(\\color{magenta}{\\widehat{f(t)} \\equiv 1/3}\\) on the domain. The center panel shows the residual function, that is \\(f(t) - \\widehat{f(t)}\\). The right panel gives the square of the length of the residual function, which is \\(\\int_{-1}^1 \\left[f(t) - \\widehat{f(t)}\\right]^{1/2}\\, dt\\) as indicated by the area shaded in \\(\\color{blue}{\\text{blue}}\\).\nFigure 37.1: Projecting \\(f(t) \\equiv t^2\\) onto \\(g(t) \\equiv \\text{one}(t)\\).",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Functions as vectors</span>"
    ]
  },
  {
    "objectID": "Accumulation/36-functions.html#dot-product-for-functions",
    "href": "Accumulation/36-functions.html#dot-product-for-functions",
    "title": "37  Functions as vectors",
    "section": "",
    "text": "Length: \\(\\|\\text{one}(t)\\| = \\left[\\int_0^1 1 \\cdot 1\\,dt\\right]^{1/2} = \\left[\\ \\strut t\\left.{\\large\\strut}\\right|_0^1\\ \\right]^{1/2} = 1\\)\nLength: \\(\\|\\text{identity}(t)\\| = \\left[\\int_0^1 t \\cdot t\\,dt\\right]^{1/2} = \\left[\\ \\strut \\frac{1}{2}t^2\\left.{\\large\\strut}\\right|_0^1\\ \\right]^{1/2} = \\frac{1}{\\sqrt{2}}\\)\nIncluded angle: \\[\\cos(\\theta) = \\frac{\\text{one}(t) \\bullet \\text{identity}(t)}{\\|\\strut\\text{one}(t)\\| \\, \\|\\text{identity}(t)\\|}  =\n\\sqrt{2}\\ \\int_0^1 t\\, dt = \\sqrt{\\strut 2} \\left.{\\Large\\strut}\\frac{1}{2} t^2\\right|_0^1 = \\sqrt{\\frac{1}{2}}\\] Since \\(\\cos(\\theta) = \\sqrt{1/2}\\), the angle \\(\\theta\\) is 45 degrees. :::\n\n\n\n\n\n\n\n\n\nTry it! 37.1\n\n\n\n\n\n\n\n\n\nTry it! 37.1 Project a function onto another\n\n\n\nProject \\(f(t) \\equiv t^2\\) onto \\(g(t) = \\text{one}(t)\\) over the domain \\(-1 \\leq t \\leq 1\\).\nThe projection of \\(f(t)\\) onto \\(g(t)\\) will be \\[\\widehat{f(t)} = \\frac{f(t) \\bullet g(t)}{g(t) \\bullet g(t)}\\ g(t)\\]\n\n\\(f(t) \\bullet g(t) \\equiv \\int_{-1}^{1} t^2 dt = \\frac{1}{3} \\left.{\\Large \\strut}t^3\\right|_{-1}^{1} = \\frac{2}{3}\\)\n\\(g(t) \\bullet g(t) \\equiv \\int_{-1}^1 \\ dt = 2\\)\n\nThus, \\[\\widehat{f(t)} = \\frac{1}{3} \\text{one(t)} = \\frac{1}{3}\\ .\\]\n\n\n\n\n\nApplication area 37.1 — Seeing sounds as sinusoids.\n\n\n\n\n\n\n\nApplication area 37.1 Sinusoids and sounds\n\n\n\nThe table links to audio files recorded by a human speaker voicing various vowels. Play the sounds to convince yourself that they really are the vowels listed. (It may help to use the controls to slow down the playback.)\nVowel | Player\n------|-------\n\"o\" as in \"stone\" | &lt;audio controls&gt;&lt;source src = \"https://linguistics.ucla.edu/people/hayes/103/Charts/VChart/o.wav\" type = \"audio/wav\"&gt;&lt;/audio&gt;\n\"e\" as in \"eel\" | &lt;audio controls&gt;&lt;source src = \"https://linguistics.ucla.edu/people/hayes/103/Charts/VChart/y.wav\" type = \"audio/wav\"&gt;&lt;/audio&gt;\nAs you may know, the physical stimuli involved in sound are rapid oscillations in air pressure. Our standard model for oscillations is the sinusoid function, which is parameterized by its period and its amplitude. The period of a sound oscillation is short: between 0.3 and 10 milliseconds. The amplitude is small. To get a sense for how small, consider the change in air pressure when you take an elevator up 10 stories in a building. The pressure amplitude of sound at a conversational level of loudness corresponds to taking that elevator upward by 1 to 10 mm.\nThe shapes of the “e” (as in “eel”) and “o” (as in “stone”) sound waves—in short, the waveforms—are drawn in ?fig-sound-waves.\n\n\n\n\n\nThe waveforms of two vowel sounds. Only about five hundredths of a second is shown.\n\n\n\n\nThe function resembles none of our small set of pattern-book functions. It is more complicated, more detailed, more irregular than any of the basic modeling functions featured in this book.\nFor many tasks it is helpful to have a modeling approach that is well suited to such detailed and irregular functions. For example, we might want to identify the speaker from a recording, or to play the recording slower or faster without changing the essence of the sound, or to tweak the function to have additional properties such as being exactly on tune while maintaining its individuality as a sound.\nA remarkable aspect of the waveforms in ?fig-sound-waves is their periodicity. The 0.05 sec graphics domain shown includes roughly seven repetitions of a basic waveform. That is, each cycle lasts about \\(\\frac{0.05 \\text{s}}{7} \\approx 7 \\text{ms}\\). what distinguishes the “e” waveform from the “o” waveform is the shape of the waveform that is being repeated. The individual cycle of the “o” has three peaks of diminishing amplitude. The “e” cycle has two main peaks, high then low. It also has a very fast wiggle superimposed on the two peaks.\nAn important strategy for modeling such complicated oscillations is to decompose (synonym: analyze) them into a linear combination of simpler parts.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Functions as vectors</span>"
    ]
  },
  {
    "objectID": "Accumulation/36-functions.html#sinusoids-as-vectors",
    "href": "Accumulation/36-functions.html#sinusoids-as-vectors",
    "title": "37  Functions as vectors",
    "section": "37.2 Sinusoids as vectors",
    "text": "37.2 Sinusoids as vectors\nThe sinusoid is our fundamental model of periodic phenomena. To get started with using sinusoids as vectors, we will start with a simple setting: a single sinusoid of a specified frequency.\nFigure 37.2 shows three sinusoids all with the same frequency, but shifted somewhat in time:\n\n\n\n\n\n\n\n\nFigure 37.2: Three sinusoids with a frequency of \\(\\omega=3\\) cycles per second.\n\n\n\n\n\nSince we have a dot product for functions, we can treat each of the three sinusoids as a vector. For instance, consider the length of waveforms A and B and the included angle between them.\n\n\n## vector lengths \nlengthA &lt;- Integrate(waveA(t) * waveA(t) ~ t, bounds(t=0:1)) |&gt; sqrt() \n## Loading required package: cubature\nlengthA\n## [1] 0.7071068\nlengthB &lt;- Integrate(waveB(t) * waveB(t) ~ t, bounds(t=0:1)) |&gt; sqrt()\nlengthB\n## [1] 0.7071068\nlengthC &lt;- Integrate(waveC(t) * waveC(t) ~ t, bounds(t=0:1)) |&gt; sqrt()\nlengthC\n## [1] 0.7071068\n## dot products\ndotAB   &lt;- Integrate(waveA(t) * waveB(t) ~ t, bounds(t=0:1)) \ndotAB\n## [1] -3.984443e-18\ndotAC   &lt;- Integrate(waveA(t) * waveC(t) ~ t, bounds(t=0:1))\ndotAC\n## [1] -0.1545085\ndotBC   &lt;- Integrate(waveB(t) * waveC(t) ~ t, bounds(t=0:1))\ndotBC\n## [1] -0.4755283\n\n\nThe cosine of the included angle \\(\\theta\\) between functions A and B is calculated using the dot product formula: \\[\\cos(\\theta) = \\frac{A\\bullet B}{\\|A\\|\\, \\|B\\|}\\] or, computationally\n\ndotAB / (lengthA * lengthB)\n## [1] -7.968886e-18\n\nSince \\(\\cos(\\theta) = 0\\), wave A and B are orthogonal. Admittedly, there is no right angle to be perceived from the graph, but the mathematics of angles gives this result.\nThe graphical presentation of orthogonality between waveforms A and B is easier to appreciate if we plot out the dot product itself: the integral of waveform A times waveform B. Figure 37.3 shows this integral using colors, blue for positive and orange for negative. The integral is zero, since the positive (blue) areas exactly equal the negative (orange) areas.\n\n\n\n\n\n\n\n\nFigure 37.3: The dot product between waveforms A and B, graphically.\n\n\n\n\n\nIn contrast, waveform A is not orthogonal to waveform C, and similarly for waveform B. ?fig-AC-BC shows this graphically: the positive and negative areas in the two integrals do not cancel out to zero.\n\n\n\n\n\nThe dot products between waveforms A and C (top panel) and between B and C (bottom panel).\n\n\n\n\nWe can project waveform C onto the 2-dimensional subspace spanned by A and B. Since waveforms A and B are orthogonal, This can be done simply by projecting C onto each of A and B one at a time. Here’s a calculation of the scalar multipliers for A and for B and the model vector (that is, the component of C in the A-B subspace):\n\nA_coef &lt;- dotAC / lengthA^2\nB_coef &lt;- dotBC / lengthB^2\nmod_vec &lt;- makeFun(A_coef*waveA(t) + B_coef*waveB(t) ~ t)\n# length of mod_vec\nIntegrate(mod_vec(t)*mod_vec(t) ~ t, bounds(t=0:1)) |&gt; sqrt()\n## [1] 0.7071068\n\nYou can see that the length of the model vector is the same as the length of the vector being projected. This means that waveform C lies exactly in the subspace spanned by waveforms A and B.\nA time-shifted sinusoid of frequency \\(\\omega\\) can always be written as a linear combination of \\(\\sin(2\\pi\\omega t)\\) and \\(\\cos(2\\pi\\omega t)\\). The coefficients of the linear combination tell us both the amplitude of the time-shifted sinusoid and the time shift.\n\n\n\n\n\n\n\n\nTry it! 37.2\n\n\n\n\n\n\n\n\n\nTry it! 37.2 Adding sinusoids\n\n\n\nConsider the function \\(g(t) \\equiv 17.3 \\sin(2*pi*5*(t-0.02)\\) on the domain \\(0 \\leq t \\leq 1\\) seconds. The amplitude is 17.3. The time shift is 0.02 seconds. Let’s confirm this using the coefficients on the linear combination of sine and cosine of the same frequency.\n\ng &lt;- makeFun(17.3 * sin(2*pi*5*(t-0.02)) ~ t)\nsin5 &lt;- makeFun(sin(2*pi*5*t) ~ t)\ncos5 &lt;- makeFun(cos(2*pi*5*t) ~ t)\nA_coef &lt;- Integrate(g(t) * sin5(t) ~ t, bounds(t=0:1)) /\n  Integrate(sin5(t) * sin5(t) ~ t, bounds(t=0:1))\nA_coef\n## [1] 13.99599\nB_coef &lt;- Integrate(g(t)*cos5(t) ~ t, bounds(t=0:1)) /\n  Integrate(cos5(t) * cos5(t) ~ t, bounds(t=0:1))\nB_coef\n## [1] -10.16868\n\nThe amplitude of \\(g(t)\\) is the Pythagorean sum of the two coefficients:\n\nsqrt(A_coef^2 + B_coef^2)\n## [1] 17.3\n\nThe time delay involves the ratio of the two coefficients:\n\natan2(B_coef, A_coef) / (2*pi*5) \n## [1] -0.02\n\nFor our purposes here, we will need only the Pythagorean sum and will ignore the time delay.\n\n\n?fig-cello-seg (top) shows the waveform of a note played on a cello. The note lasts about 1 second. The bottom panel zooms in on the waveform, showing 82 ms (that is, 0.082 s).\n\n\n\n\n\nWaveform recorded from a cello.\n\n\n\n\nThe whole note starts with a sharp “attack,” followed by a long period called a “sustain,” and ending with a “decay.” Within the sustain and decay, the waveform is remarkably repetitive, seen best in the bottom panel of the figure.\nIf you count carefully in the bottom panel, you will see that the waveform completes 9 cycles in the 0.082 s graphical domain. This means that the period is 0.082 / 9 = 0.0091 s. The frequency \\(\\omega\\) is the reciprocal of this: 1/0.0091 = 109.76 Hz. That is, the cello is vibrating about 110 times per second.\nIn modeling the cello waveform as a linear combination of sinusoids, the frequencies we use ought to respect the period of the cello vibration. Figure 37.4 shows the original waveform as well as the projection of the waveform onto a sinusoid with a frequency of 109.76 Hz. The figure also shows the residual from the projection, which is simply the original waveform minus the projected version.\n\n\n\n\n\n\n\n\nFigure 37.4: Top: The cello waveform and its projection onto a sinusoid with frequency \\(\\omega = 109.76\\) Hz. Bottom: The residual from the projection.\n\n\n\n\n\nThe sinusoid with \\(\\omega = 109.76\\) is not the only one that will repeat every 0.0091 s. So will a sinusoid with frequency \\(2\\omega = 219.52\\), one with frequency \\(3\\omega = 329.28\\) and so on. These multiples of \\(\\omega\\) are called the harmonics of that frequency. In Figure 37.5 (top) the cello waveform is projected onto \\(\\omega\\) and its first harmonic \\(2\\omega\\). In the middle panel, the projection is made onto \\(\\omega\\) and its first three harmonics. In the bottom panel, the projection is onto \\(\\omega\\) and its first eight harmonics.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs the number of harmonics increases, the approximation gets better and better.\nUntil now, all the plots of the cello waveform have been made in what’s called the time domain. That is, the horizontal axis of the plots has been time, as seems natural for a function of time.\nThe decomposition into sinusoids offers another way of describing the cello waveform: the frequency domain. In the frequency domain, we report the amplitude and phase of the projection onto each frequency, plotting that versus frequency. Figure 37.6 shows the waveform in the frequency domain.\n\n\n\n\n\n\n\n\nFigure 37.6: The frequency domain description of the cello waveform.\n\n\n\n\n\nFrom the amplitude graph in Figure 37.6, you can see that only a handful of frequencies account for almost all of the signal. Thus, the frequency domain representation is in many ways much more simple and compact than the time domain representation.\nThe frequency domain description is an important tool in many fields. As you will see in Block 6, models of many kinds of systems, from the vibrations of buildings during an earthquake, aircraft wings in response to turbulence, and the bounce of a car moving over a rutted road have a very simple form when stated in the frequency domain. Each sinusoid in the input (earthquake shaking, air turbulence, rutted road) gets translated into the same frequency sinusoid in the output (building movement, wing bending, car bound): just the amplitude and phase of the sinusoid is altered.\nThe construction of the frequency domain description from the waveform is called a Fourier Transform, one of the most important techiques in science.\n\nApplication area 37.2 — Molecules as tuning forks!\n\n\n\n\n\n\n\nApplication area 37.2 Molecular spectroscopy\n\n\n\nAn important tool in chemistry is molecular vibrational spectroscopy in which a sample of the material is illuminated by an infrared beam of light. The frequency of infrared light ranges from about \\(300 \\times 10^7\\) Hz to \\(400 \\times 10^{10}\\) Hz, about 30 million to 40 billion times faster than the cello frequency.\nInfrared light is well suited to trigger vibrations in the various bonds of a molecule. By measuring the light absorbed at each frequency, a frequency domain picture can be drawn of the molecules in the sample. This picture can be compared to a library of known molecules to identify the makeup of the sample.\nThe analogous procedure for stringed musical instruments such as the cello or violin would be to rap on the instrument and record the hum of the vibrations induced. The Fourier transform of these vibrations effectively paint a picture of the tonal qualities of the instrument.\n\n\n\n\n\n\n\n\nCalculus history—From Taylor to Lagrange\n\n\n\nIn Chapter 27 we met a method introduced by Brook Taylor (1685–1731) to construct a polynomial of order-\\(n\\) that approximates any smooth function \\(f(x)\\) close enough to some center \\(x_0\\). The method made use of the ability to differentiate \\(f(x)\\) at \\(x_0\\) and produced the general formula: \\[f(x) \\approx f(x_0) + \\frac{f'(x_0)}{1} \\left[x-x_0\\right] + \\frac{f''(x_0)}{2!} \\left[x-x_0\\right]^2 + \\frac{f'''(x_0)}{3!} \\left[x-x_0\\right]^3 + \\cdots + \\frac{f^{(n)}(x_0)}{n!} \\left[x-x_0\\right]^n\\] where \\(f'(x_0) \\equiv \\partial_x f(x)\\left.{\\Large\\strut}\\right|_{x=x_0}\\) and so on.\nUsing polynomials as approximating functions has been an important theme in mathematics history. Brook Taylor was neither the first nor the last to take on the problem.\nIn 1795, Joseph-Louis Lagrange (1736 – 1813) published another method for constructing an approximating polynomial of order \\(n\\). Whereas the Taylor polynomial builds the polynomial that exactly matches the first \\(n\\) derivatives at the center point \\(x_0\\), the Lagrange polynomial has a different objective: to match exactly the values of the target function \\(f(x)\\) at a set of knots (input values) \\(x_0\\), \\(x_1\\), \\(x_2\\), \\(\\ldots, x_n\\). ?fig-lagrange-sine shows the situation with the knots shown as orange dots.\n\n## Warning: Removed 38 rows containing missing values (`geom_line()`).\n## Warning: Removed 8 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n\nFigure 37.7: The Lagrange polynomial of order \\(n\\) is arranged to pass exactly through \\(n+1\\) points on the graph of a function \\(f(x)\\).\n\n\n\n\n\nThe Lagrange polynomial is constructed of a linear combinations of functions, one for each of the knots. In the example of Figure @ref(fig:lagrange-sine), there are 6 knots, hence six functions being combined. For knot 2, for instance, has coordinates \\(\\left(\\strut x_2, f(x_2)\\right)\\) and the corresponding function is:\n\\[p_2(x) = \\frac{(x-x_1)}{(x_2 -x_1)}\\left[\\strut\\cdot\\right]\\frac{(x-x_3)(x-x_4)(x-x_5)(x-x_6)}{(x_2 -x_3)(x_2 -x_4)(x_2 -x_5)(x_2 -x_6)}\\] The gap indicated by \\(\\left[\\strut\\cdot\\right]\\) marks where a term being excluded. For \\(p_2(x)\\) that excluded term is \\(\\frac{(x-x_2)}{(x_2 - x_2)}\\). The various functions \\(p_1(x)\\), \\(p_2(x)\\), \\(p_3(x)\\) and so on each leave out an analogous term.\nThree important facts to notice about these ingenious polynomial functions:\n\nThey all have the same polynomial order. For \\(k\\) knots, the order is \\(k-1\\).\nEvaluated at \\(x_i\\), the value of \\(p_i(x_i) = 1\\). For instance, \\(p_2(x_2) = 1\\).\nEvaluated at \\(x_j\\), where \\(j\\neq i\\), the value of \\(p_j(x_i) = 0\\). For example, \\(p_2(x_3) = 0\\).\n\nThe overall polynomial will be the linear combination \\[p(x) = y_1\\, p_1(x) +\ny_2\\, p_2(x) + \\cdots + y_k\\, p_k(x)\\ .\\] Can you see why?",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Functions as vectors</span>"
    ]
  },
  {
    "objectID": "Accumulation/36-functions.html#time-and-tide",
    "href": "Accumulation/36-functions.html#time-and-tide",
    "title": "37  Functions as vectors",
    "section": "37.3 Time and tide",
    "text": "37.3 Time and tide\nPeriodicities from https://tidesandcurrents.noaa.gov/harcon.html?id=8451552&type=\n\nhour &lt;- with(RI_tide, hour)\nb    &lt;- with(RI_tide, level)\nsin1 &lt;- sin(2*pi*hour/12.41)\ncos1 &lt;- cos(2*pi*hour/12.41)\nsin2 &lt;- sin(2*pi*hour/23.94)\ncos2 &lt;- cos(2*pi*hour/23.94)\nsin3 &lt;- sin(2*pi*hour/12)\ncos3 &lt;- cos(2*pi*hour/12)\nsin4 &lt;- sin(2*pi*hour/12.66)\ncos4 &lt;- cos(2*pi*hour/12.66)\nA &lt;- cbind(1, sin1, cos1, sin2, cos2, sin3, cos3, sin4, cos4)\nmod1 &lt;- b %onto% cbind(1, sin1, cos1)\nmod2 &lt;- b %onto% cbind(1, sin1, cos1, sin2, cos2)\nx &lt;- qr.solve(A, b)\nmod3 &lt;- A %*% x\ngf_point(level ~ hour, data = RI_tide)  %&gt;%\n  gf_line(mod3 ~ hour, color=\"magenta\")\n\n\n\n\n\n\n\n\nAnchorage, AK\nComponents: - M2 12.42 hours - S2 12 hours - N2 12.658 hours - K1 23.935 hours\n\nhour &lt;- with(Anchorage_tide, hour)\nb    &lt;- with(Anchorage_tide, level)\nsin1 &lt;- sin(2*pi*hour/12.42)\ncos1 &lt;- cos(2*pi*hour/12.42)\nsin2 &lt;- sin(2*pi*hour/23.935)\ncos2 &lt;- cos(2*pi*hour/23.935)\nsin3 &lt;- sin(2*pi*hour/12)\ncos3 &lt;- cos(2*pi*hour/12)\nsin4 &lt;- sin(2*pi*hour/12.658)\ncos4 &lt;- cos(2*pi*hour/12.658)\nA &lt;- cbind(1, sin1, cos1, sin2, cos2, sin3, cos3, sin4, cos4)\nmod1 &lt;- b %onto% cbind(1, sin1, cos1)\nmod2 &lt;- b %onto% cbind(1, sin1, cos1, sin2, cos2)\nx &lt;- qr.solve(A, b)\nmod3 &lt;- A %*% x\nresid &lt;- b - mod3\ngf_line(level ~ hour, data = Anchorage_tide)  %&gt;%\n  gf_line(mod3 ~ hour, color=\"magenta\") %&gt;%\n  gf_lims(x = c(0,1000))\n## Warning: Removed 75114 rows containing missing values (`geom_line()`).\n## Removed 75114 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n\ngf_line(resid ~ hour)",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Functions as vectors</span>"
    ]
  },
  {
    "objectID": "Accumulation/36-functions.html#fourier-transform",
    "href": "Accumulation/36-functions.html#fourier-transform",
    "title": "37  Functions as vectors",
    "section": "37.4 Fourier transform",
    "text": "37.4 Fourier transform\n\n# Fill in the missing data\nRaw &lt;- Anchorage_tide |&gt; select(hour, level) %&gt;%\n  mutate(hour = round(hour, 1))\nEven &lt;- tibble(hour=seq(min(Raw$hour), max(Raw$hour), by=0.1))\nBoth &lt;- Even |&gt; full_join(Raw)\n## Joining with `by = join_by(hour)`\n# fill in the missing data\nFix1 &lt;- Both |&gt; \n  mutate(level = ifelse(is.na(level), lag(level), level)) %&gt;%\n  mutate(level = ifelse(is.na(level), lag(level), level)) %&gt;%\n  mutate(level = ifelse(is.na(level), lag(level), level)) %&gt;%\n  mutate(level = ifelse(is.na(level), lag(level), level)) %&gt;%\n  mutate(level = ifelse(is.na(level), lag(level), level)) %&gt;%\n# Fill in a constant value for the missing days\n  mutate(level = ifelse(is.na(level), 4.867, level))\nFFT &lt;- abs(fft(Fix1$level))\n# bin 974 is 1 per day\nFFT2 &lt;- \n  tibble(freq=2*(1:10000)/974, amp=FFT[2:10001]) %&gt;%\n  mutate(period = 24/freq) %&gt;%\n  mutate(amp = ifelse(amp &lt; .3e4, 0, amp)) %&gt;%\n  mutate(speed = 360/period)\ngf_line(amp ~ period, size=.1,data = FFT2 |&gt; filter(period&lt;100)) |&gt; gf_lims(x=c(10, 14))\n## Warning: Removed 9550 rows containing missing values (`geom_line()`).",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Functions as vectors</span>"
    ]
  },
  {
    "objectID": "Accumulation/37-euler.html",
    "href": "Accumulation/37-euler.html",
    "title": "38  Integrals step-by-step",
    "section": "",
    "text": "38.1 Euler method\nThe starting point for this method is the definition of the derivative of \\(F(t)\\). Reaching back to Chapter 17,\n\\[\\partial_t F(t) \\equiv \\lim_{h\\rightarrow 0} \\frac{F(t+h) - F(t)}{h}\\] To translate this into a numerical method for computing \\(F(t)\\), let’s write things a little differently.\nWith these changes, we have \\[f(t_0) = \\frac{F(t_0+dt) - F(t_0)}{dt}\\ .\\] The one quantity in this relationship that we do not yet know is \\(F(t_0 + dt)\\). So re-arrange the equation so that we can calculate the unknown in terms of the known. \\[F(t_0 + dt) = F(t_0) + f(t_0)\\, dt\\ .\\]",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Integrals step-by-step</span>"
    ]
  },
  {
    "objectID": "Accumulation/37-euler.html#euler-method",
    "href": "Accumulation/37-euler.html#euler-method",
    "title": "38  Integrals step-by-step",
    "section": "",
    "text": "First, since the problem setting is that we don’t (yet) know \\(F(t)\\), let’s refer to things we do know. In particular, we know \\(f(t) = \\partial_t F(t)\\).\nAgain, recognizing that we don’t yet know \\(F(t)\\), let’s re-write the expression using something that we do know: \\(F(t_0)\\). Stated more precisely, \\(F(t_0)\\) is something we get to make up to suit our convenience. (A common choice is \\(F(t_0)=0\\).)\nLet’s replace the symbol \\(h\\) with the symbol \\(dt\\). Both of them mean “a little bit of” and \\(dt\\) makes explicit that we mean “a little bit of \\(t\\).”\nwe will substitute the limit \\(\\lim_{h\\rightarrow 0}\\) with an understanding that \\(dt\\) will be something “small.” How small? we will deal with that question when we have to tools to answer it.\n\n\n\n\n\n\n\n\nTip\n\n\n\nLet’s consider finding the anti-derivative of \\(\\dnorm()\\), that is, \\(\\int_0^t \\dnorm(x) dx\\). In one sense, you already know the answer, since \\(\\partial_x \\pnorm(x) = \\dnorm(x)\\). But \\(\\pnorm()\\) is just a name. Beneath the name we know \\(\\pnorm()\\) only because it has been numerically constructed by integrating \\(\\dnorm()\\). The \\(\\pnorm()\\) function is so important that the numerically constructed answer has been memorized by software.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Integrals step-by-step</span>"
    ]
  },
  {
    "objectID": "Accumulation/37-euler.html#area",
    "href": "Accumulation/37-euler.html#area",
    "title": "38  Integrals step-by-step",
    "section": "38.2 Area",
    "text": "38.2 Area\nThe quantity \\[\\Large \\color{magenta}{f(t_0)}\\, \\color{orange}{dt}\\] gives rise to a visualization that has been learned by generations of calculus students. The visualization is so compelling and powerful that many students (and teachers, and textbook authors) mistake the visualization for integration and anti-differentiation themselves.\nWe will start the visualization with a simple graph of \\(f(t)\\), which is called the integrand in the integral \\(\\int_a^b f(t) dt\\). Figure 38.1 shows the graph of \\(f(t)\\). A specific point \\(t_0\\) has been marked on the horizontal axis. Next to it is another mark at \\(t_0 + dt\\). Of course, the distance between these marks is \\(\\color{orange}{dt}\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 38.1: Illustrating the interpretation of \\(f(t_0) dt\\) as an “area.”\n\n\n\nPer the usual graphical convention, a position along the vertical axis corresponds to a possible output of \\(f(t)\\). The output for \\(t=t_0\\) is \\(\\color{magenta}{f(t_0)}\\). That same quantity corresponds to the length of the vertical orange segment connecting \\((t_0, 0)\\) to \\((t_0, f(t_0))\\).\nThe \\(\\color{orange}{dt}\\) line segment and the \\(\\color{magenta}{f(t_0)}\\) segment constitute two sides of a rectangle, shown as a shaded zone. The “area” of that rectangle is the product \\(\\color{magenta}{f(t_0)}\\ \\color{orange}{dt}\\).\nIn this sort of visualization, an integral is the accumulation of many of these \\(f(t) dt\\) rectangles. For instance, Figure 38.2 the visualization of the integral \\[\\int_{0}^3 f(t) dt\\ .\\]\n\n## Warning in is.na(x): is.na() applied to non-(list or vector) of type\n## 'expression'\n\n## Warning in is.na(x): is.na() applied to non-(list or vector) of type\n## 'expression'\n\n## Warning in is.na(x): is.na() applied to non-(list or vector) of type\n## 'expression'\n\n\n\n\n\n\n\nFigure 38.2: Visualizing the integral \\(\\int_0^3 f(t) dt\\) as the total “area” of several \\(f(t) dt\\) bars. The width of each of the bars is \\(dt\\). The height depends on the value of the function \\(f(t)\\) at the bar. For illustration, two of the bars are marked with vertical and horizontal line segments.\n\n\n\n\n\nAs always in calculus, we imagine \\(dt\\) as a “small” quantity. In ?fig-bars-0-3B you can see that the function output changes substantially over the sub-domain spanned by a single rectangle. Using smaller and smaller \\(dt\\), as in ?fig-bars-0-3-small brings the visualization closer and closer to the actual meaning of an anti-derivative.\n\n\n\n\n\nVisualizing the integral \\(\\int_0^3 f(t) dt\\) as the total “area” of several \\(f(t) dt\\) bars. The width of each of the bars is \\(dt\\). The height depends on the value of the function \\(f(t)\\) at the bar. For illustration, two of the bars are marked with vertical and horizontal line segments.\n\n\n\n\n\n\n\n\n\n\nWhy do you keep putting “area” in quotes?\n\n\n\nWhen \\(f(t_i) &lt; 0\\), then \\(f(t_i) dt\\) will be negative. There is no such thing as a negative area, but in constructing an integral the \\(f(t_i)dt\\), being negative, diminishes the accumulated area.\n\n\n\n\n\n\n\n\nFigure 38.3: The \\(\\int_{-2}^3 g(t) dt\\) covers subdomains where \\(g(t) &gt; 0\\) and where \\(g(t) &lt; 0\\). In those latter subdomains, the “area” is negative, and shown in light orange here.\n\n\n\n\n\nAnother problem is that area is a physical quantity, with dimension L\\(^2\\). The quantity produced by integration will have physical dimension \\([f(t)][t]\\), the product of the dimension of the with-respect-to quantity and the output of the function.\n“Area” is an effective metaphor for visualizing integration, but the goal of integration is not to calculate an area but, typically, some other kind of quantity.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Integrals step-by-step</span>"
    ]
  },
  {
    "objectID": "Accumulation/37-euler.html#the-euler-step",
    "href": "Accumulation/37-euler.html#the-euler-step",
    "title": "38  Integrals step-by-step",
    "section": "38.3 The Euler Step",
    "text": "38.3 The Euler Step\nThe previous section a visualization of an integral in terms of an area on a graph. As you know, a definite integral \\(\\int_a^b f(t) dt\\) can also be computed by constructing the anti-derivative \\(F(t) \\equiv \\int f(t) dt\\) and evaluating it at the upper and lower bounds of integration: \\(F(b) - F(a)\\). In this section, we will look at the numerical process of constructing an anti-derivative function, which uses many of the same concepts as those involved in finding an integral by combining areas of rectangles.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nA definite integral produces a quantity, not a function. The anti-derivative function constructed by using quantities like \\(f(t) dt\\) will be a series of quantities rather than a formula. In particular, it will have the form of a data table, something like this:\n\n\n\n\n\\(t\\)\n\\(F(t)\\)\n\n\n\n\n-2\n10.62\n\n\n-1.5\n6.47\n\n\n-1\n3.51\n\n\n-0.5\n2.02\n\n\n0\n2.4\n\n\n0.5\n3.18\n\n\n1.0\n5.14\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\nTo start in creating \\(F()\\) by anti-differentiating \\(f()\\), we will need to create a series of \\(t\\) values. We will do this by specifying a starting value for \\(t\\) and then creating successive values by adding a numerical increment \\(dt\\) to the entries one after the other until we reach a terminating value. For instance, in the above table, the starting value for \\(t\\) is \\(-2\\), the numerical increment is \\(dt=0.5\\), and the terminating value is \\(1\\).\nIn previous chapters of this book we have worked with data tables, but always the data table was given to us, we did not have to construct it.1 Now we need to construct the data frame with the \\(t\\) column containing appropriate values. Computer languages provide many ways to accomplish this task. We will use a simple R/mosaic function Picket(), which constructs a data table like the one shown above. You provide two arguments: the domain for \\(t\\), that is, the desired upper and lower bounds of integration; the interval size \\(dt\\) (which is called h in the argument list). For instance, to construct the \\(t\\) column of the table shown above, you can use Picket() this way:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAs you can see, the data table produced by Picket() has the \\(t\\) column, as well as a second column named weight. We haven’t explained weight yet, but you can see that it is the same value we specified as h.\nThe name Picket() is motivated by the shape of a picket fence. The pickets are evenly spaced, which keeps things simple but is not a requirement.\nNote that the picket does not say anything at all about the function \\(f(t)\\) being anti-differentiated. The picket can be applied to any function although precision might require a smaller \\(dt\\) for functions that have a lot going on in a small domain.\nThe next step in using the picket to perform anti-differentiation is to apply the function \\(f()\\) to the pickets. That is, we will add a new column, perhaps called vals to the data table.\nAdding a new column is a common task when dealing with data. We will do this with a new function, mutate(), whose specific function is adding new columns (or modifying old ones). Here’s the command to apply \\(f()\\) to t and call the new column vals:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow that we know the value of the function at each of the pickets, the next step is to multiply the value by the spacing between pickets. That spacing, which we set with the argument h = 0.5 in our original call to Picket() is in the column called weight. we will call the result of the multiplication step. Note that the following R command incorporates the previous calculation of vals; we are looking to build up a single command that will do all the work.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe used the name step to identify the product of the height and spacing of the pickets to help you think about the overall calculation as accumulating a series of steps. Each step provides a little more information about the anti-derivative that we will now calculate. In terms of the area metaphor for integration, each step is the area of one vertical bar of the sort presented in the previous section.\nWe will call these Euler steps, a term that will be especially appropriate when, in Block 6, we use integration to calculate the trajectories of systems—such as a ball in flight—that change in time.\nThe final step in constructing the anti-derivative is to add up the steps. This is simple addition. But we will arrange the addition one step at a time. That is, for the second row, the result will be the sum of the first two steps. For the third row, the result will be the sum of the first three steps. And so on. The name for this sort of accumulation of the previous steps is called a cumulative sum. Another name for a cumulative sum is a “running sum”: the sum-so-far as we move down the column of steps. Cumulative sums are computed in R by using cumsum(). Here, we are calling the result of the cumulative sum F to emphasize that it is the result of anti-differentiating \\(f()\\). But keep in mind that the anti-derivative is not just the F column, but the table with both t and F columns. That is, the table has a column for the input as well as the output. That is what it takes to be a function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can summarize the steps in this Euler approach to numerical integration graphically:\n\n\n\n\n\n\n\n\n1. Create the picket\n\n\n\n\n\n\n\n2. Eval function f(x) at picket locations to set height.\n\n\n\n\n\n\n\n3. Multiply picket height by width\n\n\n\n\n\n\n\n4. Cumulative sum of areas versus t\n\n\n\n\n\n\nFigure 38.4: Steps in a numerical construction of an anti-derivative. (1) Create a set of picket locations over the domain of interest. The locations are spread horizontally by amount dt, so each picket will be dt units wide. (2) evaluate the original function at the picket points to give picket heights. (3) Multiply the picket height by the picket width to create an \"area\". (4) Starting at zero for the left-most picket, add in successive picket areas to construct the points on the anti-derivative function (green). Note that the vertical axis in (4) has a different dimension and units than in steps (1)-(3). In (4) the vertical scale is in the units of the anti-derivative function output.\n\n\n\nFigure 38.5 shows a dynamic version of the process of constructing an anti-derivative by Euler steps. The integrand \\(f(t)\\) is shown in the top panel, the anti-derivative \\(F(t)\\) is shown being built up in the bottom panel. The \\(\\color{magenta}{\\text{magenta}}\\) bar in the top plot is the current Euler step. That step is added to the previously accumulated steps to construct \\(F(t)\\).\n\n\n\n\n\n\nFigure 38.5: A dynamic view of building \\(F(t)\\) from \\(f(t)\\) by accumulating Euler steps.\n\n\n\n\nApplication area 38.1 — What does “daily” tell you?\n\n\n\n\n\n\n\nApplication area 38.1 Russian COVID-19 cases\n\n\n\nThe following graphic from a well-respected news magazine, The Economist, shows the reported number of cases and deaths from Covid-19 during a two-year period in Russia.\n\n\n\n\n\n\nFigure 38.6\n\n\n\nThe figure caption gives information about the units of the quantities being graphed. Notice the word “daily,” which tells us, for example, that in mid-2021 there were about 10,000 new cases of Covid-19 each day and correspondingly about 350 daily deaths.\nHow many total cases and total deaths are reported in the graphic?\nThere are, of course, two distinct ways to present such data which can be easily confused by the casual reader. One important way to present data is as cumulative cases and deaths as a function of date. We will call these \\(C(t)\\) and \\(D(t)\\). Another prefectly legitimate presentation is of the rate of change \\(\\partial_t C(t)\\) and \\(\\partial_t D(t)\\) which, following our informal capital/lower-case-letter convention, we could write \\(c(t)\\) and \\(d(t)\\). Since there is no such thing as a “negative” case or death, we know that \\(C(t)\\) and \\(D(t)\\) are monotonic functions, never decreasing. So the graphs cannot possibly be of \\(C(t)\\) and \\(D(t)\\), since the graphs are far from monotonic. Consequently, the displayed graphs are \\(c(t)\\) and \\(d(t)\\), as confirmed by the word “daily” in the caption.\nTo find \\(C(t)\\) and \\(D(t)\\) requires integrating \\(c(t)\\) and \\(d(t)\\). The value of \\(C(t)\\) and \\(D(t)\\) at the right-most extreme of the graph can be found by calculating the “area” under the \\(c(t)\\) and \\(d(t)\\) curves. But care needs to be taken in reading the horizontal axis. Although the axes are labelled with the year, the tick marks are spaced by one month. (Notice “month” does not appear in the caption.) The far right end of the graph is in early July 2021. The far left end, when the graph moves away from zero cases and deaths, is early April 2020.\nYou can do a reasonable job estimating the “area” by extending the tick marks on the horizontal axis and counting the resulting rectangles that fall under the curve.\n\n\n\n\n\n\nFigure 38.7: Dividing the domain into regions of width \\(dt = 1\\) month.”\n\n\n\nFor the graph of cases, the “area” of each rectangle is \\(\\frac{5000\\, \\text{cases}}{\\text{ day}}\\cdot \\text{1 month}\\). This has the right dimension, “cases,” but the units are screwy. So replace 1 month with 30.5 days (or thereabouts) to get an “area” of each rectangle of 172,500 cases. Similarly, the “area” of the rectangles on the right graph is 3050 deaths.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Integrals step-by-step</span>"
    ]
  },
  {
    "objectID": "Accumulation/37-euler.html#better-numerics-optional",
    "href": "Accumulation/37-euler.html#better-numerics-optional",
    "title": "38  Integrals step-by-step",
    "section": "38.4 Better numerics (optional)",
    "text": "38.4 Better numerics (optional)\nExcept as a textbook exercise, you will likely never have to compute a numerical anti-derivative from scratch as we did in the previous section. This is a good thing. To understand why, you have to know one of the important features of modern technical work. That feature is: We never work alone in technical matters. There is always a set of people whose previous work we are building on, even if we never know the names of those people. This is because technology is complicated and it is evidently beyond the reach of any human to master all the salient aspects of each piece of technology being incorporated into the work we consider our own.\nOf course this is true for computers, since no individual can build a useful computer from first principles. It is also true for software. One detail in particular is relevant to us here. Computer arithmetic of the sort used in the previous section—particularly addition—is prone to error when adding up lots and lots of small bits. This means that it is not always sensible to choose very small \\(dt\\) to get a very accurate approximation to the anti-derivative.\nFortunately, there are specialists in numerical mathematics who work on ways to improve the accuracy of calculations for mid-sized \\(dt\\). Their work has been incorporated into the results of antiD() and Integrate() and so the details are, for us, unimportant. But they are only unimportant because they have been taken care of.\nTo illustrate how considerably more accuracy can be gained in calculating an anti-derivative, consider that the rectangular bars drawn in the previous sections are intended to approximate the “area” under the function. With this in mind, we can replace the rectangular bars with more suitable shapes that stay closer to the function over the finite extend of each \\(dt\\) domain. The rectangular bars model the function as piecewise constant. A better job can be done with piecewise linear approximations or piecewise quadratic approximations. Often, such refinements can be implemented merely by changing the weight column in the picket data frame used to start off the process.\nOne widely used method, called Gauss-Legendre quadrature can calculate a large segment of an integral accurately (under conditions that are common in practice) with just five evaluations of the integrand \\(f(t)\\).\n\n\n\nTable 38.1: Picket locations and weights For the integral \\(\\int_a^b f(t) dt\\) where \\(c = \\frac{a+b}{2}\\) and \\(w = (b-a)/2\\).\n\n\n\n\n\nlocation\nweight\n\n\n\n\n\\(c - 0.90618 w\\)\n\\(0.236927 \\times w\\)\n\n\n\\(c - 0.53847 w\\)\n\\(0.478629 \\times w\\)\n\n\n\\(c\\)\n\\(0.568889 \\times w\\)\n\n\n\\(c + 0.53847 w\\)\n\\(0.478629 \\times w\\)\n\n\n\\(c + 0.90618 w\\)\n\\(0.236927 \\times w\\)\n\n\n\n\n\n\nThe locations and weights may seem like a wizard parody of mathematics, but those precise values are founded in an advanced formulation of polynomials rooted in the theory of linear combinations to which you will be introduced in Block 5. Needless to say, you can hardly be expected to have any idea where they come from. That is why it is useful to build on the work of experts in specialized areas. It is particularly helpful when such expertise is incorporated into software that faithfully and reliably implements the methods. The lesson to take to heart: Use professional software systems that have been extensively vetted.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Integrals step-by-step</span>"
    ]
  },
  {
    "objectID": "Accumulation/37-euler.html#footnotes",
    "href": "Accumulation/37-euler.html#footnotes",
    "title": "38  Integrals step-by-step",
    "section": "",
    "text": "The root of the word “data” is the Latin for “given”.↩︎",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Integrals step-by-step</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html",
    "href": "Accumulation/38-symbolic.html",
    "title": "39  Symbolic anti-differentiation",
    "section": "",
    "text": "39.1 The cataloged functions\nIn a traditional science or mathematics education, students encounter (almost exclusively) basic functions from a mid-sized catalog. For instance: \\(\\sqrt{\\strut\\_\\_\\_\\ }\\), \\(\\sin()\\), \\(\\cos()\\), \\(\\tan()\\), square(), cube(), recip(), \\(\\ln()\\), \\(\\exp()\\), negate(), gaussian(), and so on. This catalog also includes some functions that take two arguments but are traditionally written without using parentheses. For instance, \\(a+b\\) does not look like a function but is entirely equivalent to \\(+(a, b)\\). Others in this class are \\(\\times(\\ ,\\ )\\), \\(\\div(\\ , \\ )\\), \\(-(\\ ,\\ )\\), and ^( , ).\nThe professional applied mathematician’s catalog is much larger. You can see an example published by the US National Institute of Standards and Technology as the Digital Library of Mathematical Functions. (Almost all of the 36 chapters in this catalog, important though they be, are highly specialized and not of general interest across fields.)\nThere is a considerable body of theory for these cataloged functions, which often takes the form of relating them to one another. For instance, \\(\\ln(a \\times b) = \\ln(a) + \\ln(b)\\) demonstrates a relationship among \\(\\ln()\\), \\(+\\) and \\(\\times\\). Along the same lines of relating the cataloged functions to one another is \\(\\partial_x \\sin(x) = \\cos(x)\\) and other statements about derivatives such as those listed in Chapter 20.\nSimply to illustrate what a function catalog looks like, Figure 39.1 shows a page from an 1899 handbook entitled A Short Table of Integrals.\nThe use of cataloged functions is particularly prevalent in textbooks, so the quantitatively sophisticated student will encounter symbolic anti-derivatives of these functions throughout his or her studies.\nThe cataloged functions were assembled with great effort by mathematicians over the decades. The techniques and tricks they used to find symbolic anti-derivatives are not part of the everyday experience of technical workers, although many mathematically minded people find them a good source of recreation.\nCalculus textbooks that include extensive coverage of the techniques and tricks should be understood as telling a story of the historical construction of catalogs, rather than conveying skills that are widely used today. In a practical sense, when the techniques are needed, it is more reliable to access them via computer interface such as WolframAlpha, as depicted in Figure 39.2.\nThe systems can do a good job identifying cases where the techniques will not work. In such systems, they provide the anti-derivative as constructed by numerical integration. The R/mosaic antiD() function works in this same way, although its catalog contains only a tiny fraction of the functions found in professional systems. (But then, only a tiny fraction of the professional cataloged function are widely used in applied work.)",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html#sec-cataloged-functions",
    "href": "Accumulation/38-symbolic.html#sec-cataloged-functions",
    "title": "39  Symbolic anti-differentiation",
    "section": "",
    "text": "Figure 39.1: Entries 124-135 from A Short Table of Integrals (1899) by Benjamin Osgood Pierce. The book includes 938 such entries.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 39.2: Pierce’s entry 125 as computed by the WolframAlpha system.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html#differentials",
    "href": "Accumulation/38-symbolic.html#differentials",
    "title": "39  Symbolic anti-differentiation",
    "section": "39.2 Differentials",
    "text": "39.2 Differentials\nBreathing some life into the symbol \\(dx\\) will help in understanding the algebra of techniques for anti-differentiating function compositions and products. We’ve thus far presented \\(dx\\) as a bit of notation: punctuation for identifying the with-respect-to input in anti-derivatives. That is, in interpreting a sequence of symbols like \\(\\int f(x,t) dx\\), we’ve parsed the sequence of symbols into three parts:\n\\[\\underbrace{\\int}_{\\text{integral sign}} \\overbrace{f(x, t)}^{\\text{function to be anti-differentiated}} \\underbrace{dx}_{\\text{'with respect to'}}\\]\nBy analogy, the English sentence\n\\[\\text{We loaded up on snacks.}\\]\nconsists of five parts: the five words in the sentence.\nBut you can also see “We loaded up on snacks” as having three parts:\n\\[\\underbrace{\\text{We}}_{\\text{subject}}\\  \n\\overbrace{\\text{loaded up on}}^{\\text{verb}}\\ \\ \\\n\\underbrace{\\text{snacks}}_{\\text{object}}\\]\nLikewise, the integrate sentence can be seen as consisting of just two parts:\n\\[\\underbrace{\\int}_{\\text{integral sign}} \\overbrace{f(x, t) dx}^{\\text{differential}}\\]\nA differential corresponds to the little sloped segments that we add up when calculating a definite integral numerically using the slope function visualization. That is \\[\\underbrace{\\int}_{\\text{Sum}} \\underbrace{\\overbrace{f(x,t)}^\\text{slope of segment}\\ \\  \\overbrace{dx}^\\text{run}}_\\text{rise}\\]\nA differential is a genuine mathematical object and is used, for example, in analyzing the geometry of curved spaces, as in the Theory of General Relativity. But this is well beyond the scope of this introductory calculus course.\nOur use here for differentials will be to express rules for anti-differentiation of function compositions and products.\nYou should be thinking in terms of differentials when you see a sentence like the following:\n\n“In \\(\\int \\sin(x) \\cos(x) dx\\), make the substitution \\(u = \\sin(x)\\), implying that \\(du = \\cos(x) dx\\) and getting \\(\\int u du\\), which is simple to integrate.”\n\nThe table gives some examples of functions and their differentials. “w.r.t” means “with respect to.”\n\n\n\n\n\n\n\n\n\n\nFunction\nderivative\nw.r.t.\ndifferential\n\n\n\n\n\\(v(x) \\equiv x\\)\n\\(\\partial_x v(x) = 1\\)\nx\n\\(dv = dx\\)\n\n\n\\(u(x) \\equiv x^2\\)\n\\(\\partial_x u(x) = 2x\\)\nx\n\\(du = 2x dx\\)\n\n\n\\(f(x) \\equiv \\sin(x)\\)\n\\(\\partial_x f(x) = \\cos(x)\\)\nx\n\\(df = \\cos(x)dx\\)\n\n\n\\(u(x) \\equiv e^{3 x}\\)\n\\(\\partial_x u(x) = 3 e^{3 x}\\)\nx\n\\(du = 3 e^{3 x} dx\\)\n\n\n\\(g(x) \\equiv t^3\\)\n\\(\\partial_t v(t) = 3 t^2\\)\nt\n\\(dg = 3 t^2 dt\\)\n\n\n\n\nAs you can see, the differential of a function is simply the derivative of that function followed by the little \\(dx\\) or \\(dt\\) or whatever is appropriate for the “with respect to” input.\nNotice that the differential of a function is not written with parentheses: The function \\(u(x)\\) corresponds to the differential \\(du\\).\n\n\n\n\n\n\n\n\nTry it! 39.1\n\n\n\n\n\n\n\n\n\nTry it! 39.1 What is the differential of \\(\\sin(x)\\)?\n\n\n\nAs we’ve seen, \\(\\partial_x \\sin(x) = cos(x)\\). For form the differential of \\(\\sin()\\), take the derivative and suffix it with a \\(dx\\) (since \\(x\\) is the name of the input):\n\\[\\cos(x)\\ dx\\]",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html#u-substitution",
    "href": "Accumulation/38-symbolic.html#u-substitution",
    "title": "39  Symbolic anti-differentiation",
    "section": "39.3 U-substitution",
    "text": "39.3 U-substitution\nThere is little reason to use \\(\\partial_t\\) and \\(\\int \\left[\\right]dt\\) to cancel each other out, but it is the basis of an often successful strategy—u-substitution—for finding anti-derivatives symbolically. Here’s the differentiate/integrate algorithm behind u-substitution.\n\nPick a function \\(f()\\) and another function \\(g()\\). Typically \\(f()\\) and \\(g()\\) belong to the family of basic modeling functions, e.g. \\(e^x\\), \\(\\sin(t)\\), \\(x^n\\), \\(\\ln(x)\\), and so on. For the purpose of illustration, we will use \\(f(x) = \\ln(x)\\) and \\(g(t) = \\cos(t)\\).\nCompose \\(f()\\) with \\(g()\\) to produce a new function \\(f(g())\\) which, in our case, will be \\(\\ln(\\cos(t))\\).\nUse the chain rule to find \\(\\partial_t f(g(t))\\). In the example, the derivative of \\(\\ln(x)\\) is \\(1/x\\), the derivative of \\(g(t)\\) is \\(-\\sin(t)\\). By the chain rule, \\[\\partial_t f\\left(\\strut g(t)\\right) = \\partial_t \\underbrace{\\Large\\ln}_{f()}\\left(\\underbrace{\\large\\cos(t)}_{g(t)}\\right) = \\underbrace{\\left[- \\frac{1}{\\cos(t)}\\right]}_{f'(g(t))} \\underbrace{\\left[{\\LARGE\\strut}\\sin(t)\\right]}_{g'(t)} = -  \\frac{\\sin(t)}{\\cos(t)} = - \\tan(t)\\]\n\nIn a sense, we have just watched a function give birth to another through the straightforward process of differentiation. Having witnessed the birth, we know who is the integration parent of \\(\\tan(t)\\), namely \\(\\int \\tan(t) dt = \\ln\\left(\\cos(t)\\right)\\). For future reference, we might write this down in our diary of integrals: \\[\\int \\tan(t) dt = - \\ln(\\cos(t)) + C\\] Saving this fact in your diary is helpful. The next time you need to find \\(\\int \\tan(x) dx\\), you can look up the answer (\\(-\\ln(\\cos(x)) + C\\)) from your diary. If you use \\(\\int \\tan(x) dx\\) a lot, you will probably come to memorize the answer, just as you have already memorized that \\(\\int \\cos(t) dt = \\sin(t)\\) (a fact that you will use a lot in the rest of this course).\nNow for the u-substitution game. The trick is to take a problem of the form \\(\\int h(t) dt\\) and extract from \\(h(t)\\) two functions, an \\(f()\\) and a \\(g()\\). You’re going to do this so that \\(h(t) =  \\partial_t F(g(t))\\), where \\(\\partial_x F(x) = f(x)\\) Once you’ve done this, you have an answer to the original integration question: \\(\\int h(t) dt = F(g(t)) + C\\).\n\n\n\n\n\n\n\n\nTry it! 39.2\n\n\n\n\n\n\n\n\n\nTry it! 39.2 Evaluate \\(\\int \\frac{\\sin(\\ln(x))}{x} dx\\).\n\n\n\nYou don’t know ahead of time that this is an integral amenable to solution by u-substitution. For all you know, it is not. So before you start, look at the function to see if it one of those for which you already know the anti-derivative, for example any of the pattern-book functions or their parameterized cousins the basic modeling functions.\n\nIf so, you’ve already memorized the answer and you are done. If not …\n\nAssume for a moment—without any guarantee that this will work, mind you—that the answer can be built using u-substitution. You will therefore look hard at \\(h()\\) and try to see in it a plausible form that looks like the derivative of some \\(f(g(x))\\).\nIn the problem at hand, we can readily see something of the form \\(f(g(x))\\) in the \\(\\sin(\\ln(x))\\). This immediately gives you a candidate for \\(g(x)\\), namely \\(g(x)\\equiv \\ln(x)\\) We don’t know \\(f()\\) yet, but if \\(g()\\) is the right guess, and if u-substitution is going to work, we know that \\(f()\\) has to be something that produces \\(\\sin()\\) when you differentiate it. That is \\(-\\cos()\\). So now we have a guess \\[h_\\text{guess}(x) = -\\cos(\\ln(x)) \\partial_x \\ln(x) = - \\cos(\\ln(x)) \\frac{dx}{x}\\]\n\nIf this guess matches the actual \\(h()\\) then you win. The answer to \\(\\int h(x) dx\\) will be \\(f(g(x)) = -\\cos(\\ln(x))\\). If not, see if there is any other plausible guess for \\(g(x)\\) to try. If you cannot find one that works, try integration by parts.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html#sec-integration-by-parts1",
    "href": "Accumulation/38-symbolic.html#sec-integration-by-parts1",
    "title": "39  Symbolic anti-differentiation",
    "section": "39.4 Integration by parts (standard presentation)",
    "text": "39.4 Integration by parts (standard presentation)\nIf you do a lot of symbolic anti-differentation, you will often come across functions that you don’t recognize as being the derivative of an already known function. Consider, for instance, \\[\\int x \\cos(x) dx\\ .\\]\nEven though the integrand \\(x \\cos(x)\\) is a simple product of two pattern book functions it is likely not a function that you have previously produced by differentiation. Thus, it is not yet in your diary of anti-derivatives. The purpose of integration by parts is to provide a standard way to re-organize anti-derivatives like \\(\\int x \\cos(x) dx\\), where the integrand is a product of two simple functions, into another form. Being able to do this is no guarantee that the other form will be something you can anti-differentiate, but it is worth rolling the dice to see if you get lucky.\nThe re-organization rule is based on two fundamental properties of differentiation and anti-differentiation.\n\n\\(\\int f'(x) dx = f(x)\\). This is saying nothing more than if \\(f'(x)\\) is the derivative of \\(f(x)\\), then \\(f(x)\\) must be an anti-derivative of \\(f'(x)\\).\n\\(\\partial_x \\left[\\strut u(x)\\cdot v(x) \\right] = u'(x)\\cdot v(x) + v'(x)\\cdot u(x)\\): the product rule of differentiation.\n\nLet’s integrate both sides of the statement of the product rule. For the left side, applying rule (i), we get a simple result:\n\\[\\int\\left[\\strut\\partial_x \\left[\\strut u(x)\\cdot v(x) \\right]\\right] dx = u(x) \\cdot v(x)\\]\nAs for the right side, all we get is two anti-derivatives: \\[\\int\\left[\\strut u'(x)\\cdot v(x) + v'(x)\\cdot u(x)\\right]dx =\n\\int\\left[\\strut u'(x)\\cdot v(x)\\right]dx + \\int\\left[\\strut u(x)\\cdot v'(x)\\right]dx\\] Putting together the previous two expressions and re-arranging gives: \\[\\int u(x)\\cdot v'(x)\\, dx = u(x) \\cdot v(x) - \\int  v(x)\\cdot u'(x)dx\\ \\ \\ \\mathbf{ \\text{parts re-arrangment}}\\] Now, consider a problem like \\(\\int x \\cdot \\cos(x) dx\\) that we don’t yet know how to solve. Let’s associate this problem with the left side of the parts re-arrangement equation. With luck, we will recognize a problem that we will know how to do on the right-hand side.\nTo implement the re-arrangement, we need to split our as yet unknown anti-derivative into two pieces: \\(u(x)\\) and \\(v'(x) dx\\). There are many possible ways to do this but the most obvious is \\[\\int \\underbrace{\\strut x}_{u(x)} \\cdot \\underbrace{\\cos(x) dx}_{v'(x) dx}\\] According to this proposed splitting, we have \\(u(x) = x\\) and \\(v'(x) dx = \\cos(x) dx\\). To plug things into the right side of the parts re-arrangement we will need to find \\(v(x)\\) and \\(u'(x) dx\\). Since we know \\(u(x) = x\\) it is easy to take the differential, \\(du = dx\\). Similarly, we know \\(v'(x) dx = \\cos(x) dx\\) so we can integrate both sides: \\[v(x) = \\underbrace{\\int v'(x) dx = \\int \\cos(x) dx}_{\\text{from }\\ v'(x)\\,dx\\ =\\ \\cos(x)\\,dx} = \\sin(x)\\] Now that we know the \\(v(x)\\) that is consistent with our original splitting of the anti-derivative into \\(\\int u(x) \\cdot v'(x) dx\\) we can plug in our results to the right side of the parts re-arrangement equation:\n\\[\\int x \\cdot \\cos(x)dx = x \\sin(x) - \\int \\underbrace{\\sin(x)}_{v(x)}\\  \\underbrace{\\ 1\\ dx\\ \\strut}_{u'(x) dx}\\] We are in luck! We already know the anti-derivative \\(\\int \\sin(x) dx = -\\cos(x)\\). Substituting this result for the \\(\\int v(x) u'(x) dx\\) term, we arrive at \\[\\int x \\cdot \\cos(x)dx = x \\sin(x) + \\cos(x)\\ .\\]\nThe key creative step in using integration by parts effectively is to choose a helpful split of the original integral into the \\(u(x)\\) and \\(v'(x) dx\\) parts. This is usually based on a solid knowledge of derivatives and anti-derivatives of basic functions as well as insight into the downstream consequences of any choice. In this sense, picking \\(u(x)\\) and \\(v'(x)dx\\) is like making a move in chess. Some players can see two or three moves ahead and so can pick the first move to improve their position. Without such foresight, the best most people can do is to pick a first move that seems attractive and accept that their fate might be either victory or checkmate.\nFor the calculus student learning integration by parts, there is an irony. Gaining enough experience to make good choices of \\(u(x)\\) and \\(v'(x)dx\\) means that you will solve, or read about solving, many anti-differentiation problems. You can, of course, enter the solutions into your diary of anti-derivatives, obviating to that extent the need to perform integration by parts in the future.\n\n\n\n\n\n\n\n\nTry it! 39.3\n\n\n\n\n\n\n\n\n\nTry it! 39.3\n\n\n\nIn demonstrating that \\[\\int x \\cdot \\cos(x)dx = x \\sin(x) + \\cos(x)\\] we followed a number of steps each of which might be subject to error. Best to confirm our solution before accepting it. This can be done by differentiating both sides of our solution: \\[\\partial_x \\int x \\cdot \\cos(x)dx = x \\cos(x) = \\partial_x \\left[\\strut x \\sin(x) + \\cos(x)\\right] = \\underbrace{\\sin(x) + x \\cos(x)}_{\\partial_x \\left[x\\cdot\\sin(x)\\right]}\\  \\underbrace{- \\sin(x)}_{\\partial_x \\cos(x)}= x\\cos(x)\\]\n\n\n\n\n\n\n\n\n\n\nTry it! 39.4\n\n\n\n\n\n\n\n\n\nTry it! 39.4 A unfortunate choice of parts\n\n\n\nWhat would happen in the previous example if we had made a bad choice for \\(u(x)\\) and \\(v'(x) dx\\)? For instance, we might have split \\(x \\cos(x) dx\\) into \\(u(x) = \\cos(x)\\) and \\(v'(x)\\,dx = x\\, dx\\). Working out \\(u'(x)\\,dx\\) and \\(v(x)\\) is easy: \\(u'(x)\\, dx = -\\sin(x)\\, dx\\) and \\(v(x) = \\frac{1}{2} x^2\\). Plugging into the re-arrangement formula gives:\n\\[\\int x \\cdot \\cos(x)\\,dx = \\frac{1}{2} x^2 \\cos(x) - \\int \\frac{1}{2} x^2 \\left[\\strut - \\sin(x)\\right]\\,dx = \\frac{1}{2} x^2 \\cos(x) + \\int \\frac{1}{2} x^2  \\sin(x)\\,dx\\] Unless you know \\(\\int x^2 \\sin(x) dx\\), this re-arrangement leaves you no better off than at the beginning.\nOn the other hand … if you are in the business of compiling diaries of anti-derivatives, you could use this situation to chalk up another entry based on already knowing \\(\\int x \\cdot \\cos(x) dx\\): \\[\\int x^2 \\sin(x) dx = 2 \\int x\\cdot \\cos(x)dx - x^2\\cos(x) = 2x\\sin(x) + 2\\cos(x) - x^2 \\cos(x)\\]\n\n\n\n\n\n\n\n\n\n\nTry it! 39.5\n\n\n\n\n\n\n\n\n\nTry it! 39.5 Find \\(\\int x \\ln(x) dx\\)\n\n\n\nLet \\(u(x) = \\ln(x)\\) and \\(v'(x)dx = x dx\\).\nThen, \\(u'(x)dx = \\frac{1}{x} dx\\) and \\(v(x) = \\frac{1}{2} x^2\\).\nUsing the parts re-arrangement formula …\n\\[\\int x \\ln(x) dx = \\frac{1}{2} x^2 \\cdot \\ln(x) - \\int \\frac{1}{2} x^2\\cdot \\frac{1}{x}\\, dx \\\\\n\\frac{1}{2} x^2 \\cdot \\ln(x) - \\frac{1}{4} x^2\\] And don’t forget, after all this work, to add the constant of integration \\(C\\)!",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html#sec-integration-by-parts2",
    "href": "Accumulation/38-symbolic.html#sec-integration-by-parts2",
    "title": "39  Symbolic anti-differentiation",
    "section": "39.5 Integration by parts (optional alternative presentation)",
    "text": "39.5 Integration by parts (optional alternative presentation)\nIntegration by parts applies to integrals that are recognizably of the form \\[\\int f(x) g(x) dx\\] Step 1: Split up the integrand into an \\(f(x)\\) and a \\(g(x)\\) multiplied together. That is, split the integrand into parts that are multiplied together. The way we wrote the integrand, this was trivial.\nStep 2: Pick one of \\(f(x)\\) or \\(g(x)\\). Typically, you pick the one that has a dead-easy anti-derivative. For our general description, let’s suppose this is \\(g(x)\\) which has anti-derivative \\(G(x)\\) (where we know \\(G()\\)).\nStep 3: Construct a helper function \\(h(x) \\equiv f(x) G(x)\\). This requires no work, since we’ve already identified \\(f(x)\\) and \\(G(x)\\) in step (2).\nStep 4: Find \\(\\partial_x h(x)\\). It is always easy to find derivatives, and here we just use the product rule: \\[\\partial_x h(x) = \\partial_x f(x) \\cdot G(x) + f(x)\\cdot\\partial_x G(x)\\] We know from the way we constructed \\(G(x)\\) that \\(\\partial_x G(x) = g(x)\\), so the equation is \\[\\partial_x h(x) = \\partial_x f(x) \\cdot G(x) + f(x)\\cdot g(x)\\]\nStep 5: Anti-differentiate both sides of the previous equation. From the fundamental theorem of calculus, we know how to do the left side of the equation. \\[\\int \\partial_x h(x) = h(x) \\equiv f(x)g(x)\\] The right side of the equation has two parts: \\[\\int \\left[{\\large\\strut}\\partial_x f(x) \\cdot G(x) + f(x)\\cdot g(x)\\right]dx = \\underbrace{\\int \\partial_x f(x) \\cdot G(x) dx}_\\text{Some NEW integral!}\\ \\ \\ \\  + \\underbrace{\\int f(x) g(x) dx}_\\text{The original integral we sought!}\\] Putting together the left and right sides of the equation, and re-arranging gives us a new expression for the original integral we sought to calculate: \\[\\text{Integration by parts re-arrangement}\\\\\\underbrace{\\int f(x) g(x) dx}_\\text{The original integral we sought.} = \\underbrace{f(x) g(x)}_\\text{We know this!}  - \\underbrace{\\int \\partial_x f(x) \\cdot G(x) dx}_\\text{Some NEW integral!}\\] It may seem that we haven’t accomplished much with this re-organization. But we have done something. We took a problem we didn’t otherwise know how to solve (that is \\(\\int f(x) g(x) dx\\)) and broke it down into two parts. One is very simple. The other is an integral. If we are clever in picking \\(g()\\) and lucky, we will be able to figure out the new integral and, thereby, we will have computed the original integral. But everything depends on cleverness and luck!\n\n\n\n\n\n\n\n\nTry it! 39.6\n\n\n\n\n\n\n\n\n\nTry it! 39.6 Find \\(\\int x \\cos(x) dx\\).\n\n\n\nAn obvious choice for the two parts is \\(x\\) and \\(\\cos(x)\\). But which one to call \\(g(x)\\). We will just guess and say \\(g(x)\\equiv \\cos(x)\\) which implies \\(G(x) = \\sin(x)\\). The helper function is \\(h(x) \\equiv f(x) G(x) = x \\sin(x)\\).\nDifferentiating \\(h(x)\\) can be done by the product rule. \\[\\partial_x h(x) = \\sin(x) + x \\cos(x)\\ .\\] Now anti-differentiate both sides of the above, the left side by the fundamental theorem of algebra and the right side by other means: \\[\\int \\partial_x h(x) = h(x) = x \\sin(x)= \\underbrace{\\int\\sin(x)dx}_{-\\cos(x)} + \\underbrace{\\int x \\cos(x) dx}_\\text{The original integral}\\] Re-arranging gives the answer \\[\\underbrace{\\int x \\cos(x) dx}_\\text{The original integral} = x \\sin(x) + \\cos(x) + C\\] The constant of integration \\(C\\) needs to be included to make the equality true.\nTo confirm the result, you can differentiate the right-hand side; differentiation is always easy.\nAlternatively, we can check numerically if \\(\\int x \\cos(x) dx - (x\\sin(x)+cos(x))\\) is a constant. (See @fig-check-constant).)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nA numerical check shows \\(\\\\int x \\\\cos(x) dx - (x\\\\sin(x)+cos(x))\\) is a constant.\n\n\n\n\n\n\n\n\nTry it! 39.7\n\n\n\n\n\n\n\n\n\nTry it! 39.7 Find \\(\\int \\ln(x) dx\\).\n\n\n\nThe easy solution is to recognize that the anti-derivative of \\(\\ln(x)\\) is contained in the table at the top of the chapter. But let’s try doing it by parts as an example (and to show you how it got into the table in the first place).\nIt is hard to see a separate \\(f(x)\\) and \\(g(x)\\) in the integrand \\(\\ln(x)\\). But sometimes you need to be clever. We will set \\(f(x) \\equiv \\ln(x)\\) and \\(g(x) \\equiv 1\\). This means that \\(G(x) = x\\). The helper function is therefore \\(h(x) = x\\ln(x)\\)\nDifferentiating the helper function gives (by the product rule): \\(\\partial_x h(x) = \\ln(x) + x \\frac{1}{x} = \\ln(x) + 1\\)\nIntegrating the differentiated helper function, we find \\[\\int \\partial_x h(x) dx = f(x)g(x) = x \\ln(x) = \\underbrace{\\int \\ln(x) dx}_\\text{The original integral} + \\underbrace{\\int 1 dx}_{x}\\] Re-arranging, we have \\[\\underbrace{\\int \\ln(x) dx}_\\text{The original integral} = x \\ln(x) - x\\ \\  =\\ \\  x\\left[\\strut \\ln(x) - 1\\right]\\]\n\n\n\n\n\n\n\n\n\n\nTry it! 39.8\n\n\n\n\n\n\n\n\n\nTry it! 39.8 Find \\(\\int \\sin(x) e^x dx\\).\n\n\n\nThis isn’t the integral of a pattern book or basic modeling function, and substitution didn’t work, so we try integration by parts.\nThe obvious choice for the two parts is \\(\\sin(x)\\) and \\(e^x\\). Both are really easy to anti-differentiate. Let’s choose \\(g(x) = \\sin(x)\\), giving \\(G(x) = -\\cos(x)\\). The re-arrangement of the original integral will be \\[\\sin(x) e^x + \\int \\cos(x) e^x dx\\] The new integral that we need to compute does not look any friendlier than the original, but who knows? we will do \\(\\int cos(x) e^x dx\\) by parts as well and keep our fingers crossed. That integral turns out to be \\[\\int \\cos(x) e^x dx = \\cos(x) e^x - \\int \\sin(x) e^x dx\\] This may look like we are going in circles, and maybe we are, but let’s put everything together. \\[\\underbrace{\\int \\sin(x) e^x dx}_\\text{The original problem} = \\underbrace{\\sin(x) e^x + \\cos(x) e^x}_\\text{Easy stuff!}\\ \\ \\  - \\underbrace{\\int \\sin(x) e^x dx}_\\text{Also the original problem}\\] Rearranging gives \\[\\int \\sin(x) e^x dx = \\frac{\\sin(x) e^x + \\cos(x) e^x}{2} = \\frac{e^x}{2}\\left[{\\large\\strut} \\sin(x) + \\cos(x)\\right]\\] And don’t forget the constant of integration.\n\n\n[The presentation of integration by parts in this section was formulated by Prof. Michael Brilleslyper.]\n\n39.6 Didn’t work?\nIf integration by parts does not work … and it does not always work! … there is a variety of possibilities such as asking a math professor (who has a much larger set of functions at hand than you), looking through a table of integrals (which is to say, the collective calculus diary of generations of math professors), using a computer algebra system, or using numerical integration. One of these will work.\nIf you have difficulty using u-substitution or integration by parts, you will be in the same league as the vast majority of calculus students. Think of your fellow students who master the topic in the way you think of ice dancers. It is beautiful to watch, but you need a special talent and it hardly solves every problem. People who would fall on their face if strapped to a pair of skates have nonetheless made huge contributions in technical fields, even those that involve ice.\nProf. Kaplan once had a heart-to-heart with a 2009 Nobel-prize winner who confessed to always feeling bad and inadequate as a scientist because he had not done well in introductory calculus. It was only when he was nominated for the Nobel that he felt comfortable admitting to his “failure.” Even if you don’t master u-substitution or integration by parts, remember that you can integrate any function using easily accessible resources.\n\n\n39.7 Integrating polynomials\nOne of the most famous settings for integration comes from the physics of free fall under gravity.\nHere’s the setting. An object—a ball, let’s imagine—is being held at height \\(x_0\\). At \\(t=0\\) the ball is released. Perhaps the ball is released from a standstill in which case it is velocity at release is \\(v_0 = v(t=0) =0\\). Or perhaps the ball has been tossed upward so that \\(v_0 &gt; 0\\), or downward so that \\(v_0 &lt; 0\\). Whichever it is, the initial velocity will be labelled \\(v_0\\).\nOn release, the force that held the ball steady is removed and the object moves under the influence of only one factor: gravity. The effect of gravity near the Earth’s surface is easy to describe: it accelerates the object at a constant rate of about 9.8 m/s\\(^2\\).\nAcceleration is the derivative with respect to time of velocity. Since we know acceleration, to find velocity we find an anti-derivative of acceleration: \\[v(t) = \\int -9.8\\ dt = -9.8\\ t + C\\] The constant of integration \\(C\\) is not just a formality. It has physical meaning. In this case, we see that \\(C=v(0)\\), that is, \\(C = v_0\\).\nVelocity is the derivative of position: height in this case. So height is an anti-derivative of velocity. \\[x(t) = \\int v(t) dt = \\int \\left[\\strut -9.8\\ t + v_0\\right]dt = - \\frac{9.8}{2} t^2 + v_0\\ t + C\\] Why is \\(C\\) back again? it is a convention to use \\(C\\) to denote the constant of integration. Those experienced with this convention know, from context, that the value of \\(C\\) in the integration that produced \\(v(t)\\) has nothing to do with the value of \\(C\\) involved in the production of \\(x(t)\\). The situation is a bit like the presentation of prices in US stores: to the price of the item itself, you must always add “plus taxes.” Nobody with experience would assume that “taxes” is always the same number. It depends on the price and type of the item itself.4 You won’t have to deal with the taxes at the time you pick the item from the shelf, but eventually you will see them when you check out of the store. Think of \\(+\\ C\\) as meaning, “plus some number that we will have to deal with at some point, but not until checkout.”\nLet’s checkout the function \\(x(t)\\) now. For that, we need to figure out the value of \\(C\\). We can do that by noticing that \\(x(0) = C\\). So in the anti-differentiation producing \\(x()\\), \\(C = x_0\\) giving, altogether the formula for free-fall famous from physics classes \\[x(t) =  - \\frac{9.8}{2} t^2 + v_0\\ t + x_0\\] An important thing to notice about \\(x(t)\\): it is a polynomial in \\(t\\). Polynomials can be birthed by successive anti-differentiations of a constant. At each anti-differentiation, each of the previous terms is promoted by one order. That is, the previous constant becomes the first order term. The previous first-order term becomes the second order term, with the division by 2 familiar from anti-differentiating \\(t\\). A previous second-order term will become the new third-order term, again with the division by 3 familiar from anti-differentiating \\(t^2\\).\nStated generally, the anti-derivative of a polynomial is\n\\[{\\Large\\int} \\left[\\strut \\underbrace{a + b t + ct^2 + \\ldots}_\\text{original polynomial}\\right] dt = \\underbrace{C + a\\,t + \\frac{b}{2} t^2 + \\frac{c}{3} t^3 + \\ldots}_\\text{new polynomial}\\] By use of the symbol \\(C\\), it is easy to spot how the constant of integration fits in with the new polynomial. But if we were to anti-differentiate the new polynomial, we had better replace \\(C\\) with some more specific symbol to that we don’t confuse the old \\(C\\) with the one that is going to be produced in the new anti-differentiation.\n\n\n\n\n\n\nTip\n\n\n\nIn exercise 26.16, we introduced a Taylor polynomial approximation to the gaussian function. That might have seemed like a mere exercise in high-order differentiation at the time, but there is something more important at work.\nThe gaussian is one of those functions for which the anti-derivative cannot be written exactly in terms of what the mathematicians call “elementary functions.” (See Section 39.1.) Yet integrals of the gaussian are very commonly used in science, especially in statistics where the gaussian is called the normal PDF.\nThe approach we’ve taken in this book is simply to give a name and a computer implementation of the anti-derivative of the gaussian. This is the function we’ve called \\(\\pnorm()\\) with the R computer implementation pnorm().\nWe never told you the algorithm contained in pnorm(). Nor do we really need to. We all depend on experts and specialists to design and build the computers we use. The same is true of software implementation of functions like pnorm(). And for that matter, for implementations of functions like exp(), log(), sin(), and so on. You don’t have to know about semi-conductors to use a computer productively, and you don’t need to know about numerical algorithms to use those functions.\nOne feasible algorithm for implementing \\(\\pnorm()\\) is to integrate the Taylor polynomial. It is very easy integrate polynomials. To ensure accuracy, different Taylor polynomials can be computed for different centers, say \\(x=0\\), \\(x=1\\), \\(x=2\\), and so on.\nAnother feasible approach integrates \\(\\dnorm()\\) numerically using an advanced algorithm such as Gauss-Hermite quadrature.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html#didnt-work",
    "href": "Accumulation/38-symbolic.html#didnt-work",
    "title": "39  Symbolic anti-differentiation",
    "section": "39.6 Didn’t work?",
    "text": "39.6 Didn’t work?\nIf integration by parts does not work … and it does not always work! … there is a variety of possibilities such as asking a math professor (who has a much larger set of functions at hand than you), looking through a table of integrals (which is to say, the collective calculus diary of generations of math professors), using a computer algebra system, or using numerical integration. One of these will work.\nIf you have difficulty using u-substitution or integration by parts, you will be in the same league as the vast majority of calculus students. Think of your fellow students who master the topic in the way you think of ice dancers. It is beautiful to watch, but you need a special talent and it hardly solves every problem. People who would fall on their face if strapped to a pair of skates have nonetheless made huge contributions in technical fields, even those that involve ice.\nProf. Kaplan once had a heart-to-heart with a 2009 Nobel-prize winner who confessed to always feeling bad and inadequate as a scientist because he had not done well in introductory calculus. It was only when he was nominated for the Nobel that he felt comfortable admitting to his “failure.” Even if you don’t master u-substitution or integration by parts, remember that you can integrate any function using easily accessible resources.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html#integrating-polynomials",
    "href": "Accumulation/38-symbolic.html#integrating-polynomials",
    "title": "39  Symbolic anti-differentiation",
    "section": "39.7 Integrating polynomials",
    "text": "39.7 Integrating polynomials\nOne of the most famous settings for integration comes from the physics of free fall under gravity.\nHere’s the setting. An object—a ball, let’s imagine—is being held at height \\(x_0\\). At \\(t=0\\) the ball is released. Perhaps the ball is released from a standstill in which case it is velocity at release is \\(v_0 = v(t=0) =0\\). Or perhaps the ball has been tossed upward so that \\(v_0 &gt; 0\\), or downward so that \\(v_0 &lt; 0\\). Whichever it is, the initial velocity will be labelled \\(v_0\\).\nOn release, the force that held the ball steady is removed and the object moves under the influence of only one factor: gravity. The effect of gravity near the Earth’s surface is easy to describe: it accelerates the object at a constant rate of about 9.8 m/s\\(^2\\).\nAcceleration is the derivative with respect to time of velocity. Since we know acceleration, to find velocity we find an anti-derivative of acceleration: \\[v(t) = \\int -9.8\\ dt = -9.8\\ t + C\\] The constant of integration \\(C\\) is not just a formality. It has physical meaning. In this case, we see that \\(C=v(0)\\), that is, \\(C = v_0\\).\nVelocity is the derivative of position: height in this case. So height is an anti-derivative of velocity. \\[x(t) = \\int v(t) dt = \\int \\left[\\strut -9.8\\ t + v_0\\right]dt = - \\frac{9.8}{2} t^2 + v_0\\ t + C\\] Why is \\(C\\) back again? it is a convention to use \\(C\\) to denote the constant of integration. Those experienced with this convention know, from context, that the value of \\(C\\) in the integration that produced \\(v(t)\\) has nothing to do with the value of \\(C\\) involved in the production of \\(x(t)\\). The situation is a bit like the presentation of prices in US stores: to the price of the item itself, you must always add “plus taxes.” Nobody with experience would assume that “taxes” is always the same number. It depends on the price and type of the item itself.4 You won’t have to deal with the taxes at the time you pick the item from the shelf, but eventually you will see them when you check out of the store. Think of \\(+\\ C\\) as meaning, “plus some number that we will have to deal with at some point, but not until checkout.”\nLet’s checkout the function \\(x(t)\\) now. For that, we need to figure out the value of \\(C\\). We can do that by noticing that \\(x(0) = C\\). So in the anti-differentiation producing \\(x()\\), \\(C = x_0\\) giving, altogether the formula for free-fall famous from physics classes \\[x(t) =  - \\frac{9.8}{2} t^2 + v_0\\ t + x_0\\] An important thing to notice about \\(x(t)\\): it is a polynomial in \\(t\\). Polynomials can be birthed by successive anti-differentiations of a constant. At each anti-differentiation, each of the previous terms is promoted by one order. That is, the previous constant becomes the first order term. The previous first-order term becomes the second order term, with the division by 2 familiar from anti-differentiating \\(t\\). A previous second-order term will become the new third-order term, again with the division by 3 familiar from anti-differentiating \\(t^2\\).\nStated generally, the anti-derivative of a polynomial is\n\\[{\\Large\\int} \\left[\\strut \\underbrace{a + b t + ct^2 + \\ldots}_\\text{original polynomial}\\right] dt = \\underbrace{C + a\\,t + \\frac{b}{2} t^2 + \\frac{c}{3} t^3 + \\ldots}_\\text{new polynomial}\\] By use of the symbol \\(C\\), it is easy to spot how the constant of integration fits in with the new polynomial. But if we were to anti-differentiate the new polynomial, we had better replace \\(C\\) with some more specific symbol to that we don’t confuse the old \\(C\\) with the one that is going to be produced in the new anti-differentiation.\n\n\n\n\n\n\nTip\n\n\n\nIn exercise 26.16, we introduced a Taylor polynomial approximation to the gaussian function. That might have seemed like a mere exercise in high-order differentiation at the time, but there is something more important at work.\nThe gaussian is one of those functions for which the anti-derivative cannot be written exactly in terms of what the mathematicians call “elementary functions.” (See Section 39.1.) Yet integrals of the gaussian are very commonly used in science, especially in statistics where the gaussian is called the normal PDF.\nThe approach we’ve taken in this book is simply to give a name and a computer implementation of the anti-derivative of the gaussian. This is the function we’ve called \\(\\pnorm()\\) with the R computer implementation pnorm().\nWe never told you the algorithm contained in pnorm(). Nor do we really need to. We all depend on experts and specialists to design and build the computers we use. The same is true of software implementation of functions like pnorm(). And for that matter, for implementations of functions like exp(), log(), sin(), and so on. You don’t have to know about semi-conductors to use a computer productively, and you don’t need to know about numerical algorithms to use those functions.\nOne feasible algorithm for implementing \\(\\pnorm()\\) is to integrate the Taylor polynomial. It is very easy integrate polynomials. To ensure accuracy, different Taylor polynomials can be computed for different centers, say \\(x=0\\), \\(x=1\\), \\(x=2\\), and so on.\nAnother feasible approach integrates \\(\\dnorm()\\) numerically using an advanced algorithm such as Gauss-Hermite quadrature.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Accumulation/38-symbolic.html#footnotes",
    "href": "Accumulation/38-symbolic.html#footnotes",
    "title": "39  Symbolic anti-differentiation",
    "section": "",
    "text": "One small deviation from the pattern-book functions is \\(\\int \\frac{dx}{x} = \\ln(|x|)\\). The absolute value \\(|x|\\) in \\(\\ln(|x|)\\) reflects the differing domains of the functions \\(\\ln(x)\\) and \\(1/x\\). Logarithms are defined only the positive half of the number line, while the reciprocal function \\(1/x\\) is defined for all non-zero \\(x\\). Including the absolute value in the argument to log covers situations such as \\(\\int_{-2}^{-1} \\frac{dx}{x}\\) which has the value \\(\\ln(2)\\).↩︎\nMathematicians have a list that is a bit longer than our pattern-book functions—they call them elementary functions and include the tangent and other trig functions and their inverses, as well as what are called “hyperbolic functions” and their inverses.↩︎\nAgain, mathematicians prefer to refer to the “elementary functions” rather than the pattern-book functions. \\(\\dnorm()\\) and \\(\\pnorm()\\) are not elementary functions, and there are several elementary function that we don’t include in the pattern-book list.↩︎\nMany jurisdictions tax food and clothing, etc. at a different rate than other items.↩︎",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Symbolic anti-differentiation</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html",
    "href": "Dynamics/B6-diff-eq.html",
    "title": "40  Differential equations",
    "section": "",
    "text": "40.1 Dynamical systems\nIn this Block, we take on what an important application of derivatives: the representation of dynamical systems.\n“Dynamical systems” (but not under that name) were developed initially in the 1600s to relate planetary motion to the force of gravity. Nowadays, they are used to describe all sorts of physical systems from oscillations in electrical circuits to the ecology of interacting species to the spread of contagious disease.\nAs examples of dynamical systems, consider a ball thrown thrown through the air or a rocket being launched to deploy a satellite. At each instant of time, a ball has a position—a point in \\(x,y,z\\) space—and a velocity \\(\\partial_t x\\), \\(\\partial_t y\\), and \\(\\partial_t z\\). These six quantities, and perhaps others like spin, constitute the instantaneous state of the ball. Rockets have additional components of state, for example the mass of the fuel remaining.\nThe “dynamical” in “dynamical systems” refers to the change in state. For the ball, the state changes under the influence of mechanisms such as gravity and air resistance. The mathematical representation of a dynamical system codifies how the state changes as a function of the instantaneous state. For example, if the instantaneous state is a single quantity called \\(x\\), the instantaneous change in state is the derivative of that quantity: \\(\\partial_t x\\).\nTo say that \\(x\\) changes in time is to say that \\(x\\) is a function of time: \\(x(t)\\). When we write \\(x\\), we mean \\(x()\\) evaluated at an instant. When we write \\(\\partial_t x\\), we mean “the derivative of \\(x(t)\\) with respect to time” evaluated at the same instant as for \\(x\\).\nThe dynamical system describing the motion of \\(x\\) is written in the form of a differential equation, like this:\n\\[\\partial_t x = f(x)\\ .\\] Notice that the function \\(f()\\) is directly a function of \\(x\\), not \\(t\\). This is very different from the situation we studied in Block 3, where we might have written \\(\\partial_t y = \\cos\\left(\\frac{2\\pi}{P} t\\right)\\) and assigned you the challenge of finding the function \\(y(t)\\) by anti-differentiation. (The answer to the anti-differentiation problem, of course, is \\(y(t) = \\frac{P}{2\\pi}\\sin\\left(\\frac{2\\pi}{P} t\\right) + C\\).)\nDynamical systems with multiple state quantities are written mathematically as sets of differential equations, for instance: \\[\\partial_t y = g(y, z)\\\\\n\\partial_t z = h(y, z)\\] We typically use the word system rather than “set,” so a dynamical system is represented by a system of differential equations.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Differential equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#dynamical-systems",
    "href": "Dynamics/B6-diff-eq.html#dynamical-systems",
    "title": "40  Differential equations",
    "section": "",
    "text": "Tip\n\n\n\nIt is essential that you train yourself to distinguish two very different statements\n\nanti-differentiation problems like \\(\\partial_{\\color{blue}{t}} y = g(\\color{blue}{t})\\), which has \\(t\\) as both the with-respect-to variable and as the argument to the function \\(g()\\).\n\nand\n\ndynamical systems like \\[\\partial_{\\color{blue}{t}} \\color{magenta}{y} = g(\\color{magenta}{y})\\ .\\]\n\nThis is one place where Leibniz’s notation for derivatives can be useful: \\[\\underbrace{\\frac{d\\color{magenta}{y}}{d\\color{blue}{t}} = g(\\color{blue}{t})}_{\\text{as in antidifferentiation}}\\ \\ \\ \\text{versus}\\ \\ \\ \\underbrace{\\frac{d\\color{magenta}{y}}{d\\color{blue}{t}} = g(\\color{magenta}{y})}_{\\text{dynamical system}}\\]\n\n\n\n\nApplication area 40.1  \n\n\n\n\n\n\n\nApplication area 40.1 Dynamics and board games\n\n\n\nLet’s illustrate the idea of a dynamical system with a children’s game: “Chutes and Ladders”. Since hardly any children have studied calculus, the game isn’t presented as differential equations, but as a simple board and the rules for the movement along the board.\n\n\n\n\n\n\n\n\nFigure 40.1: The game of Chutes and Ladders\n\n\n\n\n\nA player’s state in this game is shown by the position of a token, but we will define the state to be the number of the square that the player’s token is on. In Chutes and Ladders the state is one of the integers from 1 to 100. In contrast, the dynamical systems that we will study with calculus have a state that is a point on the number line, or in the coordinate plane, or higher-dimensional space. Our calculus dynamical system describe the change of state using derivatives with respect to time, whereas in chutes and ladders the state jumps from one value to the next value.\nThe game board displays not only the set of possible states but also the rule for changing state jumping from one state to another.\nIn the real game, players roll a die to determine how many steps to take to the next state. But we will play a simpler game: Just move one step forward on each turn, except … from place to place there are ladders that connect two squares. When the state reaches a square holding the foot of a ladder, the state is swept up to the higher-numbered square at the top of the ladder. Similarly, there are chutes. These work much like the ladders but carry the state from a higher-numbered square to a lower-numbered square.\nThe small drawings on the board are not part of the action of the game. Rather, they represent the idea that good deeds lead the player to progress, while wrong-doing produces regression. Thus, the productive gardener in square 1 is rewarded by being moved upward to the harvest in square 38. In square 64 a brat is pulling on his sister’s braids. This misdeed results in punishment: he is moved back to square 60.\nOur dice-free version of Chutes and Ladders is an example of a discrete-time, discrete-state dynamical system. Since there is no randomness involved, the movement of the state is deterministic. (With dice, the movement would be stochastic.)\nThe differential equations of a dynamical system correspond to a continuous-time, continuous-space system. This continuity is the reason we use derivatives to describe the motion of the state. The movement in the systems we will explore is also deterministic. (In ?sec-forcing we will encounter briefly some instances of stochastic systems.)",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Differential equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#state",
    "href": "Dynamics/B6-diff-eq.html#state",
    "title": "40  Differential equations",
    "section": "40.2 State",
    "text": "40.2 State\nThe mathematical language of differential equations and dynamical systems is able to describe a stunning range of systems, for example:\n\nphysics\n\nswing of a pendulum\nbobbing of a mass hanging from a spring.\na rocket shooting up from the launch pad\n\ncommerce\n\ninvestment growth\ngrowth in equity in a house as a mortgage is paid up. (“Equity” is the amount of the value of the house that belongs to you.)\n\nbiology\n\ngrowth of animal populations, including predator and prey.\nspread of an infectious disease\ngrowth of an organism or a crop.\n\n\nAll these systems involve a state that describes the configuration of the system at a given instant in time. For the growth of a crop, the state would be, say, the amount of biomass per unit area. For the spread of infectious disease, the state would be the fraction of people who are infectious and the fraction who are susceptible to infection. “State” in this sense is used in the sense of “the state of affairs,” or “his mental state,” or “the state of their finances.”\nSince we are interested in how the state changes over time, sometimes we refer to it as the dynamical state.\nOne of the things you learn when you study a field such as physics or epidemiology or engineering is what constitutes a useful description of the dynamical state for different situations. In the crop and infectious disease examples above, the state mentioned is a strong simplification of reality: a model. Often, the modeling cycle leads the modeler to include more components to the state. For instance, some models of crop growth include the density of crop-eating insects. For infectious disease, a model might include the fraction of people who are incubating the disease but not yet contagious.\nConsider the relatively simple physical system of a pendulum, swinging back and forth under the influence of gravity. In physics, you learn the essential dynamical elements of the pendulum system: the current angle the pendulum makes to the vertical, and the rate at which that angle changes. There are also fixed elements of the system, for instance the length of the pendulum’s rod and the local gravitational acceleration. Although such fixed characteristics may be important in describing the system, they are not elements of the dynamical state. Instead, they might appear as parameters in the functions on the right-hand side of the differential equations.\nTo be complete, the dynamical state of a system has to include all those changing aspects of the system that allow you to calculate from the state at this instant what the state will be at the next instant. For example, the angle of the pendulum at an instant tells you a lot about what the angle will be at the next instant, but not everything. You also need to know which way the pendulum is swinging and how fast.\nFiguring out what constitutes the dynamical state requires knowledge of the mechanics of the system, e.g. the action of gravity, the constraint imposed by the pivot of the pendulum. You get that knowledge by studying the relevant field: electrical engineering, economics, epidemiology, etc. You also learn what aspects of the system are fixed or change slowly enough that they can be considered fixed. (Sometimes you find out that something your intuition tells you is important to the dynamics is, in fact, not. An example is the mass of the pendulum.)",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Differential equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#state-space",
    "href": "Dynamics/B6-diff-eq.html#state-space",
    "title": "40  Differential equations",
    "section": "40.3 State space",
    "text": "40.3 State space\nThe state of a dynamical system tells you the configuration of the system at any instant in time. It is appropriate to think about the instantaneous state as a single point in a state space, a coordinate system with an axis for each component of state. As the system configuration changes with time—say, the pendulum loses velocity as it swings to the left—the instantaneous state moves along a path in the state space. Such a path is called a trajectory of the dynamical system.\nIn this book, we will work almost exclusively with systems that have a one- or two-dimensional state. Consequently, the state space will be either the number line or the coordinate plane. The methods you learn will be broadly applicable to systems with higher-dimensional state.\nFor the deterministic dynamical systems we will be working with, a basic principle is that a trajectory can never cross itself. This can be demonstrated by contradiction. Suppose a trajectory did cross itself. This would mean that the motion from the crossing point couple possibly go in either of two directions; the state might follow one branch of the cross or the other. Such a system would not be deterministic. Determinism implies that from each point in state space the flow goes only in one direction.\nThe dimension of the state space is the same as the number of components of the state; one axis of state space for every component of the state. has important implications for the type of motion that can exist.\n\nIf the state space is one-dimensional, the state as a function of time must be monotonic. Otherwise, the trajectory would cross itself, which is not permitted.\nA state space that is two- or higher-dimensional can support motion that oscillates back and forth. Such a trajectory does not cross itself, instead it goes round and round in a spiral or a closed loop.\n\nFor many decades, it was assumed that all dynamical systems produce either monotonic behavior or spiral or loop behavior. In the 1960s, scientists working on a highly simplified model of the atmosphere discovered numerically that there is a third type of behavior, the irregular and practically unpredictable behavior called chaos. To display chaos, the state space of the system must have at least three elements.\n\nApplication area 40.2 —Describing mathematically the dynamics of an epidemic.\n\n\n\n\n\n\n\nApplication area 40.2 The state of COVID\n\n\n\nWhat does it take to describe the dynamical state of an epidemic?\nNews reports of the COVID pandemic usually focus on the number of new cases each day and the fraction of the population that has been vaccinated. But this is not adequate, even for a simple description of the dynamics.\nFrom a history of new-case counts over time (e.g. ?fig-NYT-covid-history) you can see that the number of new cases waxes and wanes. Knowing that the number of cases today is, say, 100 thousand does not tell you what the number of cases will be in two weeks: 100 thousand is encountered both on the way up and on the way down.\n\n\n![COVID-19 new-case counts in the US over the first two years of the pandemic. Source: [New York Times]]](www/NYT-covid-report.png){#fig-NYT-covid-history fig-align=‘center’ width=90%}",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Differential equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#dynamics",
    "href": "Dynamics/B6-diff-eq.html#dynamics",
    "title": "40  Differential equations",
    "section": "40.4 Dynamics",
    "text": "40.4 Dynamics\nThe dynamics of a system is a description of how the individual components of the state change as a function of the entire set of components of the state.\nAt any instant in time, the state is a set of quantities. We will use \\(x\\), \\(y\\), and \\(z\\) for the purpose of illustration, although most of our work in this introduction will be with systems that have just one or two state variables.\nThe differential equations describing the \\(x, y, z\\) system have a particular form:\n\\[\\partial_t x(t) = f(x(t), y(t), z(t))\\ \\, \\\\\n\\partial_t y(t) = g(x(t), y(t), z(t))\\ \\, \\\\\n\\partial_t z(t) = h(x(t), y(t), z(t))\\ .\\]\nThe way these equations are written is practically impossible to read: the expression \\((t)\\) is repeated 12 times! It takes concentration to look beyond the \\((t)\\) to see the overall structure of the equations. to avoid this problem of not seeing the forest for the \\((t)\\)s, the convention is to omit the \\((t)\\): \\[\\partial_t x = f(x, y, z)\\\\\n\\partial_t y = g(x, y, z)\\\\\n\\partial_t z = h(x, y, z)\\] This leaves it to the reader to remember that \\(x\\) is really \\(x(t)\\) and so on.\nThis more concise way of writing the differential equations makes it easier to describe how to interpret the equations. Formally, \\(\\partial_t x\\) is a function, the derivative of the function \\(x(t)\\) with respect to time. But try to put this highly literal interpretation on a back burner. Think of the expression \\(\\partial_t x =\\) as meaning, “the way the \\(x\\)-component of state changes in time is described by ….” We need three differential equations because there are three components of state in the \\(x,y,z\\) system, and we need to describe for each component the way that component changes.\nOn the right side of each equation is a function that takes the state quantities as inputs. Each individual equation can be interpreted as completing the elliptical sentence (that is, ending in “…”) in the previous paragraph, so that the whole equation reads like, “The way the \\(x\\)-component of state changes at any instant in time is specified by the function \\(h()\\) evaluated at the instantaneous state.” These functions are called dynamical functions since they give the rules for the dynamics.\nRemember that \\(x\\), \\(y\\), and \\(z\\) are state variables, so they are all functions of time. At any instant in time, the values \\(x\\), \\(y\\), \\(z\\) have a specific value. Thus, at any instant in time, evaluating the functions \\(f(x, y, z)\\), \\(g(x, y, z)\\), and \\(h(x, y, z)\\) at the current state produces a specific, scalar value. If we wanted to make this perfectly explicit, we could write \\(g_x(x(t), y(t), z(t))\\), which makes it clear that the output of \\(g_x()\\) is a function of time.\n\n\n\n\n\n\nTip\n\n\n\nMathematically, a dynamical system consists of two things:\n\nThe state variables, which is a set of quantities that vary in time.\nThe dynamics, which is the set of dynamical functions, one function for each of the state variables.\n\n\n\nA simple example is the dynamics of retirement-account interest. In a retirement account, you put aside money—this is called “contributing”—each month. The value \\(V(t)\\) of the account accumulates over time, both due to new monthly deposits and to the interest \\(r\\) earned on the current account value. If you are setting aside \\(M\\) dollars per month, the dynamics are: \\[\\partial_t V = r V + M\\ .\\] The left-hand side of this equation is boilerplate for “the way the \\(V\\) component of state changes is described by the dynamical function \\(rV + M\\).” This is a function of \\(V\\) with parameters \\(r\\) and \\(M\\). In this example, there is just the one state variable \\(V\\), so the dynamical function has only one argument: \\(V\\).\nRemember that the dynamical function is something that the modeler constructs from her knowledge of the system. To model the dynamics of a pendulum requires some knowledge of physics. Without getting involved with the physics, we note that the oscillatory nature of pendulum movement means that there must be at least two state variables. A physicist learns that a good way to describe the motion uses these two quantities: the angle \\(\\theta(t)\\) of the pendulum rod with respect to the vertical and the angular velocity \\(v(t)\\) telling how the velocity changes with time. Since there are two state variables, there must be two dynamical functions. For a pendulum, one of the functions, the one for \\(\\partial_t v\\) comes from applying Newton’s Second Law: \\(F = m a\\). (Remember that \\(\\partial_t v\\) is an acceleration.) So one of the differential equations is \\[\\partial_t v  =  f(\\theta, v) \\equiv - \\sin(\\theta)\\]\nThe other equation comes from the definition that the derivative of the position \\(\\theta\\) is the velocity. \\[\\partial_t \\theta  =  g(\\theta, v) \\equiv  v\\\\\n\\]\n\n\n\n\n\n\nWhy?\n\n\n\nWhy define a state variable \\(v\\) when it is, by definition, the same as \\(\\partial_t \\theta(t)\\)?\nEven though the dynamical equation \\(\\partial_t \\theta(t) = v\\) is a calculus tautology, we need always to be explicit about what are the two quantities in the dynamical state. The \\(\\partial_t \\theta\\) differential equation comes for free from basic calculus concepts. The second equation is about the physics, that is, the relationship between forces and acceleration.\nThere is a style of writing dynamics equations that discards such tautologies. For example, the pendulum dynamics are often written \\[\\partial_{tt} \\theta(t) = - \\sin(\\theta)\\ .\\] This sort of equation, containing a second-order derivative, is called a second-order differential equation. In contrast, the two equations, one for \\(\\partial_t \\theta\\) and one for \\(\\partial_t v\\) are called first-order differential equations because each involves a first-order derivative. We will return to this second-order style in Chapter 47 since it is often encountered in physics and engineering. For now, we are avoiding the second-order style because it obscures the fact that there are two state variables: \\(\\theta(t)\\) and \\(v(t)\\).\n\n\n\nApplication area 40.3  \n\n\n\n\n\n\n\nApplication area 40.3 Interacting species\n\n\n\nConsider the population of two interacting species, say rabbits and foxes. As you know, the relationship between rabbits and foxes is rather unhappy from the rabbits’ point of view even if it is fulfilling for the foxes.\nMany people assume that such populations are more or less fixed: that the rabbits are in a steady balance with the foxes. In fact, as any gardener can tell you, some years there are lots of rabbits and others not: an oscillation. Just from this fact, we know that the dynamical state must have at least two components.\nIn a simple, but informative, model, the two components of the dynamical state are \\(r(t)\\) and \\(f(t)\\), the population of rabbits and foxes respectively. In the absence of foxes, the dynamics of rabbits are exponential growth; each successive generation is larger than the previous one. This can be described by a dynamical equation \\(\\partial_t r(t) = \\alpha r(t)\\), where \\(\\alpha\\) is a fixed quantity that describes rabbit fecundity.\nSimilarly, in the absence of food (rabbits are fox food), the foxes will starve or emigrate, so the dynamical equation for foxes is very similar \\(\\partial_t f(t) = - \\gamma f(t)\\), where \\(\\gamma\\) is a fixed quantity that indicates the rate at which foxes die or emigrate.\nOf course, in real ecosystems there are many other quantities that change and that are relevant. For instance, foxes eat not only rabbits, but birds and frogs and earthworms and berries. And the diet of rabbits eat weeds and grass (which is generally in plentiful supply), but also the gardener’s flowers and carrots (and other vegetables). Growth in the rabbit population leads to decrease in available flowers and vegetables, which in turn leads to slower growth (or even population decline) for rabbits.\nIn the spirit of illustrating dynamics, we will leave out these important complexities and imagine that the state consists of just two numbers: how many rabbits there are and how many foxes. The dynamics therefore involve two equations, one for \\(\\partial_t r\\) and one for \\(\\partial_t f\\). For the rabbit/fox model, we will allow the rabbit population change (\\(\\partial_t r\\)) to be affected by fox prediation and similarly let the fox population change (\\(\\partial_t f\\)) reflect the consumption of rabbits as food, writing: \\[\\partial_t r = \\ \\ \\ \\ \\ \\alpha\\, r - \\overbrace{\\beta\\, f r}^{\\text{fox predation}}\\\\\n\\partial_t f = \\underbrace{\\delta\\, r f}_{\\text{rabbits as food}} - \\gamma\\, f\\]\nThe quantities \\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\), and \\(\\delta\\) are parameters quantify the biology of the system: the reproduction rate of rabbits, the need of foxes for food (rabbits) to reproduce, the hunting success of foxes, and the death or emigration of foxes in response to a shortage of food.\nHow are you supposed to know that \\(r\\) and \\(f\\) are state variables while quantities like \\(\\beta\\) and \\(\\gamma\\) are parameters? Because there is a differential equation involving \\(\\partial_t r\\) and \\(\\partial_t f\\), while no differential equation has been given describing \\(\\partial_t \\beta\\) or \\(\\partial_t \\alpha\\).\nComing up with this description of dynamics requires knowing something about rabbits and foxes. The particular forms used, for instance the interaction term \\(r f\\), come from modeling experience. The interaction term is well named because it is about the literal, biological interaction of foxes and rabbits.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Differential equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#state-space-and-flow-field",
    "href": "Dynamics/B6-diff-eq.html#state-space-and-flow-field",
    "title": "40  Differential equations",
    "section": "40.5 State space and flow field",
    "text": "40.5 State space and flow field\nFor the purpose of developing intuition it is helpful to represent the instantaneous state as a point in a graphical frame and the dynamics as a field of vectors showing how, for each possible state, the state changes. For instance, in the Rabbit-Fox dynamics, the state is the pair \\((r, f)\\) and the state space is the coordinate plane spanned by \\(r\\) and \\(f\\).\nThe present state of the system might be any point in the state space. But once we know the present state, the dynamical functions evaluated at the present state tell us how the state changes over a small increment in time. The step over a small increment of time can be represented by a vector.\nLet’s illustrate with the Rabbit-Fox system, whose dynamical equations are given above. The dynamical functions take a position in state space as input. Each of the functions returns a scalar.\nTo make a plot, we need numerical values for all the parameters in those equations.\nThe vector field corresponding to the dynamics is called a flow, as if it were a pool of swirling water. Figure 40.2 shows the flow of the rabbit/fox system.\n\n\n\n\n\n\n\n\nFigure 40.2: The dynamics of the rabbit/fox system shown as a vector field over the state space. The parameters have been set, for the purpose of illustration, to \\(\\alpha = 2/3\\), \\(\\beta = 4/3\\), \\(\\gamma = 1\\), and \\(\\delta = 1\\).\n\n\n\n\n\nStaying with the analogy to a pool of swirling water or the currents in a river, you can place a lightweight marker such as a leaf at some point in the flow and follow its path over time. This path—position in state space as a function of time—is called the trajectory of the flow. There are many possible trajectories, depending on where you place the leaf.\nIn Chapter 49 we considered the path followed by a robot arm. In that chapter, we separated out the \\(x\\)- and \\(y\\)-components of the arm’s position over time, calling them functions \\(x(t)\\) and \\(y(t)\\). Analogously, the decomposition of a trajectory from an initial condition in the flow—this would be \\(r(t)\\) and \\(f(t)\\) for the rabbit/fox system—gives us the solution to the differential equation.\nEach component of the solution is called a time series and is often plotted as a function of time, for instance \\(r(t)\\) versus \\(t\\).\nFrom the flow field, you can approximate the trajectory that will be followed from any initial condition. Starting from the initial condition, just follow the flow. You already have some practice following a flow from your study of the gradient ascent method of optimization described in Chapter 24. At the argmax, the gradient is nil. Thus, the gradient ascent method stops at the argmax. We will see an analogous behavior in dynamical systems: any place where the flow is nil is a potential resting point for the state, called a fixed point.\n\nApplication area 40.4  \n\n\n\n\n\n\n\nApplication area 40.4 Flow field for a pendulum\n\n\n\nLet’s return to the pendulum and examine its flow field. We will modify the equations just a little bit to include air resistance in the model. Air resistance is a force, so we know it will appear in the \\(\\partial_t v_\\theta(t)\\) equation. A common model for air resistance has it proportional in size to the square of the velocity and with a direction that is the opposite of the velocity. In a differential equation, the model of air resistance can be written as \\(- \\alpha\\, L\\, \\text{sign}(v(t))\\ v(t)^2\\), where \\(\\text{sign}()\\) is a piecewise function that has the value \\(+1\\) when the argument is positive and \\(-1\\) when the argument is negative. \\(L\\) is the length of the pendulum. \\[\\partial_t \\theta = v\\\\\n\\partial_t v = - \\sin(\\theta) - \\alpha\\,L^2\\, \\text{sign}(v)\\ v^2\\] (Keep in mind as always that for dynamical systems a state variable like \\(\\theta\\) is also a function of time \\(\\theta(t)\\).) Whenever you have a state variable, you know that it is a function of time and so the explicit \\((t)\\) is often omitted for the sake of conciseness.\n?fig-pendulum-in-air shows the flow field of the pendulum. Also shown is a trajectory and the two time series corresponding to that trajectory.\n\n## Solution containing functions theta(t), v(t).\n\n\n\n\n\n\n\nFigure 40.3: The flow field of a pendulum with air resistance. From the initial condition (marked by \\(\\color{red}{\\text{x}}\\)), a trajectory is sketched out for \\(0 \\leq t \\leq 20\\). The individual components of that trajectory are graphed as time series.\n\n\n\n\n\n\n\n\n\n\n\nFigure 40.4: The flow field of a pendulum with air resistance. From the initial condition (marked by \\(\\color{red}{\\text{x}}\\)), a trajectory is sketched out for \\(0 \\leq t \\leq 20\\). The individual components of that trajectory are graphed as time series.\n\n\n\n\n\nThe pendulum was started out by lifting it to an angle of \\(45^\\circ\\) and giving it an initial upward velocity. The bob swings up for a bit before being reversed by gravity and swinging toward \\(\\theta = 0\\) and beyond. Due to air resistance, the amplitude of swinging decreases over time.\n\n\nThe flow of a dynamical system tells how different points in state space are connected. Because movement of the state is continuous in time and the state space itself is continuous, the connections cannot be stated in the form “this point goes to that point.” Instead, as has been the case all along in calculus, we describe the movement in terms of a “velocity” vector. Each dynamical function specifies one component of the “velocity” vector, taken together they tell the direction and speed of movement of the state at each instant in time.\nPerhaps it would be better to use the term state velocity instead of “velocity.” In physics and most aspects of everyday life, “velocity” refers to the rate of change of physical position of an object. Similarly, the state velocity tells the rate of change of the position of the state. It is a useful visualization technique to think of the state as an object skating around the state space in a manner directed by the dynamical functions. But the state space almost always includes components other than physical position. For instance, in the rabbit/fox model, the state says nothing about where individual rabbits and foxes are located in their environment; it is all about the density of animals in a region.\nIn physics, often the state space consists of position in physical state as well as the physical velocity in physical space. For instance, the state might consist of the three \\(x, y, z\\) components of physical position as well as the three \\(v_x, v_y, v_z\\) components of physical velocity. Altogether, that is a six-dimensional state space. The state velocity also has six components. Three of those components will be the “velocity of the velocity,” that is, the direction and speed with which the physical velocity is changing.\n\nApplication area 40.5  \n\n\n\n\n\n\n\nApplication area 40.5 Board-game flow\n\n\n\nReturning to the Chutes and Ladders game used as an example near the start of this chapter …\nThe state in chutes and ladders is one of the hundred numbers 1, 2, \\(\\ldots\\), 100. This is a discrete state space. Therefore, we can describe the “flow” in a very concrete way: how each state is directly connected to another. Figure 40.5 shows these connections. There is no velocity involved because there is no infinitesimal movement of state. For instance, state 47 connects directly to state 26.\n\n\n\n\n\n\n\n\nFigure 40.5: The “flow” connecting the discrete states in the dice-free Chutes and Ladders game. Source: Maj. Austin Davis\n\n\n\n\n\nIn the no-dice game, the state follows the arrows. Looking carefully at Figure 40.5, you can see that each state has a forward connection to at most one state. This is the hallmark of determinism.\nIn the children’s game, the play is not deterministic because a die is used to indicate which state follows from each other state. A die has six faces with the six numbers 1 to 6. So, each state is connected to six other states in the forward direction. Which of the six is to be followed depends on the number that comes up on the die. Multiple forward connections means the dynamics are stochastic (random).\nStraightforward examination of the flow often tells you a lot about the big picture of the system. In dice-free Chutes and Ladders, The 100 states are divided into three isolated islands. State 1 is part of the island in the lower right corner of Figure 40.5. Follow the arrows starting from any place on that island and you will eventually reach state 84. And state 84 is part of a cycle \\(84 \\rightarrow 85 \\rightarrow \\cdots \\rightarrow 28 \\rightarrow 84 \\rightarrow \\cdots\\). Once you are on that cycle, you never get off. We will see such cycles in continuous-time dynamical systems as well.\n\n\n\n\n\n\n\n\nCalculus history—Numerical weather forecasting\n\n\n\nWeather forecasting by numerical process is a highly influential book, from 1922, by Lewis Fry Richardson. He envisioned a calculation for a weather forecast as a kind of function. The domain for the forecast is the latitude and longitude of a point on the globe, rather than the rectilinear organization of corridor.\nOne fantastic illustration of the idea shows a building constructed in the form of an inside-out globe. Source At each of many points on the globe, there is a business. (You can see this most easily in the foreground, which shows several boxes of workers.)\n\n\n\n\n\n\n\n\nFigure 40.6: An artist’s depiction of the organization of calculations for weather forecasting by Richardson’s system.\n\n\n\n\n\nIn each business there is a person who will report the current air pressure at that point on the globe, another person who reports the temperature, another reporting humidity, and so on. To compute the predicted weather for the next day, the business has a staff assigned to visit the neighboring businesses to find out the pressure, temperature, humidity, etc. Still other staffers take the collected output from the neighbors and carry out the arithmetic to translate those outputs into the forecast for tomorrow. For instance, knowing the pressure at neighboring points enables the direction of wind to be calculated, thus the humidity and temperature of air coming in to and out of the region the business handles. In today’s numerical weather prediction models, the globe is divided very finely by latitude, longitude, and altitude, and software handles both the storage of present conditions and the calculation from that of the future a few minutes later. Repeating the process using the forecast enables a prediction to be made for a few minutes after that, and so on.\nSome of the most important concepts in calculus relate to the process of collecting outputs from neighboring points and combining them: for instance finding the difference or the sum. To illustrate, here is the first set of equations from Richardson’s Weather forecasting … written in the notation of calculus:\n\n\n\n\n\n\n\n\n\nYou can hardly be expected at this point to understand the calculations described by these equations, which involve the physics of air flow, the coriolis force, etc. but it is worth pointing out some of the notation:\n\nThe equations are about the momentum of a column of air at a particular latitude (\\(\\phi\\)) and longitude.\n\\(M_E\\) and \\(M_N\\) are east-west and north-south components of that momentum.\n\\(\\partial M_E /\\partial t\\) is the rate at which the east-west momentum will change in the next small interval of time (\\(\\partial t\\)).\n\\(p_G\\) is the air pressure at ground level from that column of air.\n\\(\\partial p_G / \\partial n\\) is about the difference between air pressure in the column of air and the columns to the north and south.\n\nCalculus provides both the notation for describing the physics of climate and the means to translate this physics into arithmetic calculation.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Differential equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-solution.html",
    "href": "Dynamics/B6-solution.html",
    "title": "41  Finding a “solution”",
    "section": "",
    "text": "41.1 The flow field\nWith a pair of differential equations, as with the pendulum or the rabbit-fox model, each equation gives one component of the change in state. To draw the flow at single point in state space, evaluate the dynamical functions at that point. Each dynamical function contributes, as its output, one of the components of the state velocity vector. If the parameters in the model have been assigned numerical values, the result of evaluating the right-hand sides will be two numbers.\nA case in point is the rabbit-fox system. The axes in the rabbit-fox state space are denominated in units of rabbit density \\(r\\) and fox density \\(f\\). The differential equations are \\[\\begin{eqnarray}\n\\partial_t r & = & 0.66 r - 1.33 r f\\\\\n\\partial_t f & = & -f + rf\\\\\n\\end{eqnarray}\\]\nTo to find the state velocity at, say, \\(r=2, f=1/4\\), plug those values into the right-hand side:\n\\(\\partial_t r  = 1.33 - 0.66   = 0.66\\ \\ \\ \\)rabbit density per month\n\\(\\partial_t f  = -0.25 + 0.5 = 0.25\\ \\ \\ \\)fox density per month.\nOnce you know the numerical vector value of the state velocity, you need to convert it to a form suitable for plotting in the state space. The conversion is needed because the state space is denominated in rabbit density and fox density, not in rabbit density per month or fox density per month. The conversion is accomplished by multiplying the state velocity vector by a small \\(dt\\), say, 0.1 months.\nThe conversion produces a vector whose components are denominated in the same way as the state space and thus can be plotted meaningfully in the state space.\nTo illustrate, let’s draw a flow vector for the state space coordinate \\((r=2, f = 1/4)\\). Above, we already calculated the components of the state velocity vector;Given the value \\(\\partial_t f = 0.25\\) and \\(\\partial_t f = 0.66\\). For the sake of illustration, we will set \\(dt = 0.1\\) month. Consequently, the vector to be plotted will be \\((0.25, 0.66) dt = (0.025, 0.066)\\)$ with units of rabbit density and fox density respectively. the right. This flow arrow is drawn in Figure 41.1.\nFigure 41.1: The flow arrow for the state value \\((r=2, f=1/4)\\) using \\(dt=0.1\\) month.\nTo draw the entire flow field, repeat this process at many other points in the state space as in Figure 41.2.\nSome people prefer a visualization of short segments of actual trajectories, as in the right panel in Figure 41.2, rather than the state velocity vector. This is a matter of personal preference.\nWith the flow field depicted in sufficient detail, you can now trace out trajectory.\nTo trace out a trajectory, select a initial condition for the system. Then follow the flow, taking only a small step in state space. The next step should be in the direction of the flow arrow at the end of the previous step.\nThe trajectory you draw will be only a sketch, but it can be effective for developing intuition. Figure 41.3 shows a semi-automated version of the go-with-the-flow method. The computer has been used to draw the arrows. When you click in the plot, the computer also undertakes calculation of the trajectory.\nRegrettably, from such a sketch of the trajectory, you cannot easily construct \\(r(t)\\) and \\(f(t)\\) for time-series plots. Also, you don’t get a sense of how slow or fast the flow is going. Click at different initial conditions in the flow and you will see different trajectories, each of which is a closed loop, the sort of cycles seen in the dice-free Chutes and Ladders game. But the shape of the trajectory does not tell you whether it takes a long time or a short time to complete a loop.\nThe next section will show you how the computer constructed the trajectory and how we can get information on the speed of the flow.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Finding a \"solution\"</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-solution.html#the-flow-field",
    "href": "Dynamics/B6-solution.html#the-flow-field",
    "title": "41  Finding a “solution”",
    "section": "",
    "text": "The flow field depicted by drawing the state velocity vector (multiplied by \\(dt = 0.1\\) to turn it into a length) for many points in the state space.\n\n\n\n\n\n\n\nInstead of plotting the state velocity vector, small snippets of trajectories of duration 0.1 are shown.\n\n\n\n\n\n\n\nFigure 41.2: The flow in the rabbit-fox system shown in two ways.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 41.3: The flow field for the rabbit/fox dynamics. Click at an initial state to generate the trajectory from that state. You may need to pinch in or out to see the flow arrows clearly.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Finding a \"solution\"</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-solution.html#euler-method",
    "href": "Dynamics/B6-solution.html#euler-method",
    "title": "41  Finding a “solution”",
    "section": "41.2 Euler method",
    "text": "41.2 Euler method\nRecall from Block 2 the limit definition of the derivative: \\[\\partial_t x(t) = \\lim_{dt \\rightarrow 0} \\frac{x(t + dt) - x(t)}{dt}\\ .\\] we will use this definition to develop a very general way to solve differential equations: the Euler method.\nThe differential equations specify the values of \\(\\partial_t x(t)\\) in terms of the dynamical function. In Block 2, we paid attention to whether the limit exists. But here, we know it must because the dynamical functions themselves don’t involve limits. In working with the differential equation it suffices to pick some small, finite \\(dt\\). How small? Pick \\(dt\\) to be small enough that the result wouldn’t change in any substantial way if we used an even smaller time increment, say \\(dt/10\\).\nOur starting point for solving each differential equation is to re-write it as a finite difference. To illustrate, we will solve the equation \\(\\partial_t x = x (1 - x)\\), which is often called the logistic equation.\nApplying the finite difference definition, we get \\[\\underbrace{\\frac{f(t + dt)- f(t)}{dt}}_{\\text{finite-difference approx.}} = \\underbrace{x (1-x)}_{\\text{dynamical function}}\\ .\\] Multiplying both sides of the above by \\(dt\\) and re-arranging terms produces \\[\\underbrace{f(t + dt)}_{\\text{future state}} = \\underbrace{f(t)}_{\\text{current state}} +\\ \\ \\  \\underbrace{x (1-x) dt}_{\\text{step}}\\] We call this last equation the Euler formula.\nTo use this, we start at the initial condition, say \\(x(t=0) = 0.2\\). This initial condition gives us the first row of a tabular representation of the function \\(x(t)\\): Table 41.1.\n\n\n\n\n\nTable 41.1: Initial state\n\n\n\n\n\ntime\nstate\n\n\n\n\n0\n0.2\n\n\n\n\n\n\n\n\n\n\nTable 41.2: The next time step.\n\n\n\n\n\ntime\nstate\n\n\n\n\n0.0\n\\(0.2\\)\n\n\n0.1\n\\(0.2 + \\color{brown}{0.016} = \\color{blue}{0.216}\\)\n\n\n\n\n\n\n\n\n\n\nTable 41.3: Still another time step\n\n\n\n\n\ntime\nstate\n\n\n\n\n0.0\n\\(0.2\\)\n\n\n0.1\n\\(0.2 + \\color{brown}{0.016} = \\color{blue}{0.216}\\)\n\n\n0.2\n\\(\\color{blue}{0.216} + \\color{magenta}{0.0169} = 0.2329\\)\n\n\n\n\n\n\n\n\nNext, pick a value for \\(dt\\) that we will use for all the following steps, each of which will add a new row to the table. For the example, we will set \\(dt = 0.1\\). When we have constructed the whole table we can go back and check whether that was small enough.\nTo fill in the next row, as in Table 41.2, we apply the Euler formula. Sine \\(dt = 0.1\\), the next time step will be \\(0.1\\). Plug in the current state—which is 0.2 right now—to calculate the future state. The step will be \\(0.2 (1-0.2)\\, dt = \\color{brown}{0.016}\\). Add this step to the current state to get the future state.\nThe next step is shown in Table 41.3 and will bring us to time \\(0.2\\). Use the Euler formula, pluggin in the value of the present state, \\(\\color{blue}{0.216}\\), to find the step. Here that will be \\(0.216 (1-0.216)\\, dt = \\color{magenta}{0.0169.}\\).\nAdd as many rows to the table as you like; the process will be the same for each step, the new row being calculated from the values in the previous row.\nRecognize that this is an iterative process.\n\n\n\n\n\n\n\n\n\nEuler iteration\n\n\n\nAs is so often the case, it is wise to think about carrying out processes in terms of fundamental tasks accomplished by calculus operations—evaluate, differentiate, anti-differentiate, solve, find argmax, iterate. The obvious choice for integrating differential equations is “anti-differentiate,” but as described previously, the techniques we covered in Block 3 are not sufficient for the task. Instead, we use iteration to solve differential equations.\nThis example uses the software you have already seen, Iterate(), to carry out the task. In practice, however, you will use a special form of Iterate() called integrateODE() that makes use of interpolation techniques to give a more precise answer.\nTo implement the iteration to solve \\(\\partial_t x = x (1-x)\\), we need to create a function that takes the current state as input and produces the next state as output. Our one-step function can be this:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice that we wrote next_step() with an input slot for \\(dt\\). This will not be part of the state being iterated, just a parameter that allows us easily to explore different values for \\(dt\\).\nUse Iterate() to carry out the iteration of next_step(). Note that we use the fargs argument to Iterate() to pass our selected value for dt to the function next_step(). We will run the iteration for 100 steps. With \\(dt=0.1\\), those 100 steps will 10 units of time.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOr, in graphical form ….\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\nTry it! 41.1\n\n\n\n\n\n\n\n\n\nTry it! 48.4 Iterate vs integrateODE\n\n\n\nThe previous example used Iterate() to solve a differential equation. The output of the iteration was a data frame containing values for the solution at discrete times: 0, 0.1, 0.2, and so on. A data table is a perfectly good way to represent a function, but it is handier to have a function in a form that operations like slice_plot() and D() can be applied to. Another way to look at things is that, mathematically, the solution to a differential equation should be a continuous-time function. Fortunately, we have at hand the interpolation techniques covered in Chapter 49 to carry out the construction of a continuous-time function from a tabular representation. The R/mosaic function integrateODE() connects together the iteration and interpolation to provide a solution that is in the form of continuous-time function(s).\nUse the R/mosaic function integrateODE() to solve differential equations numerically. It is a specialized function that handles sets of first-order differential equations, but any high-order differential equation can be separated into a set of first-order equations.\nTo illustrate, this command will solve the differential equation \\(\\partial_t x = x (1-x)\\) that we took on in the previous example with Iterate().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe first argument is a tilde expression, but in a form that is different from from that used in functions such as D() or contour_plot(), etc. To the left of the tilde is a single name composed of the state variable—x here—prefixed by a d. The d is just a reminder that we are describing not x itself, but \\(\\partial_t\\ \\mathtt{x}\\). On the right of the tilde is the function from the differential equation, in this case, \\(x(1-x)\\).\nThe next argument is the initial condition. We are starting the integration at \\(x=0.2\\). The bounds() sets the time interval for the integration and dt sets the time step..\nThe output of integrateODE() is an R structure of a type called a “list” that is new to us. The list contains the function(s) created by integrateODE() which you refer to by name (x) using a special form of R punctuation $ suited to lists.. In other words, Soln2$x will be a function, which you can plot like any other function, for instance:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis use of the R symbol $ is new to us. We won’t emphasize it here. Instead, we’ll use the traj_plot() graphics function (introduced in Chapter 49) which already knows how to access the functions created by integrateODE().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAn important feature of integrateODE() is its ability to handle sets of first-order differential equations. For instance, the rabbit/fox system \\[\\partial_t r = 0.66\\, r - 1.33\\, r f\\\\\n\\partial_t f = -f + rf\\] will be integrated by this command:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou can plot the time series using slice_plot()\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTo plot the trajectory, simply change the tilde expression used in traj_plot(). which creates a time series plot, traj_plot() shows the trajectory.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Finding a \"solution\"</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-solution.html#sec-symbolic-solutions-ODE",
    "href": "Dynamics/B6-solution.html#sec-symbolic-solutions-ODE",
    "title": "41  Finding a “solution”",
    "section": "41.3 Symbolic solutions",
    "text": "41.3 Symbolic solutions\nOccasionally it is possible to integrate a differential equation using symbolic techniques. This is particularly true for differential equations that are linear. The example we will handle here is the first-order linear differential equation \\[\\partial_t x = a\\, x\\ .\\] An advantage of symbolic solutions is that parameters can be handled symbolically.\nA method we will use repeatedly in this block is called the “method of ansätze.” An ansatz (singular of the German “ansätze”) is, in this context, a guess for the solution. Since differential equations have been a central part of science for more than 200 years, you can imagine that a large library of equations and their solutions has been assembled. For the equations that are most frequently used and that can be solved symbolically, the solutions are already known. Thus, the “guess” for the solution can be a very well informed guess.\nLet’s see how this works for \\(\\partial_t x = a\\, x\\). From experience, the ansatz will be an exponential function of time, which we can write \\(x(t) \\equiv A e^{\\omega t}\\). We don’t yet know what is the value of \\(\\omega\\) or \\(A\\), so we plug the ansatz into both the left and right sides of the differential equation to work it out.\nPlugging in the ansatz, translates the differential equation to a new form: \\[\\underbrace{A \\omega e^{\\omega t}}_{\\partial_t x(t)}\\  =\\  \\underbrace{a A e^{\\omega t}}_{a x(t)}\\ .\\] Cancelling out the terms that appear on both sides of the equation gives \\[\\omega = a\\ \\ \\ \\text{which implies}\\ \\ \\ x(t) = A e^{a t}\\ .\\] The ansatz substitution didn’t give any result at all for \\(A\\). That is to say, unlike \\(\\omega\\), the \\(A\\) is not determined by the differential equation itself. This means that \\(A\\) must be related to the initial condition. Setting \\(t=0\\) gives \\(x(0) = A\\), so in this simple differential equation, \\(A\\) is the initial condition.\nA slightly more complex differential equation is \\[\\partial_t x = a\\, (x - b)\\ .\\] This also has an exponential solution. It is easiest to see this by defining a new variable \\(y \\equiv x - b\\). By the rules of differentiation, \\(\\partial_t y = \\partial_t x\\), so the differential equation can be re-written in the form \\(\\partial_t y = a y\\). We already know the solution to this is \\(y(t) = y_0 e^{a t}\\). Translating by to \\(x\\) we get \\[x(t) - b = (x_0 -b) e^{at}\\ \\ \\ \\implies x(t) = (x_0 -b)\\,e^{at} + b)\\ .\\]\nFor nonlinear dynamical function, there is no perfectly general way to find symbolic solutions. But for some dynamical functions, it can be done. we will demonstrate by integrating \\(\\partial_t x = x (1-x)\\). The method is made more plausible by using the Leibnizian notation for derivatives, with which the differential equation has this form: \\[\\frac{dx}{dt} = x(1-x)\\ .\\] The Leibnizian notation can be interpreted as the ratio of two differentials: \\(dx\\) and \\(dt\\) in this case.\nThe idea of separating the differential equation is to algebraically move all the \\(x\\) terms to the left side of the equation and all the \\(t\\) terms to the right and then to integrate each side of the equation. \\[dx = x(1-x) dt \\ \\ \\ \\implies \\ \\ \\ \\frac{1}{x(x-1)}dx = dt\\ \\ \\ \\implies\\ \\ \\ \\int\\frac{1}{x(x-1)}dx = \\int dt .\\]\nThe integral on the right side, \\(\\int dt\\), should be easily recognizable, giving \\(\\int dt = t + F\\), where \\(F\\) is the “constant of integration.”\nThe integral on the left side may not be as familiar, but the person solving this problem for the second time will remember that \\[\\frac{1}{x(1-x)} = \\frac{1}{x} + \\frac{1}{1-x}\\] as you can confirm by putting the right side over a common denominator. Each of \\(1/x\\) and \\(1/(1-x)\\) have integrals that are logs: \\(\\int dx/x = \\ln(x) + D\\) and \\(\\int dx/(1-x) = - \\ln(1-x) + E\\). Putting the equation back together again, produces \\[\\ln(x) + D - \\ln(1-x) + E = t + F\\ .\\] At this point, move all the constants of integration over to the right side and consolate them into a single constant of integration \\(C\\). At the same time, collect together the two logarithmic terms, giving: \\[\\ln\\left(\\frac{x}{1-x}\\right) = t + C\\ .\\] Exponentiate both sides to get: \\[\\frac{x}{1-x} = \\underbrace{e^C}_{A} e^t\\  .\\] Since \\(e^C\\) is just a constant, we will write it more simply as \\(A\\).\nNow we have \\[x = Ae^t - x A e^t \\ \\ \\implies\\ \\ \\ x (1 + Ae^t) = Ae^t\\] which gives our solution \\[x = \\frac{Ae^t}{1 + Ae^t}\\ .\\] To find the initial condition symbolically, plug in \\(t=0\\), giving \\(x_0 = A/(1+A)\\) or, equivalently \\(A = x_0/(1-x_0)\\). Our previous examples used \\(x_0 = 0.2\\), for which \\(A = 0.2/0.8 = 0.25\\). Graphing this solution gives us the familiar sigmoid:\n\nSymb_soln = makeFun(A*exp(t)/(1 + A*exp(t)) ~ t)\nslice_plot(Symb_soln(t, A=0.2) ~ t, bounds(t=-5:10))\n\n\n\n\n\n\n\n\nNot all differential equations can be separated in this way, and even for those that can, the integrals may not be tractable. So this route to a solution is not a general-purpose one, unlike the Euler method. Still, the Euler method gives only an approximate solution, so with Euler we need to take care that the approximation is close enough for the purpose at hand. In this case, we have both an Euler solution (with \\(dt=0.1\\)) and a symbolic solution. Figure 41.4 shows the difference between the two solutions, which ideally should be zero. To show more of the time domain of the solution, we will reset the initial condition to \\(x_0 = 0.01\\). This corresponds to \\(A = 1/99\\).\n\n\n\n\n\n\n\n\nFigure 41.4: The difference between the Euler and the symbolic solution to \\(\\partial_t x = x (1-x)\\) as a fraction of the symbolic solution. At the worst, the Euler solution is off by 1.5 parts in one-million.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Finding a \"solution\"</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html",
    "href": "Dynamics/B6-flow-on-line.html",
    "title": "42  Flows on the line",
    "section": "",
    "text": "42.1 Dynamical function and flow\nIn the previous chapter, we saw how to draw a flow field in a two-dimensional state space, evaluating the dynamical functions and using the results to construct a vector. We cannot practically visualize both the flow and the shapes of the two dynamical functions in a single plot, which makes it harder to understand structures such as fixed points.\nHappily, with a one-dimensional state space, we can easily show both the flow vectors and the single dynamical function at once.\nFor ease of reference, we will name the dynamical function for the rest of this section \\(f(x)\\), so that the differential equation is \\[\\partial_t x = f(x)\\ .\\]\nThe flow itself appears as the example in Figure 42.1. The state space is the number line and the flow vectors are, as usual arrows that point from place to place in the state space.\nFigure 42.1: A one-dimensional state space shown with its flow vectors.\nBecause the state space can be drawn without using the vertical coordinate of the page, we can use that vertical coordinate to show something else: the dynamical function, as in Figure 42.2.\nFigure 42.2: A one-dimensional state space shown with its flow vectors.\nThe correspondence between the dynamical function and the flow field is easy to see in such a presentation. Where the output of the dynamical is large and positive (say, near \\(x=0\\)), the flow is in the positive direction and relatively fast, as shown by a long, right-pointing flow vector. When the output of the dynamical function is negative (around \\(x=3\\), for instance) the flow is in the negative direction: a left pointing arrow.\nNear a zero crossing of the dynamical function, the flow arrows are negligibly short: the state velocity is very slow. Indeed, at the zero crossings, the state velocity is exactly zero. Such zero crossings are called fixed points: since the state velocity is zero, the state never moves!\nWe can see the dynamics near fixed points more closely by zooming in, as in Figure 42.3 which shows two of the system’s fixed points.\nFigure 42.3: Zooming in on the flow for the system shown in @fig-phase-line-intro2.\nNotice in Figure 42.3 that the flow is slower the nearer the state is to the fixed point, but it is only exactly zero at the fixed point.\nA calculus technique you will be familiar with from previous Blocks is zooming in a region that we want to examine in detail.\nFigure 42.4: Zooming in closely on each of the fixed points seen in @fig-phase-line-intro3.\nThe short pieces of the dynamical function shown in Figure 42.4, are, like short pieces of any continuous function: almost exactly straight lines. For the left fixed point, the dynamical function is \\(f(x) \\approx -2.804 (x + 3.055)\\) while for the right it is \\(f(x) \\approx 5.065 (x + 1.586)\\). In Section @ref(symbolic-solutions-ODE) we found symbolically the solutions for dynamical functions in this form. For \\(x_0\\approx-3.055\\) the solution is \\[x(t) \\approx (x_0 + 3.055)e^{-2.804 t} - 3.055\\ ,\\] while for \\(x_0\\approx -1.586\\) the solution is \\[x(t) \\approx (x_0 +1.586)\\, e^{5.065 t} - 1.586\\ .\\] There is something fundamentally different about these two solutions. One of them is exponential decay toward the fixed point, while the other grows exponentially away from the fixed point. We call the dynamics near the fixed-point with exponential decay stable and the dynamics near fixed-point with exponential growth unstable.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Flows on the line</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#dynamical-function-and-flow",
    "href": "Dynamics/B6-flow-on-line.html#dynamical-function-and-flow",
    "title": "42  Flows on the line",
    "section": "",
    "text": "Tip\n\n\n\nGraphics such as Figure 42.2 let you see both the flow and the dynamical functions together in one place.\nHow about also showing trajectories? Unfortunately, the two-dimensional extent of a computer screen or a piece of paper make it hard to include still more information in an intelligible way. It would be nice to have a third dimension for the display.\nMajor Austin Davis developed such a display, using time as the third dimension. In the movie below, the state space is shown as a horizontal line, as before. The vertical axis shows the dynamical function as in Figure 42.2. The dynamical function is shown in another way: as the hue and intensity of color, which lets you focus on the activity in the state space. This activity is shown by the moving gray triangles. Each triangle is placed on the phase line to mark an initial condition, then moves right or left according to the dynamics.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Flows on the line</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#generic-behavior",
    "href": "Dynamics/B6-flow-on-line.html#generic-behavior",
    "title": "42  Flows on the line",
    "section": "42.2 Generic behavior",
    "text": "42.2 Generic behavior\nSo long as two dynamical systems have similar fixed points with the same stability, their trajectories will be much the same. For example, our model dynamical function might be different in detail, as in Figure 42.5, and still produce the same behavior.\n\n\n\n\n\n\n\n\nFigure 42.5: The dynamical function shown in black is a distortion of \\(f(x)\\) from the previous plots. Yet the flow field is practically identical and leads to the same outcomes as \\(f(x)\\) for any initial condition.\n\n\n\n\n\nSo long as two flows have similar fixed points with the same stability, their trajectories will be much the same. Consequently, studying the fixed points without worrying about the details of the dynamics gives a huge amount of information about the system.\nFor example, Figure 42.6 shows a score of different time series following the solutions from a score of initial conditions. The long-term behaviors for all the time series is similar: they converge to one or another of the stable fixed points.\n\n## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\nFigure 42.6: Time series from the differential equation \\(\\partial_t x = f(x)\\) starting at many initial conditions. The locations of the three fixed points are marked with horizontal lines. All the solutions convert to one or the other of the two stable fixed points in the system, and depart from the unstable fixed point.\n\n\n\n\n\nIt is worth pointing out a consequence of the mathematics of continuous functions: if a system with a continuous dynamical function has a region of state space with two different fixed points, there must be an unstable fixed point in between them.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Flows on the line</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#linearization",
    "href": "Dynamics/B6-flow-on-line.html#linearization",
    "title": "42  Flows on the line",
    "section": "42.3 Linearization",
    "text": "42.3 Linearization\nYou can see in Figure 42.6 that many of the solutions approach their final, equilibrium value in an exponential manner. This is particularly true for the solutions with initial conditions very near the stable fixed points. All these solutions are characterized quantitatively by the parameter \\(a\\) in the exponential solution \\(A e^{a t}\\). (Remember, \\(a &lt; 0\\) when there is exponential decay.)\nQuantitative knowledge of \\(a\\) is helpful to understand the time scale of the exponential approach to stable fixed points. We can find a numerical value for \\(a\\) for each fixed point by constructing a linear approximation to the dynamical function near each of the fixed points.\nThe procedure involves the same principles as introduced in Block 2 for constructing low-order polynomial approximations to functions, but here “low-order” means “first order.”\nThe analysis is done separately for each of the fixed points, so the first step is to find the fixed points, the values \\(x^\\star\\) such that \\(f(x^\\star) = 0\\).\nRecall from Block 2 the Taylor polynomial approximation to a function \\(f(x)\\) centered on a point \\(x^\\star\\): \\[f(x) \\approx f(x^\\star) + \\partial_x f(x^\\star) \\left[x - x^\\star\\right]\\] When \\(x^\\star\\) is a fixed point, \\(f(x^\\star) = 0\\) so the approximation is simply \\(f(x) \\approx \\partial_x f(x^\\star) \\left[x - x^\\star\\right]\\). Keep in mind that \\(\\partial_x f(x^\\star)\\) is the derivative function \\(\\partial_x f\\) evaluated at the input \\(x^\\star\\), so \\(\\partial_x f(x^star)\\) is simply a quantity, not a function. Indeed, \\(\\partial_x f(x^star)\\) is exactly the quantity \\(a\\) in the exponential solution \\(e^{a t}\\).\nThis process of constructing the linear approximation \\(f(x) \\approx a \\left[x - x^\\star\\right]\\) is called linearization.\n\n\n\n\n\n\n\n\nTry it! 42.1\n\n\n\n\n\n\n\n\n\nTry it! 42.1 Exponential dynamics near fixed points\n\n\n\nConsider the first-order differential equation \\[\\partial_t x = f(x) \\equiv r x (x - x/K)\\] where \\(r\\) and \\(K\\) are parameters that are greater than zero. Linearizing the nonlinear function \\(f(x)\\) lets us figure out how fast or slow is the exponential growth or decay of the solutions for initial conditions near the fixed points.\n\nThere are two fixed points, one at \\(x_1^\\star = 0\\) and the other at \\(x_2^\\star = K\\). What is the exponential parameter \\(a\\) for each of the fixed points.\nThe derivative (with respect to \\(x\\)) \\(\\partial_x f(x)\\) can be found with the product rule from Block 2. It is \\[\\partial_x f(x) = r\\, (1 - x/K) - r\\, x\\, (1/K)\\]\nEvaluating \\(\\partial_x f(x)\\) at the two fixed points \\(x_1^\\star = 0\\) and \\(x_2^\\star = K\\) gives\n\n\\[\\partial_x f(x_1^\\star) = r\\ \\ \\ \\text{and}\\ \\ \\ \\partial_x f(x_2^\\star) = -r\\] Solutions near \\(x_1^\\star\\) will grow exponentially as \\(e^{r t}\\), unstable since \\(0 &lt; r\\). Solutions near \\(x_2^\\star\\) will decay toward \\(x_2^\\star\\) in an exponential manner as \\(e^{-r t}\\).\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt is critical to distinguish carefully between \\(x^\\star\\), which is the location of the fixed point being examined, and \\(x_0\\), which is the initial condition of the state, that is, \\(x(t=0)\\).\n\n\n\nApplication area 42.1  \n\n\n\n\n\n\n\nApplication area 42.1 Retirement savings redux\n\n\n\nLet’s return to the model of saving for retirement in Chapter 40: \\[\\partial_t V = r\\, V + M\\ .\\] The state variable here is named \\(V\\). The dynamical function is \\[g(V) = r\\, V + M\\] where \\(r\\) is the interest rate (say, 3% per year which is \\(r=0.03\\) per year) and \\(M\\) is the monthly contribution. To keep the units consistent, we set the units of \\(t\\) to be years, of \\(r\\) to be 1/years, of \\(V\\) to be dollars and of \\(M\\) to be dollars-per-year. So a monthly contribution of \\(1000 would come to\\)M=12000$ dollars-per-year.\nFind the amount \\(V\\) that will result from 30 years of savings with an initial condition \\(V_0 = 0\\).\nStep i) Find the fixed point. This is a value \\(V^\\star\\) such that \\[r\\, V^\\star + M = 0\\ \\ \\ \\implies \\ \\ \\ V^\\star = -M/r\\ .\\] Step ii) Find the derivative of the dynamical function evaluated at the fixed point: Since \\(g(V)\\) happens to be a straight-line function, we know the derivative is a constant. So \\(b = \\partial_x g(V^\\star) = r\\).\nStep iii) Translate the state variable into \\(y = V - V^\\star\\). The dynamics in terms of \\(y\\) are \\(\\partial_t y = b y\\), which has an exponential solution \\(y = A e^{bt}\\).\nStep iv) \\(A\\) is the initial condition in terms of \\(y\\). This will be \\(y_0 = V_0 - V^\\star\\). Since we stated that \\(V_0 = 0\\) (no savings at the start), \\(y_0 = -V^\\star\\) and the solution is \\[y(t) = -V^\\star e^{bt} = \\frac{M}{r} e^{rt}\\ .\\]\nStep v) Translate the solution in step (iv) back into terms of \\(V(t)\\). Since \\(y(t) = V(t) - V^\\star\\), this will be \\(V(t) = y(t) + V^\\star\\) or, \\[V(t) = \\frac{M}{r} e^{r t} + V^\\star = \\frac{M}{r} \\left[ e^{r t} - 1\\right]\\ .\\] To get an idea of this retirement plan, that is, \\(r=3\\%\\) and \\(M=12000\\) dollars-per-year, let’s see how much you will have after 30 years and 40 years.\n\nV &lt;- makeFun((M/r)*(exp(r*t)-1) ~ t, r=0.03, M=12000)\nV(30)\n## [1] 583841.2\nV(40)\n## [1] 928046.8\n\nAfter 40 years of contributions, your retirement account will have almost one-million dollars.\nYou could have accomplished the same calculation using integrateODE(), like this:\n\nSoln &lt;- integrateODE(dV ~ r*V + M, V=0, M=12000, r=0.03,  \n                     domain(t=0:40))\n## Solution containing functions V(t).\nSoln$V(30)\n## [1] 583841.2\nSoln$V(40)\n## [1] 928046.8",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Flows on the line</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#bifurcation",
    "href": "Dynamics/B6-flow-on-line.html#bifurcation",
    "title": "42  Flows on the line",
    "section": "42.4 Bifurcation",
    "text": "42.4 Bifurcation\nA broad, pressing, social concern goes under the name sustainability. Is it sustainable to burn fossil fuels at steady historical levels, let alone at the increasing rate seen since over the last century? Climate scientists answer resoundingly with a no. Is it sustainable to increase food production to the levels needed for developing economies to approach the sort of consumption seen in rich economies?\nDynamical systems are highly relevant to the questions surrounding sustainability. If the economy is near a stable fixed point, then it is sustainable; the trajectory will bring the state of the economy toward the fixed point. On the other hand, if the economy is near an unstable fixed point, we can expect exponential change.\nIf such exponential changes are not seen, does that mean we are not near an unstable fixed point? One of the terms used to mark the possibility that a stable system can quickly turn unstable is tipping point, defined as\n\nThe point at which a series of small changes or incidents becomes significant enough to cause a larger, more important change. Source: New Oxford American Dictionary\n\nThe mathematics of tipping points is not at all the same as exponential growth. Certainly, in exponential growth one sees a relatively slow rate of change increase to a large rate of change, a situation described by journalists as “sky-rocketing” or “explosive” or, literally, “exponential.” As you’ve seen, exponential growth is a phenomenon seen in linear dynamical systems; there is no special point at which the dynamics changes.\nThere is an area of mathematical theory called catastrophe theory. We will use a famous example to show how catastrophes or tipping points are modeled mathematically.\nThe example comes from a 1977 article in Nature, one of the world’s most prestigious scientific journals. The article, by Robert May, is entitled “Thresholds and breakpoints in ecosystems with a multiplicity of stable states.” The words “thresholds” and “breakpoints” have not been encountered yet in this book, but “multiplicity of stable states” should bring to mind the sort of dynamics seen in Figure 42.2.\nThe setting for the catastrophe is an otherwise bucolic scene, livestock grazing on a pasture. A pasture is a kind of factory for producing vegetable biomass; the grazing is the consumption of the biomass produced.\nAs a model for the production of biomass, denoted \\(v\\) for “vegetation,” we will use \\[\\partial_t v = r v \\left(1 - \\frac{v}{K}\\right)\\] which, as we’ve seen, has an unstable fixed point at \\(v_1^\\star=0\\) and a stable fixed point at \\(v_2^\\star=K\\). Physically, the fixed point \\(v_1^\\star\\) corresponds to a bare field, without any vegetation. It is unstable because any small disturbance in the form of a stray seed landing in the dirt can lead to germination and the rapid growth of vegetation as seeds from the germinated plant spread across the field. Once the field is covered in vegetation, the growth can be exponentially rapid at first but then runs into limited resources: there is only so much sunlight that falls on the field, and the growing vegetation will eventually consume the soil nutrients and water.\nThis biomass production model corresponds to a sustainable system. Once the biomass level is at \\(v_2^\\star\\) it will stay there.\nBut biomass production is not the only thing going on in the pasture. The grazing animals—let’s imagine they are cows—are consuming the grass. To start very simply, suppose that each cow consumes amount \\(C\\) of biomass each day. If there are \\(H\\) cows, the total consumption is \\(H C\\) per day. This modifies the dynamics to a slightly new form \\[\\partial_t v = r \\,v(1-\\frac{v}{K}) - HC\\]. The original, ungrazed dynamics are compared with the grazed dynamics in Figure 42.7.\n\n\n\n\n\n\n\n\nFigure 42.7: Comparing the pasture dynamics for different herd sizes.\n\n\n\n\n\nWith grazing, the net growth of biomass is reduced due to the removal of the consumed biomass by the cows’ consumption. For a moderate herd size, there is still a stable fixed point, but it is at a lower level of biomass than would be seen in the ungrazed field. But if the herd size is too large, the ecosystem completely collapses.\nThis is an example of a tipping point or catastrophe. For moderate herd sizes, there remains a stable fixed point. A farmer might be tempted to add another cow to the pasture, and that is sustainable: there is still a stable fixed point. Indeed, the movement of the stable fixed point might not even be noticed. But add even one cow too many and the fixed point entirely disappears. Still, herd management can fix the problem; take away the cow that tipped the pasture and the fixed point will return.\n\nApplication area 42.2 —Details of chewing\n\n\n\n\n\n\n\nApplication area 42.2 Cows eat grass\n\n\n\nIn Chapter 16 we illustrated the iterative process for building models: using the results of a model to suggest possible improvements in the model. Let’s look again at how cows eat grass.\nMissing from the pasture model is a simple idea of how cows eat. If there is very little biomass, the cows cannot continue to eat their fill. Will the reduction in consumption per cow preserve the stable fixed point?\nIn his Nature article, May modeled the consumption rate by a single cow with the functional form \\[C(v) \\equiv \\frac{\\beta v^2}{v_0 - v^2}\\] which is graphed for \\(\\beta=0.1\\) and \\(v_0 = 3\\) in Figure 42.8\n\nconsumption &lt;- makeFun((beta*v^2/(v0^2 + v^2))~ v, beta=0.1, v0=1)\nslice_plot(consumption(v) ~ v, bounds(v=0:10)) %&gt;%\n  gf_labs(y=\"Consumption (tons/day)\", x=\"v: available biomass (tons)\")\n\n\n\n\n\n\n\nFigure 42.8: Consumption of vegetation by a single cow as a function of the amount available in the pasture.\n\n\n\n\n\nYou can recognize this as a form of sigmoid. When the amount of vegetation is very large, a cow will eat her fill. That is the saturation of the sigmoid. For small \\(v\\), the cow needs to hunt around for vegetation tall enough to eat, reducing the consumption steeply.\nFigure 42.9 modifies the pasture dynamics to incorporate this sigmoid model of consumption.\n\n\n\n\n\n\n\n\nFigure 42.9: Pasture dynamics for a sigmoid consumption function.\n\n\n\n\n\nWe can start the story with 3 cows in the pasture. Vegetation growth is more than sufficient to provide for these cows. You can see this from the stable fixed point at about 9 tons of biomass, which is more than enough to reach saturation of the sigmoid consumption function.\nThe farmer decides to increase the herd to 5 cows. Nothing much happens. The stable fixed point is at about 8 tons of biomass, entirely adequate to keep the cows well fed in a sustainable manner.\nCan the pasture be sustainable with 7 cows? The stable fixed point remains, now at about 6.5 tons at biomass. The cows are still sustainably well fed.\nYou can see in the 7-cow dynamics a hint of what of what might go wrong. There is a new, unstable fixed point at about 3 tons of biomass. If the pasture ever happened transiently to fall below 3 tons—say due to a summer frost followed by a return to normal weather—the vegetation biomass will head toward the new stable fixed point at 0.5 tons of biomass. At this level, the cows are eating only about one-quarter their normal amount and we can fairly say that the ecosystem has collapsed. But until such a disaster happens, the farmer will see only a sustainable level of biomass with cows well fed.\nIt is only we, who have a mathematical model of the situation, who can anticipate the potential problems.\nSince things are fine with 7 cows in the field, the farmer lets an eighth cow join the herd. That is the tipping point. The happy herd fixed point at 6.5 tons of biomass has disappeared, and the ecosystem collapses, even without a weather disaster.\nRemoving the eighth cow from the pasture will not fix the situation. With seven or even six cows in the pasture, the system won’t be able to grow out of the stable fixed point with 0.5 tons of biomass. Reducing the herd size to five will remove that 0.5 ton fixed point, but the grass will grow back very slowly; the dynamics give positive growth, but very close to zero.\nAvoiding such catastrophes is a major motivation for mathematical modeling.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Flows on the line</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-modeling.html",
    "href": "Dynamics/B6-modeling.html",
    "title": "44  Modeling dynamics",
    "section": "",
    "text": "44.1 A single state quantity\nWe will start with situations that can be modeled with a single state variable. Throughout our examples, we will call that state variable \\(S\\), so the differential equation describing how \\(S\\) changes in time will always be \\[\\partial_t S = f(S)\\]. The modeler chooses the shape of \\(f()\\) depending on the situation being modeled.\nIn principle, there is an infinite number of shapes for \\(f(S)\\). But many modeling settings involve behavior that is simple. We will work with function shapes where the dynamical function \\(f(S)\\) is continuous and has one or two fixed points.\nFigure 44.1 shows four generic dynamical function shapes where these is one fixed point. The location of the fixed point is, of course, the \\(S_0\\) at which \\(f(S_0)=0\\), that is, the intersection of the function and the blue dashed line.\nFigure 44.1: Four generic functions shapes with one state variable having one fixed point.\nThe fundamental distinction is between models with stable and models with unstable fixed points. When the situation being modeled has a steady equilibrium, only the stable shapes of \\(f(S)\\) are relevant. A second distinction is between functions with a bounded shape and those with a linear shape. Use a linear shape when you are concerned only with the behavior near the fixed point. But when your model needs to account for behavior far from the fixed point, you need first to have a way to represent what is meant by “far from.” That is represented by the location of the shoulder of the curve relative to the fixed point.\nA setting for a linear stable model is the cooling or warming of an object to the ambient temperature. \\(S\\) stands for the temperature of the object and the fixed point is the ambient temperature. This model often goes under the name Newton’s Law of Cooling. The prestige of the model name distracts from the fact that this is a very simple model. But in the real world there are likely to be complications that make Newton’s Law imprecise, unlike, say, Newton’s Second Law of Motion which is exact (at non-quantum and non-relativistic scales). For instance, a cup of hot water will cool faster than a cup of cold water. In hot water, evaporation from the surface speeds up the warming. When ice is involved, the rate of temperature change slows when melting or freezing is encountered.\nAnother classic setting for a linear, stable model is radioactive decay. The rate at which the atoms in a mass of a radioactive isotope decay is a constant \\(\\alpha\\) that depends on the nuclear structure. A mass of \\(n\\) atoms will produce \\(\\alpha n\\) individual decay events in a given time interval. But, since each decay event reduces \\(n\\) by 1, the differential equation describing the number of radioactive atoms is \\[\\partial_t n = - \\alpha nt\\] which leads to exponential decay towards zero. Notice that only the \\(0 \\leq n\\) half of the state space is relevant, because the number of atoms cannot be negative.\nAn example of a setting where the bounded stable model applies is one where \\(S\\) stands for the amount of prey or food stock, and there is a constant population of predators who have a limited capacity for eating. Consider, for example, \\(S\\) being the availability of acorns. There might be a fixed population of, say, oaks that produce acorns at a given rate. When predation is low, the acorns accumulate. But when there are a lot of acorns, predators might focus on that bountiful food source. Still, they can only eat so many acorns per day before they are full.\nThe linear unstable model is often used to model population growth. The underlying idea, which might or might not correspond to reality, is that there is a set reproduction rate per member of the population. The differential equation is \\[\\partial_t{S} = a S + c\\] with \\(S\\) being the size of the population. The parameter \\(c\\) captures immigration (\\(0 &lt; c\\)) or emigration (\\(c &lt; 0\\)). To be more detailed, the model can be written as summing a birth process and a death process: \\[\\partial_t S = b S - d S + c\\] where \\(b\\) is the birth rate and \\(d\\) is the death rate. Of course, the detailed model collapses arithmetically to the \\(a S + c\\) model, with \\(a = b - d\\). Still, elaborations on the birth or death processes may include the influence of changing factors. We will return to this idea in a bit.\nTake care to use the parameters \\(a\\) and \\(c\\) correctly. The output of \\(f(S) = a S + c\\) must have dimension \\([S]/[t]\\), for instance organisms per hour might be appropriate for bacteria. Thus the individual terms \\(aS\\) and \\(c\\) must have dimenion \\([S]/[t]\\). Consequently, the parameter \\(a\\) has dimension \\(1/[t]\\) as in per hour. That might seem odd until you remember that \\(a\\) is about the creation of new organisms, \\([S]/t\\), per existing organism. Thus the dimension of \\(a\\) is \\([S] / [S][t]\\) which works out to be simply \\(1/[t]\\).\nFor bacteria, the linear unstable model may be realistic for short periods of time, or, more precisely, for as long as the population is small compared to the carrying capacity. (See ?sec-nonlinear-on-line.) In contrast, human and other animal populations often have an important age structure, which is just to say that neither a 6 nor a 60 year old person has the same reproduction rate as a 26 year old. Such an age structure calls for a dynamical state with multiple components.\nBut if the environment is steady—no food shortages, no disease, economy unchanging, etc.—it can be reasonable to describe even age-structured populations as a percentage growth per unit time, e.g. percent per year. Realize that such a description is not only about the biology of reproduction, but summarizes the whole system of aging, death, and reproduction. This summary description may no longer be relevant when the system as a whole changes. An example of this in the human population is seen in countries where the number of births per woman has fallen substantially—by half or more—over the time of a generation. Such falls typically accompany a growth in economic wealth and the realization that more resources (e.g. education) needs to be provided to each offspring.\nThe bounded unstable model is a way to incorporate factors that interfere with sustained exponential growth. Exponential growth requires that the growth rate \\(\\partial_t S\\) increase as \\(S\\) increases: a kind of positive feedback. In the bounded model, the growth rate becomes constant for large \\(S\\). A constant growth rate means that \\(S\\) will grow steadily, that is \\(\\partial_t S = c\\) which has a solution that grows linear in time, as distinct from the exponential solution that results from \\(\\partial_t S = a S\\).\nAn application of the bounded unstable model is seen in the description of micro-organism growth given by Jacques Monod (1910-1976), a Nobel Prize winning biochemist. His idea was that the organisms are reproducing in a kind of sea that has a limited concentration of an essential nutrient, but very large amounts of the nutrient spread out over space. Even though the nutrient is begin consumed by the organisms, more nutrient diffuses in from far away to keep the concentration steady. At large population sizes, the growth rate is nutrient concentration limited, hence constant.\nChapter 16 introduced the idea of a modeling cycle: taking an initial model, examining the consequence/predictions of that model, and then modifying the model to better correspond to observed reality or new mechanism.\nA case in point is the linear unstable model for population growth. The linear model is always appropriate near a fixed point. This is just a consequence of the calculus idea that any function can be approximated by a linear function over a small enough domain. In defining derivatives, the question was what constitutes “small enough.” So a linear dynamical function is a good starting point for dynamics near a fixed point. But, as we’ve seen, extending the linear model far from the fixed point leads to population explosion: exponential growth. This can be a valid idea for modeling a pathogen growing in a bowl of room-temperature chicken salad: the pathogen need not consume all the salad to become a threat, so in the domain of interest—human health—the linear model can do the job.\nBut we observe generally that exponential growth does not continue indefinitely. The demographer Thomas Malthus (1766-1834) famously propounded a “principle of population” which held that it is in the nature of populations to growth exponentially until linally limited by famine or disease. He wrote, “[G]igantic inevitable famine stalks in the rear, and with one mighty blow levels the population with the [lack of] food of the world.”\nMalthus’s model is exponential growth that runs into a wall of limited food. Malthus saw human reproduction as the engine of the immense poverty and suffering of the lower classes in early industrial Britain. This became the basis of an important political dispute, two poles of which are “there is no point helping the poor, because they create their own poverty,” and “the poverty is due to exploitation, not reproduction.”\nFor us in calculus, there is a middle road: Malthus’s mathematical model, the unstable linear model, is much too abrupt and narrow minded and can easily be made more realistic. Adding that realism removes the “one mighty blow” from the situation. Let’s add that realism now.\nRecall the earlier suggestion that the linear unstable model \\(\\partial_t S = a S + c\\) be broken into components: \\[\\partial_t S = \\underbrace{b S}_{\\text{births}}\n- \\underbrace{d S}_{\\text{deaths}} + \\underbrace{c}_{\\text{immigration}}\\ .\\]\nEven in Malthus’s time, there were calls to alleviate poverty by encouraging people to leave for less crowded lands: emigration. In the dynamics, emigration corresponds to a negative value for \\(c\\).\nMaking \\(c\\) negative does not do the job on its own. Note that whatever the value of \\(c\\), the dynamics are unstable. Emigration at a constant rate changes the location of the fixed point, but since the dynamics are unstable, growth will still be unbounded. Suppose, however, that government policy sets an emigration goal not as a constant number of people per year but as a constant fraction, \\(eS\\) of the population. Now the dynamics become \\[\\partial_t S = b S - d S - e S\\ .\\] These dynamics are stable or unstable depending on the value of \\(b - (d+e)\\). If that value is negative, the dynamics are stable, if positive, the dynamics are unstable. The situation resembles (mathematically) that of a nuclear power reactor: the control parameter \\(e\\) has to be carefully manipulated to set the population at a fixed level.\nBut there are other things that come into play. One of them is that the parameter setting the death rate, \\(d\\), need not be constant. From Malthus’s perspective, \\(d\\) would change in episodes set by disease and starvation. In Malthus’s era, pandemics were common and wiped out a major fraction of the population in “one mighty blow.” Similarly, starvation plays out on a smaller time scale than reproduction and seems to cut through the population.\nBut the death rate can also be a function of population \\(S\\). For instance, \\(d = d_0 + d_1 S\\) corresponds to a death rate that increases gradually with population size. (The parameters \\(d_0\\) and \\(d_1\\) are positive.)\nSimilarly, birth rate can depend on population, that is \\(b = b_0 - b_1 S\\). As the population gets larger, there is less food and less space, and these changes can reduce the reproduction rate. (The parameters \\(b_0\\) and \\(b_1\\) are positive.)\nThese models for \\(d\\) and \\(b\\) are simplistic. Why should they have a linear form? The answer is … calculus. Whatever are the functions \\(b(S)\\) and \\(d(S)\\), they must be approximately linear over a small domain.\nLet’s plug in the refined models for birth and death rates into the population models. We get: \\[\\partial_t S = (b_0 - b_1 S) S - (d_0 + d_1 S) S - e\\ .\\] A little algebraic simplification reduces this to:\n\\[\\partial_t S = (b_0 - d_0) S - (b_1 + d_1) S^2 - e\\] Whatever are the size of the quantities \\(b_0, b_1, d_0, d_1\\), so long as they are positive, the dynamical function \\(f(S)\\) will have two fixed points, one at small \\(S\\) and the other at large \\(S\\). For small \\(S\\), the fixed point is unstable. The population will grow away from this fixed point. The fixed point at large \\(S\\) will be stable, hence no population explosion.\nOne of the major flaws with the Malthusian viewpoint is that it treated all the dynamical functions as linear, whereas in reality the functions can have a quadratic shape. The classical differential equation for limited population growth, \\[\\partial_t S = a S (1-S/K)\\ ,\\] was introduced by Pierre-François Verhulst in 1838, just four years after Malthus’s death.\nAnother important flaw with Malthus’s model is that it failed to account for the transition from purely agricultural economies to economies that produced large amounts of other goods and services. It turns out as populations grow wealthier, their reproduction rates decrease. With wealth available in non-food terms—clothing, public health, education—reproduction rates can go down even without the “one mighty blow” of starvation and disease.\nThe next section examines both of these factors—the introduction of multiple state variables and the ability to “soften” the explosive unstable linear dynamics with nonlinear corrections—in making subtle models of the behavior of systems.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Modeling dynamics</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-modeling.html#a-single-state-quantity",
    "href": "Dynamics/B6-modeling.html#a-single-state-quantity",
    "title": "44  Modeling dynamics",
    "section": "",
    "text": "Tip\n\n\n\nIf \\(S\\) is observed to oscillate or to reverse the direction of change, then there must be at least one more state variable, that is, at least one more quantity that changes in time. A single first-order differential equation will not be able to model the situation.\nIf there are no fixed points, then the only possible dynamics are continuous increase in \\(S\\) or continuous decrease in \\(S\\). Often, the point of interest will be whether there is some other factor that changes increase to decrease or vice versa. Again, such situations should be modeled in the context of at least two state variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nRemember that in a differential equation \\(\\partial_t S = f(S)\\), the input to \\(f()\\) is has dimension \\([S]\\), while the output of \\(f()\\) has a different dimension: \\([S]/[t]\\). Thus, in the oak/acorn example above, the output of \\(f()\\) has a dimension corresponding to acorns per day, a rate of consumption. \\(S\\) is acorns, the output of \\(f(S)\\) is acorns per day.\n\n\n\n\n\nApplication area 44.2  \n\n\n\n\n\n\n\nApplication area 44.2 Bacterial growth\n\n\n\nUnder ideal reproductive conditions, some bacteria can split in two every 20 minutes. What does this tell us about \\(a\\)?\nIt is easy to get confused. For instance, a single bacterium that splits every 20 minutes will go from an initial population of \\(S=1\\) at time \\(t=0\\) to a population of \\(S=2\\) at \\(t=\\frac{1}{3}\\) hour to \\(S=4\\) at \\(t=\\frac{2}{3}\\) hour to \\(S=8\\) at \\(t=1\\) hour. This might make it seem that the reproduction rate is 8 per hour. But this calculation of the population size at hour 1 is redundant with the accumulation that will be accomplished in solving the differential equation.\nThe correct way to calculate \\(a\\) from the stated information that there is a split every 20 minutes works like this:\n\nThe dynamics are \\(\\partial_t S = a S\\). Therefore the solution is \\(S(t) = S_0 e^{a t}\\).\nAccording to the given information about splitting, when the initial condition is that \\(S(0) = 1\\), \\[S(1/3) = S_0 e^{a/3} = e^{a/3} = 2\\ .\\]\nWorking from \\(e^{a/3} = 2\\) gives the parameter value we see: \\(a = 3 \\ln(2)\\).\n\n\n\n\n\n\nApplication area 44.3 —Unstable atoms are everywhere!\n\n\n\n\n\n\n\nApplication area 44.3 Nuclear decay\n\n\n\nRadioactive decay of nuclei is a situation where the linear unstable model is realistic. Previously, we’ve pointed out that radioactive decay of an isotope is well modeled by the linear stable model. This leads the number of atoms of the radioactive isotope to decay exponentially.\nBut there is an important exception. Some radioactive isotopes are fissile, for instance uranium-233, uranium-235, plutonium-239, and plutonium-241. Fissile materials decay via two different mechanisms. One is each-atom-on-its-own decay that applies generally to radioactive isotopes. The other mechanism involves the decay of one atom triggering the decay of others.\nThe means of triggering involves a sub-atomic particle called a neutron. The decay of a fissile atom releases one or more neutrons, depending on the nuclear structure. If one of these neutrons has the correct energy, and if they collide in the appropriate way with a second fissile atom, that second atom will itself undergo decay, leading to the release of more neutrons. Such a process is called a chain reaction.\nTypically, a fissile chain reaction takes place inside an engineered device called a reactor. A simple differential equation of a chain reaction can be constructed using the number of neutrons in the reactor, and is \\[\\partial_t N = \\alpha N\\ .\\] As you’ve already seen, the solution to this is \\(N(t) = A e^{\\alpha t}\\): exponential growth. The value of \\(\\alpha\\) is determined by the design of the device. If the device is small, then neutrons can escape from the device before triggering a reaction, so alpha is small. If there are non-fissile neutron absorbers in the device, neutrons are taken out of play so, again, alpha is small and can even be negative.\nIn everyday terms, rapid exponential growth is called an explosion. Exponential growth cannot continue forever, and indeed a fissile bomb blows itself up, resulting in negative \\(\\alpha\\) as the fissile material is scattered.\nControl of a fission bomb requires a mechanism that changes \\(\\alpha\\) from negative (stable \\(N\\), so no explosion) to positive. This can be accomplished, for instance, by bringing together pieces of fissile material that by themselves has negative \\(\\alpha\\) into a critical mass where \\(\\alpha\\) positive.\nNon-explosive nuclear reactions, as in power plants, call for a kind of juggling act. The device cannot have negative \\(\\alpha\\) or the reaction would die out exponentially. It cannot have positive \\(\\alpha\\) or the reaction would become explosive.\nA power reactors is designed to keep \\(\\alpha\\) near zero. Near zero not at zero. The reactor design needs to allow \\(0 &lt; \\alpha\\) to start up the reaction, but trim this down to zero when the reactor is at the desired power. Typically, there is some combination of active and passive mechanisms to provide this capability. An active mechanism is the insertion of “control rods,” which absorb neutrons by reactor operators to make \\(\\alpha &lt; 0\\) when the power generation is higher than desired. Passive mechanisms can involve the transformation of reactor water into steam, which reduces the ability of neutrons to induce new fissile decays.\nReactors can be very complicated, however. The explosion of the Soviet Union’s Chernobyl reactor in 1986 was caused by a chain of events that led to control rods being withdrawn beyond the design intentions. Due to the construction of the rods, reinserting the rods to dampen the run-away reaction caused the reaction to accelerate. Avoiding such disasters requires a combination of safety oriented design and proper training of the operators. Neither of these were a feature of the 1980s Soviet environment, where secretiveness interfered with proper training and economic motivations to produce were so strong as to encourage widespread cheating.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Modeling dynamics</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-modeling.html#multiple-state-quantities",
    "href": "Dynamics/B6-modeling.html#multiple-state-quantities",
    "title": "44  Modeling dynamics",
    "section": "44.2 Multiple state quantities",
    "text": "44.2 Multiple state quantities\nThe previous section examined dynamics of a single state variable. Now we will consider the possibilities when there is a second state variables. It turns out that adding more state variables above two does not introduce many fundamentally new behaviors, so we will focus on dynamical systems with two variables. We will continue to use capital letters, like \\(S\\), to stand for the state variables. But with two (or more) state variables, we will need to give them different names so we can keep tract of what’s doing what to what. The parameters in the dynamical functions will, as has been our practice, be written as lower-case letters, such a, b, r, c, and so on.\nA starting observation is that for dynamics to be genuinely two-dimensional, the differential equations for the state variables need to be coupled to one another. For example, a dynamical system that nominally has two state variables \\(X\\) and \\(Y\\) is:\n\\[\\partial_t X = f(X)\\\\\n\\partial_t Y = g(Y)\\ .\\]\nThe state variables here are not coupled, since the change in each variable depends only on the value of that variable and not on the other.\nCoupled state variables have dynamics that look like this:\n\\[\\begin{eqnarray}\n\\partial_t X & = f(X, Y)\\\\\n\\partial_t Y & = g(X, Y)\\ .\\\\\n\\end{eqnarray}\\] The time evolution of each state variable depends on the other state variable.\nThe most mathematically simple form of coupled dynamics is this:\n\\[\\begin{eqnarray}\n\\partial_t R & = a B\\\\\n\\partial_t B & = c R\\ .\\\\\n\\end{eqnarray}\\]\nWhat type of real-world setting might such a simple model correspond to? Surprisingly, even this simple model has important things to say about complex phenomena such as love and warfare.\nWe will start with warfare, where the signs of the parameters are easy to determine. The model, called Lanchester’s Law, is \\[\\begin{eqnarray}\n\\partial_t R & = - b B\\\\\n\\partial_t B & = -r R\\\\\n\\end{eqnarray}\\] with both parameters \\(r\\) and \\(b\\) taken to be positive.\nThe state variables \\(R\\) and \\(B\\) stand for the size of the two armies in conflict: the Red army versus the Blue army. As the two armies meet in battle, the Blue army causes casualties in the Red army. These casualties reduce the size of the Red army. Similarly, the Red army causes casualties in the Blue army.\nThe model describes the rate of reduction in the armies as being proportional to the size of the opposing army. But the two armies can be different in their efficiency of causing casualties, reflected by possibly different values of the \\(r\\) and \\(b\\) parameters.\nThe dynamics are not exponential. Exponential decay of the army size would correspond to a model like \\(\\partial_t R = - r R\\), an army fighting itself. But the Lanchester model has \\(\\partial_t R = - b B\\).\nWe will defer for a moment finding the trajectories of the state variables in the course of battle. (Hint: in the model, one army wipes out the other.) Instead, we will focus on a surprisingly rich implication of of such simple dynamics.\nLanchester’s Law has a surprising consequence for measuring the overall strength of a force in a way that combines size (\\(R\\) and \\(B\\)) and effectiveness (\\(r\\) and \\(b\\)) and the implications that has for tactics.\nLanchester proposed that the quantity \\[Q(R, B) \\equiv rR^2 - b B^2\\] is a good way to characterize the dynamics. His reasoning was based on a fundamental idea from physics and chemistry: that quantities are conserved. In physics, examples of conserved quantities are energy, momentum, and angular momentum. In chemical reactions, the number of atoms of each species is conserved.\nIt is hard to say how Lanchester came up with the formula \\(rR^2 - b B^2\\): insight is hard to explain. But we can easily demonstrate that it is conserved, that is, the quantity does not change in time regardless of how the battle proceeds. We will do this by showing \\(\\partial_t Q(R, B) = 0\\).\n\\[\\partial_t Q(R, B) = \\partial_t \\left[\\strut rR^2 - b B^2\\right]\\] Applying the chain rule we find that \\[\\partial_t r R^2 = 2 r R\\, \\partial_t R\\ \\ \\ \\ \\text{and}\\ \\ \\ \\partial_t b B^2 = 2 b B\\, \\partial_t B\\ .\\] Substituting in \\(\\partial_t R = - b B\\) and \\(\\partial_t B = - r R\\) gives \\[\\partial_t Q(R, B) =  - 2 r b R B + 2 b r  B R = 0\\ .\\] The conserved quantity \\(Q(R, B)\\) describes an aspect of the battle that goes unchanged over the course of the battle. At any moment, it describes the match between the overall capability of the two armies. That the difference between the capabilities is conserved does not mean the individual capabilities are unchanged in battle. Those capabilities decrease as the army sizes, \\(R\\) and \\(B\\) are reduced. But at any instant in time, the capability of each army is proportional to the square of the army size. change The consequence, is that the capability of each army is, at all times,\nTo illustrate, consider a battle between two armies of archers. The B-army archers are more skilled: they can fire 12 arrows per minute. The R-army archers can fire at only half the rate—6 arrows per minute. But the R army is twice the size of the B army.\nAre the armies equally matched? It may at first glance seem so, since both armies can fire at the same rate. For instance, if there are 1000 archers in the R army and 500 in the B army, both armies start capable of firing 6000 arrows per minute. But Lanchester’s Law tells us that the R army is twice as capable as the B army: \\(6 \\times 1000^2\\) is twice as big as \\(12 \\times 500^2\\).\nTo see why the R army is superior, remember that each arrow can take out only one of the opposing archers. For each B arrow that is on target, the firing rate of R is reduced by 6 arrows per minute. But for each R arrow that hits, the firing rate of B is reduced by 12 arrows per minute. The initial casualty rate for the two armies is the same, but B sees a twice as large reduction in its firing rate.\n\n\n\n\n\n\nCalculus history—Fighting strength\n\n\n\nFrederick William Lanchester (1868-1946) was a British engineer, considered one of the greats of British automotive engineering. But that hardly does justice to him.\nWhile voyaging across the Atlantic to America, he became captivated by the gliding flight of herring gulls. This led to his development of his circulation theory of flight, a foundation of aerofoil theory. In 1906 he published Aerial Flight containing the first full theory of lift and drag. In Aerodonetics (1908) he developed his phugoid theory of aircraft stability, describing oscillations and stalls.\nIn 1914, Lanchester wrote a book-length series of journal articles that were published in 1916 as Aircraft in Warfare: the Dawn of the Fourth Arm. Imagine trying to theorize about a form of conflict that had never been seen!\n\nThe difficulty … is that to get the future into true perspective, it is necessary to be able to look forward along two parallel lines of development—i.e. to visualize the improvement of aircraft possible in the near future as a matter of engineering development, and simultaneously to form a live conception of what this improvement and evolution will open up in the potentialities of the machine as an instrument of war. (p.3)\n\n\n\nMathematician Steven Strogatz proposed in the 1990s that similar equations might be used to describe how love between two people varies over time. Strogatz’s equations are usually written with state variables R and J, standing for Romeo and Juliet. Positive values represent love, negative values are hate. And best to think of the model as a cartoon, but a cartoon that captures some of the behavior seen in reality.\nTo start, let’s consider a form of love that is really more like warfare:\n\\[\\partial_t R = -j J\\\\\n\\partial_t J = - r R \\ .\\] In this pathological relationship, the more Romeo loves Juliet, the faster Juliet’s love decreases toward hate. And vice versa.\nImagine that, somehow, these two perverse people started out in love: \\(R(t=0) &gt; 0\\) and \\(J(t=0) &gt; 0\\). As with Lanchester’s Law, both lovers fall increasingly out of love. Depending on the initial intensity of their love and whether or not \\(jJ^2\\) is bigger than \\(rR^2\\) (Lanchester’s conserved quantity), one of the parties will become indifferent, that is, a love level of 0 while the other’s love level is still positive. For the purpose of example, let’s suppose that Juliet is the first to reach indifference. But unlike the warring armies, the love quantity can become negative. As Juliet’s love becomes negative—remember, Romeo still has a positive level of love—then the true perversity of Romeo’s personality becomes apparent. Juliet’s increasing hostility causes Romeo’s love to grow. Without bound, because this is a linear dynamical function. The result is that Juliet’s hate increases even while Romeo’s love increases. But don’t blame Juliet. If Romeo had been the first to reach indifference, Juliet would suffer the unrequited love and Romeo would be villainously hateful.\nStrangely, if Romeo and Juliet started out mutually hating each other, their personalities would still lead to one having unbounded love for the other, who hates their partner without limit.\nA mathematically small change in the Romeo-Juliet dynamical system can lead to a profound change in the outcome. For instance, changing one sign, as in \\[\\begin{eqnarray}\n\\partial_t R & = r J\\\\\n\\partial_t J & = - j J\\ ,\\\\\n\\end{eqnarray}\\] produces, as we will see, a never-ending cycle of alternating love/hate.\nThe two dynamical functions in the previous examples, \\(-r R\\) and \\(-j J\\) are low-order polynomials. A sensible human being might suggest that the constant term in the polynomials should be added, but the cold, analytic mind of the mathematician would see that this would only change the location of the fixed point and not its stability. That suggests that the next more complicated model to consider involves includes both variables in the dynamical function. Like this:\n\\[\\begin{eqnarray}\n\\partial_t R & = a R + b J\\\\\n\\partial_t J & = c R + d J\\ ,\\\\\n\\end{eqnarray}\\]\nwhere the coefficients \\(a, b, c, d\\) might be either positive or negative depending on the personality of the lovers. Analysis of this model will have to await the introduction of new mathematical tools in Chapter 46.\nWhether Strogatz’s love model is realistic or not, it does illustrate a basic idea of model building: start with simple dynamical functions, check out their consequences, then modify the dynamical functions. We will do this now, with the modifications being purely mathematical along the lines of including different terms in low-order polynomial approximations and considering positive and negative coefficients. As you will see, the simple models correspond to a surprisingly wide range of behaviors.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Modeling dynamics</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-modeling.html#classical-phase-plane-models",
    "href": "Dynamics/B6-modeling.html#classical-phase-plane-models",
    "title": "44  Modeling dynamics",
    "section": "44.3 Classical phase-plane models",
    "text": "44.3 Classical phase-plane models\nWe have been using the term state space to refer to the set of possible values for the state variables. When there is only one state variable, the state space corresponds to the number line, or perhaps just the positive half of the number line. When there are two state variables, the state space corresponds to the coordinate plane; any point in the plane is a legitimate state for the system.\nHistorically, another term is used for the two-variable state space: the phase plane. This is just a matter of terminology, but it is so prevalent that you will occasionally see it mentioned. We don’t use it since dynamical systems can have a state space that is 1, 2, 3, or higher dimensional, but the phrase “phase plane” only works for 2-dimensional state spaces.\nIn this section, we will look at some famous models that involve two state variables. Out of respect for history, we will call these “classical phase plane” models, but this is entirely equivalent to saying “classical dynamical models with two state variables.”\nOur purpose in studying these classical models is two-fold: to show how simple models can make it easier to draw out the consequences of the mechanisms that we think are at work in real-world systems; and to show you how modifications to purely linear models can produce dynamics that are realistic even away from fixed points.\nTo start, let’s return to the Rabbit-Fox dynamics models. Classically this is called the predator-prey model. It is also called the “Lotka-Volterra” model in honor of it is inventors: American biophysicist Alfred Lotka (1880-1949) and Italian mathematical physicist Vito Volterra (1860-1940).\nThe two first-order differential equations in the Lotka-Volterra model are \\[\\begin{eqnarray}\n\\partial_t R & = \\alpha R - \\beta F R\\\\\n\\partial_t F & = \\delta F R - \\gamma F\\ ,\\\\\n\\end{eqnarray}\\] each of which contains a linear term (\\(\\alpha R\\) in the \\(R\\) equation, \\(\\gamma F\\) in the F equation). Each equation also contains an interaction term. Here, the mathematical/statistical name for the product of two quantities corresponds nicely with the physical reality that the terms describe what happens to rabbits when they interact with a fox, and similarly what happens to foxes. The parameters \\(\\alpha, \\beta, \\gamma\\), and \\(\\delta\\) can, mathematically, be either positive or negative, but they make sense in terms of rabbits and foxes only if all of them are positive. So the “interaction” is always negative for the rabbits and positive for the foxes.\nRewriting the model provides a bit of insight: \\[\\begin{eqnarray}\n\\partial_t R &  = \\underbrace{(\\alpha - \\beta F)}_{k_R}\\ R\\\\\n\\partial_t F & = \\ \\underbrace{(-\\gamma + \\delta R)}_{k_F}\\ F\\ . \\\\\n\\end{eqnarray}\\] Think about the \\(k_R\\) and \\(k_F\\) terms as the reproduction rates. If the fox population were constant, then the rabbit dynamics would be exponential growth or decay, depending on the sign of \\(k_R = \\alpha - \\beta F\\). Similarly, if the rabbit population were constant, the fox dynamics would be exponential decay or growth, depending on the sign of \\(k_F = -\\gamma + \\delta R\\).\nThe two equations are coupled so that the rabbit population alternating between growth and decay leads the fox population to so alternate, and vice versa.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Modeling dynamics</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-modeling.html#epidemic",
    "href": "Dynamics/B6-modeling.html#epidemic",
    "title": "44  Modeling dynamics",
    "section": "44.4 Epidemic",
    "text": "44.4 Epidemic\nIn a communicable disease, such as COVID-19, the infectious agent is transmitted from an infective person to another person who is susceptible. The time course of an epidemic can be modeled simply with two state variables. We will let \\(S(t)\\) be the number of susceptible people and \\(I(t)\\) the number of infective people at any time \\(t\\).\nThe dynamics of the \\(S\\) variable can be simple: \\(S\\) changes when an infective person meets (interacts with!) a susceptible person. That susceptible person, with some probability, becomes infective. So \\[\\partial_t S = -\\beta S I\\ .\\] The dynamics of the \\(I\\) variable are a just a little more complicated. First, every person who is converted from susceptible to infective becomes a new infective. This is the \\(\\beta S I\\) term in the following differential equation. Second, infectives gradually recover. This is often modeled as a simple \\(-\\alpha I\\) term.\n\\[\\partial_t I = \\beta S I - \\alpha I\\] This is famously called the SIR model, standing for the susceptible, infective, recovered chain of events.\nIn the model, recovery means “no longer able to infect.” Thus, a person who has been isolated is considered “recovered,” whether or not they display symptoms of the disease.\nWe usually think of recovery in terms of a time span, for instance taking a week to recover. But \\(\\alpha I\\) does not work this way. To see why, consider the situation starting on the day that there are no more infective people, that is, \\(S=0\\). The dynamics from this day forward are simplified: \\(\\partial_t I = =\\alpha I\\).\nOf course, the solution to this simplified differential equation is \\(I(t) = I_0 e^{-\\alpha t}\\); the size of the infective group gets smaller exponentially. Figure 44.2 compares what \\(I(t)\\) would look like if it takes, say, one week to recover and what \\(I(t)\\) looks like under the model’s \\(\\partial_t I = =\\alpha I\\) dynamics.\n\n\n\n\n\n\n\n\nFigure 44.2: Comparing \\(I(t)\\) for the “takes a week to recover” model and the \\(\\partial_t I = -\\alpha I\\) model.\n\n\n\n\n\nTo show the dynamics of the SIR model, we need to propose numerical values for \\(\\alpha\\) and \\(\\beta\\). This is not a trivial matter if the goal is to match the dynamics to a particular disease and size of population. For our purposes here, we will imagine that \\(S(0) = 0.999\\) and \\(I(0) = 0.001\\), which is to say we are looking at the proportion of the population that is susceptible or infective.\nFigure 44.3 shows the flow field for \\(\\beta = 1/2\\) and \\(\\alpha = 1/7\\).\n\n## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\nFigure 44.3: SIR flow field for \\(\\beta=1/2, \\alpha = 1/7\\), and the trajectory for initial conditions \\(S_0 = 0.999, I_0 = 0.001\\).",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Modeling dynamics</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-equilibria.html",
    "href": "Dynamics/B6-equilibria.html",
    "title": "45  Equilibrium and transient",
    "section": "",
    "text": "45.1 One state variable\nLinear systems with one state variable have simple dynamics: \\[\\partial_t y = k y\\] which has a fixed point at \\(y^\\star = 0\\). Even dynamics like \\(\\partial_t x = k x + b\\) can be easily transformed into this simple form; the fixed point is \\(x^\\star = - b/a\\) and defining \\(y \\equiv x - x^\\star\\) gives the \\(\\partial_t y = k y\\) form.\nThe solution is also simple: \\(y(t) = y_0\\  e^{kt}\\), where \\(y_0\\) is the initial condition on \\(y\\). If the parameter \\(k &lt; 0\\), the dynamics are exponential decay to the fixed point. If \\(0 &lt; k\\), the dynamics are exponential growth away from the fixed point.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Equilibrium and transient</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-equilibria.html#two-state-variables",
    "href": "Dynamics/B6-equilibria.html#two-state-variables",
    "title": "45  Equilibrium and transient",
    "section": "45.2 Two state variables",
    "text": "45.2 Two state variables\nIf the state variables \\(x\\) and \\(y\\) are measured with respect to a fixed point, the differential equation of the linear or linearized system is: \\[\\begin{eqnarray}\n\\partial_t x & = a x + b y\\\\\n\\partial_t y & = c x + d y\\ .\\\\\n\\end{eqnarray}\\]\nExponentials are an important form of ansatz for linear differential equations. To show why, let’s review the solution to \\(\\partial_t x = k x\\), but assume that all we know is that the solution is an exponential function of time: \\(x(t) = A e^{\\lambda t}\\) and that we don’t yet know the parameters \\(A\\) or \\(\\lambda\\). As usual for an ansatz, we plug it into both sides of the differential equation, giving \\[\\partial_t A e^{\\lambda t} = k A e^{\\lambda t}\\ \\ \\implies \\lambda A e^{\\lambda t} = k A e^{\\lambda t}\\ \\ \\implies \\lambda = k\\ .\\] Now we know the value of \\(\\lambda\\).\nWhat about \\(A\\)? Evaluate the solution at \\(t=0\\). This gives \\(x(0) = A e^{\\lambda 0} = A\\). So we know \\(A\\) is the initial condition \\(x(0)\\) (which we usually abbreviate \\(x_0\\)).\nWe will try the same approach with the two-state variable system, but we will start with a special case where some of the parameters \\(a, b, c\\), and \\(d\\) are zero.\n\\[\\text{Simplification:}\\ \\ \\  \\ \\ \\begin{array}{l}\\partial_t x  = \\cancel{ax}  +  b y\\\\\\partial_t y =\\ c x + \\cancel{dy}\\end{array}\\ .\\]\nIn the spirit of exponential ansatze, we might try \\[x(t) \\equiv C e^{\\lambda_1 t} \\ \\ \\text{and}\\ \\ \\ y(t) \\equiv D e^{\\lambda_2 t}\\ .\\]\nBut this is unnecessary complexity. To see why plug the ansatze in to the first differential equation to get \\[\\lambda_1 C e^{\\lambda_1 t} = b D e^{\\lambda_2 t}\\ .\\] This can be true only if \\(\\lambda_1 \\neq \\lambda_2\\) because exponentials with different half-lives cannot be proportional to one another.\nIf \\(x(t)\\) and \\(y(t)\\) are proportional to one another, then we hardly need to keep track of both. In fact, we need just one differential equation in \\(x(t)\\). To turn the system of differential equations into a single differential equation we will take the derivative with respect to time of both sides of the top equation, giving: \\[\\partial_{tt} x = b\\,  \\partial_{t\\ }y\\\\\n\\partial_{t\\ } y  =  c\\, x \\] Substitute in the value for \\(\\partial_t y\\) from the bottom equation to get a single, second-order differential equation: \\[ \\partial_{tt} x = b\\, c\\, x\\ .\\]\nPlug in the usual ansatz, \\(x(t) = A e^{\\lambda t}\\) to get \\[\\lambda^2 A e^{\\lambda t} = b\\,c\\, A e^{\\lambda t}\\ \\ \\ \\implies\\ \\ \\ \\ \\lambda = \\pm \\sqrt{\\strut b\\,c}\\] The \\(\\pm\\) is the interesting part here. If, say, \\(b=1\\) and \\(c=1\\), there are two values for \\(\\lambda\\) that will be consistent with the differential equation: \\(\\lambda_1 = 1\\) and \\(\\lambda_2 = -1\\). Either of these will produce a solution that satisfies the differential equation: \\(x_1(t) = A e^{\\lambda_1 t}\\) or \\(x_2(t) = B e^{\\lambda_2 t}\\). So which of the two possibilities is it?\nSince everything about the differential equation is linear, any linear combination of the two possibilities will also satisfy the equation. So we can conclude that \\[x(t) = A e^{\\lambda_1 t} + B e^{\\lambda_2 t}\\ .\\]\nSince \\(\\lambda_2 = -1\\), we know that the \\(B e^{\\lambda_2 t}\\) component of the linear combination will decay to zero. That is, \\(B e^{\\lambda_2 t}\\) is the transient part of the solution.\nWhat are \\(A\\) and \\(B\\)? That depends on the initial condition. Evaluate both sides of the solution equation at \\(t=0\\) to get \\[x(0) = A e^{\\lambda_1 0}+ B e^{\\lambda_2 t} = A + B\\ .\\] At this point, you need to look back at the original system of equations. There are two state variables \\(x\\) and \\(y\\) and therefore we need to specify two components of the initial condition. If \\(x(0)\\) is interpreted as the initial position, then following the example of the pendulum we can look to the velocity \\(\\partial_t x\\) as the second component of the initial condition. From \\(x(t)\\) we can easily calculate the velocity: \\[\\partial_t x(t) = \\lambda_1 A e^{\\lambda_1 t} + \\lambda_2 B e^{\\lambda_2 t}\\ .\\] Again, evaluate this at \\(t=0\\) to get a second equation for the initial condition the pair \\[\\begin{array}{c}\\partial_t x(0)  =   \\lambda_1 A  +  \\lambda_2 B\\\\x(0)  = \\ \\ A \\ \\  + \\ B\\\\\\end{array}\\ \\ \\ \\ \\implies\\ \\ \\ \\\n\\left[\\begin{array}{c}\\lambda_1 \\ \\ \\ \\ \\ \\lambda_2\\\\1 \\ \\ \\ \\ \\ \\  1\\end{array}\\right] \\left[\\begin{array}{c}A\\\\ B\\end{array}\\right] = \\left[\\begin{array}{c}\\partial_t x(0)\\\\ x(0)\\end{array}\\right] .\\] From Block 5, we know how to solve such matrix equations. So, given the initial values \\(x(0)\\) and \\(\\partial_t x(0)\\)—position and velocity—we can find an exact, quantitative solution to the differential equation.\n\n\n\n\n\n\n\n\nTry it! 45.1\n\n\n\n\n\n\n\n\n\nTry it! 45.1 Trajectories and their time series\n\n\n\nFigure 45.1 shows the flow field, some trajectories and their corresponding time series for the system \\[\\partial_t x = b y\\\\ \\partial_t y = c x\\] for \\(b=1\\) and \\(c=2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.1: Three trajectories from the system \\(\\\\partial_t x = y\\) & \\(\\\\partial_t y = 2 x\\)\n\n\n\nEach of these trajectories starts out by heading toward the fixed point at (0,0). Then, each turns and heads away toward \\(\\pm \\infty\\) from the fixed point,\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.2: The time series \\(x(t)\\) for the three different trajectories in Figure 45.1.\n\n\n\nEach of the time series is similar, first showing exponential decay toward 0 then exponential growth toward \\(\\pm \\infty\\).\nThe initial conditions for the black and \\(\\color{magenta}{\\text{magenta}}\\) trajectories are very similar. You can imagine a trajectory starting between those initial conditions that would go down the middle of the “trumpet.” This trajectory would be exponential decay toward 0, but would be hard to see since \\(x=0, y=0\\) is an unstable fixed point (a saddle).\nThe initial condition for the black trajectory is \\(x(0)=0.72\\) and \\(y(0)=\\partial_t x(0) = -1\\), while for the \\(\\color{magenta}{\\text{magenta}}\\) trajectory it is \\(x(0)=0.70\\) and \\(y(0)=\\partial x(0) = -1\\). Let’s find each trajectory as a separate linear combination \\(A e^{\\lambda_1 t} + B e^{\\lambda_2 t}\\). The equations to solve are \\[\\left[\\begin{array}{c}1 \\ \\ \\ \\ 1\\\\\\lambda_1 \\ \\  \\lambda_2\\end{array}\\right] \\left[\\begin{array}{c}A\\\\ B\\end{array}\\right] = \\left[\\begin{array}{c}x(0)\\\\ \\partial_t x(0)\\end{array}\\right] .\\]\nBy plugging in the parameters \\(a=0\\), \\(b=1\\), \\(c=2\\), \\(d=0\\) in the dynamical functions, we find that \\[\\lambda = \\pm \\sqrt{\\strut 2} \\approx \\pm 1.4142 \\ .\\] Therefore, we solve \\[\\left[\\begin{array}{c}1.4142 \\ \\ \\  -1.4142\\\\1 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   1\\end{array}\\right] \\left[\\begin{array}{c}A\\\\ B\\end{array}\\right] = \\left[\\begin{array}{c}\\partial_t\\,x(0)\\\\x(0)\\end{array}\\right] .\\]\nM &lt;- cbind(rbind(1.4142, 1), rbind(-1.4142,1))\nb_black = rbind(-1, 0.72)\nb_magenta = rbind(-1, 0.70)\nqr.solve(M, b_black)\nqr.solve(M, b_magenta)\nThe two trajectories are therefore\n\\(x_\\text{black}(t) = 0.0064 e^{1.4142 t} + 0.7136 e^{-1.4142}\\)\n\\(\\color{magenta}{x_\\text{magenta}(t)} = -0.00356 e^{1.4142 t} + 0.70356 e^{-1.4142 t}\\).\nFor both trajectories, the initial amplitude of the decaying exponential is much larger than for the growing exponential. That is why the time series decay toward zero initially. As \\(t\\) grows, the exponential growth become much more important. For the black trajectory, the exponential growth has a positive coefficient, so the growth is toward \\(\\infty\\). But for the \\(\\color{magenta}{\\text{magenta}}\\) trajectory, the exponential growth has a negative coefficient, thus that trajectory grows toward \\(-\\infty\\).\n\n\nThe method we used to solve the simplified problem also works for the original problem \\[\\begin{array}{c}\\partial_t x  = ax  +  b y \\\\ \\partial_t y = c x +  dy\\end{array}\\ .\\]\nStep 1: Differentiate with respect to \\(t\\) both sides of the top equation, giving\n\\[\\begin{array}{c}\\partial_{tt} x  =   a\\, \\partial_t x  +  b\\, \\partial_t y\\\\ \\  \\ \\ \\partial_t y =  c x \\ \\ \\ \\ \\ \\ \\ +  dy\\ \\ \\ \\ \\ \\ \\ \\ \\end{array}\\ .\\] Step 2: Use the second equation to substitute for \\(\\partial_t\\, y\\) in the top equation, giving \\[\\partial_{tt} x = a \\partial_t x + b\\left(\\strut c x + dy\\right) = a\\, \\partial_t x + b\\, c\\, x + b\\, d\\, y\\] Step 3: One more substitution. From the original top equation, we know \\[y = \\frac{\\partial_t x - a x}{b}\\ .\\] Plug this in for \\(y\\) in the result from Step 2, giving \\[\\partial_{tt} x = a\\, \\partial_t x + b\\, c\\, x + b\\, d\\, \\frac{\\partial_t x - a x}{b} = \\left(\\strut a + d\\right)\\ \\partial_t x + \\left(\\strut b c - a d\\right)\\] Step 4: Use the ansatz \\(x(t) = e^{\\lambda t}\\). This produces \\[\\lambda^2 e^{\\lambda t}= (a + d) \\lambda e^{\\lambda t}+ \\left(\\strut bc - ad\\right)e^{\\lambda t} \\ \\ \\ \\implies\\ \\ \\ \\lambda^2 = (a + d) \\lambda + \\left(\\strut bc - ad\\right)\\] which can be solved for \\(\\lambda\\): \\[\\lambda = \\frac{1}{2}\\left(a + d\\right) \\pm \\frac{1}{2}\\sqrt{\\left(a - d\\right)^2 - 4 b c}\\] Again, the \\(\\pm\\) is the interesting bit here. There are two simple solutions that satisfy the differential equation: \\(x_1(t) = e^{\\lambda_1 t}\\) and \\(x_2(t) = e^{\\lambda_2 t}\\). In addition, any linear combination \\(A e^{\\lambda_ t} + B e^{\\lambda_2 t}\\) of these simple solutions will satisfy the differential equations. Once we know \\(\\lambda_1\\) and \\(\\lambda_2\\), the situation is identical to the simplified version. Again, knowing the initial condition \\(x(0)\\) and \\(\\partial_t x(0)\\) allows us to find the coefficients in the linear combination by solving the matrix equation \\[\\left[\\begin{array}{c}\\lambda_1 \\ \\ \\  \\lambda_2\\\\1 \\ \\ \\ \\ \\ 1\\end{array}\\right] \\left[\\begin{array}{c}A\\\\ B\\end{array}\\right] = \\left[\\begin{array}{c}\\partial_tx(0)\\\\  x(0)\\end{array}\\right] .\\]",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Equilibrium and transient</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-eigen.html",
    "href": "Dynamics/B6-eigen.html",
    "title": "46  Eigenvalues, eigenvectors",
    "section": "",
    "text": "46.1 Vector solutions to linear differential equations\nThe form in which we have been writing linear differential equations in two state variables is \\[\\begin{eqnarray}\n\\partial_t x & = a x + b y\\\\\n\\partial_t y & = c x + d y\\ .\n\\end{eqnarray}\\]\nA key part of constructing a theory of stability is finding a set of mathematical ideas that enable us to view dynamics in a simpler way. The idea we will introduce here is thinking about the state and trajectory of a differential equation in terms of vectors. We will work here with systems with a two-variable dynamical state, but the results apply just as well to higher dimensional states. That is important in applied work, where the systems being modeled are complicated with many state components.\nWe can re-write the linear differential equation using vector and matrix notation. Suppose that we collect the \\(x\\) and \\(y\\) components of the state into a vector, \\[\\vec{w(t)} =\\left[\\begin{array}{c}x(t)\\\\y(t)\\end{array}\\right]\\ .\\] The differential equation, in terms of \\(\\vec{w(t)}\\) is \\[\\partial_t \\vec{w(t)} = \\left[\\begin{array}{cc}a&b\\\\c&d\\end{array}\\right] \\vec{w(t)}\\ .\\] Now imagine that we pick two non-colinear vectors, \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) that span the state space. Since the vectors are assumed to span the state, any initial condition can be written as a linear combination of those two vectors: \\[\\vec{w(0)} =\\left[\\begin{array}{c}x(0)\\\\y(0)\\end{array}\\right] = m_1 \\vec{u_1} + m_2 \\vec{u_2}\\ .\\]\nFor the moment, we won’t worry about how best to choose \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\); any two vectors that are not colinear will do.\nAs a running example, we will work with the pair of first-order differential equations \\[\\begin{eqnarray}\n\\partial_t x &= x + y\\\\\n\\partial_t y &= 2 x \\ ,\\\\\n\\end{eqnarray}\\] which, in vector/matrix form are \\[\\partial_t \\vec{w(t)} = \\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right] \\vec{w(t)}\\ .\\] Imagine that we choose, arbitrarily, \\[\\vec{u_1} = \\color{magenta}{\\left[\\begin{array}{r}1\\\\-3\\end{array}\\right]}\\ \\ \\ \\text{and}\\ \\ \\ \\vec{u_2} = \\color{blue}{\\left[\\begin{array}{r}1.0\\\\0\\end{array}\\right]}\\ .\\]\nFor the example, we will calculate a trajectory starting at the initial condition \\(\\vec{w(0)} = \\left[\\begin{array}{r}-1.1\\\\ 2.1\\end{array}\\right]\\):\ntraj &lt;- integrateODE(dx ~ x + y, dy ~ 2*x, x=-1.1, y=2.1, domain(t=0:2))\ntraj_plot(y(t) ~ x(t), traj)\nFigure 46.1: The trajectory calculated starting at (-1.1, 2.1). The graph is annotated with the vectors \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) and the flow field.\nThe initial condition (marked “0” in Figure 46.1 is, like any other point in the state space, a linear combination of \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\). We can find the scalar coefficients of the linear combination using any of the methods presented in Block 5, for instance the telescope method. We will illustrate with qr.solve():\nM &lt;- cbind(rbind(1,-3), rbind(1,0))\nw0 &lt;- rbind(-1.1, 2.1)\nqr.solve(M, w0)\n##      [,1]\n## [1,] -0.7\n## [2,] -0.4\nSo, \\(\\vec{w(0)} = -0.7 \\vec{u_1} - 0.4 \\vec{u_2}\\). Keep these scalar coefficients, \\(-0.7\\) and \\(-0.4\\) in mind for the next example.\nWe can use integrateODE() to find the solution starting at any initial condition. In particular, we can find the solution \\(\\vec{u_1}\\) as the initial condition and, similarly, using \\(\\vec{u_2}\\) as the initial condition.\ntraj_u1 &lt;- integrateODE(dx ~ x + y, dy ~ 2*x, x=1, y=-3, domain(t=0:2))\ntraj_u2 &lt;- integrateODE(dx ~ x + y, dy ~ 2*x, x=1, y= 0, domain(t=0:2))\nFigure 46.2 shows these trajectories.\nFigure 46.2: Trajectories from the initial conditions \\(\\color{magenta}{\\vec{u_1}}\\) and \\(\\color{blue}{\\vec{u_2}}\\).\nAt first glance, the two trajectories \\(\\vec{u_1(t)}\\) and \\(\\vec{u_2(t)}\\) in Figure 46.2 that start from \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) might not look much like the trajectory in Figure 46.1 that starts from \\(\\vec{w(0)} = -0.7 \\vec{u_1} - 0.4 \\vec{u_2}\\). But in fact there is a very simple relationship between the trajectories: \\[\\vec{w(t)} = -0.7 \\vec{u_1(t)} - 0.4 \\vec{u_2(t)}\\ .\\] To state the situation more generally, any solution to the differential equations can be written as a linear combination of the solutions starting at \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\), regardless of how \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) were chosen.\nWe can see this algebraically. Since \\(\\vec{u_1(t)}\\) and \\(\\vec{u_2(t)}\\) are solutions to the linear differential equation, it must be that \\[\\partial_t \\vec{u_1(t)} = \\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right] \\vec{u_1(t)}\\ \\ \\text{and}\\ \\ \\partial_t \\vec{u_2(t)} = \\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right] \\vec{u_2(t)}\\ .\\] Taking a linear combination of these equations gives\n\\[\\partial_t \\left[m_1\\, \\vec{u_1(t)} + m_2 \\vec{u_2(t)}\\right] = \\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right] \\left[m_1\\, \\vec{u_1(t)} + m_2 \\vec{u_2(t)}\\right]\\] The same will be true in general, that is, for the matrix \\(\\left[\\begin{array}{cc}a&b\\\\c&d\\end{array}\\right]\\).",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Eigenvalues, eigenvectors</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-eigen.html#eigenvectors-and-eigenvalues",
    "href": "Dynamics/B6-eigen.html#eigenvectors-and-eigenvalues",
    "title": "46  Eigenvalues, eigenvectors",
    "section": "46.2 Eigenvectors and eigenvalues",
    "text": "46.2 Eigenvectors and eigenvalues\nIn the previous section, we saw that the solution to any linear differential equation starting at any initial condition can be written as a linear combination \\(m_1 \\vec{u_1(t)} + m_2 \\vec{u_2(t)}\\), where \\(\\vec{u_1(t)}\\) is the solution starting at an initial condition \\(\\vec{u_1}\\) and \\(\\vec{u_2(t)}\\) is the solution starting at \\(\\vec{u_2}\\). It does not matter how \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) are chosen, so long as they are not colinear, that is, so long as they span the state space.\nIn this section, we will demonstrate that there is a particular way of selecting \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) that makes the solutions \\(\\vec{u_1(t)}\\) and \\(\\vec{u_2(t)}\\) have a very simple, purely exponential format. The vectors to be chosen are the eigenvectors of the matrix \\(\\left[\\begin{array}{cc}a&b\\\\c&d\\end{array}\\right]\\). We will call these eigenvectors \\(\\vec{\\Lambda_1}\\) and \\(\\vec{\\Lambda_2}\\). (This use of the Greek letter \\(\\Lambda\\) (capital “lambda”) and it is lower-case version \\(\\lambda\\), is conventional in mathematics, physics, and engineering. So it is worth learning to identify the letters.)\nOur task in this section is to show how to compute the eigenvectors \\(\\vec{\\Lambda_1}\\) and \\(\\vec{\\Lambda_2}\\) and that the solutions \\(\\vec{\\Lambda_1(t)}\\) and \\(\\vec{\\Lambda_2(t)}\\) are in fact simple exponentials. In Chapter 47 we will derive the formula for the eigenvectors. Here, we will use the R function eigen() to do the calculations for us.\n\n\n\n\n\n\n\n\nTry it! 46.1\n\n\n\n\n\n\n\n\n\nTry it! 46.1 Calculating eigenvectors\n\n\n\nEigenvectors can be calculated using the R function eigen() applied to the abcd matrix that defines the linear differential equation.\nFor the system of first-order differential equations \\[\\partial_t x = x + y\\\\\\partial_t y = 2x\\ \\ \\ \\ \\ \\] the matrix is, as we’ve seen, \\[\\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right]\\ .\\]\nCarrying out the eigenvector calculation is straightforward:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe eigenvectors are the two columns of the matrix labeled vectors returned by the calculation. Here, that is\n\\[\\vec{\\Lambda_1} = \\left[\\begin{array}{r}0.7071\\\\0.7071\\end{array}\\right]\n\\ \\ \\ \\text{and}\\ \\ \\ \\\n\\vec{\\Lambda_2} = \\left[\\begin{array}{r}-0.4472\\\\0.8944\\end{array}\\right]\\ .\\]\nThe calculation also produces eigenvalues. Here that is \\(\\lambda_1 = 2\\) and \\(\\lambda_2 = -1\\).\n\n\nWe can see what’s special about \\(\\vec{\\Lambda_1}\\) and \\(\\vec{\\Lambda_2}\\) by plotting them along with the flow field, as in Figure 46.3.\n\n\n\n\n\n\n\n\nFigure 46.3: The eigenvectors for the \\(\\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right]\\) plotted along with the flow.\n\n\n\n\n\nThe eigenvectors mark the directions where the flow is either directly toward the fixed point or directly away from it. Here, the flow on the subspace of \\(\\color{magenta}{\\vec{\\Lambda_1}}\\) is away from the fixed point, while the flow along the subspace of \\(\\color{blue}{\\vec{\\Lambda_2}}\\) is inward to the fixed point.\nThe consequence of this alignment of the flow with the eigenvectors is that the trajectory from any initial condition \\(m_1 \\vec{\\Lambda_1}\\) will have the form \\(m_1(t) \\vec{\\Lambda_1}\\) and similarly for an initial condition \\(m_2(t) \\vec{\\Lambda_2}\\).\nAs we did in the previous section, let’s calculate the trajectories \\(\\color{magenta}{\\vec{\\Lambda_1(t)}}\\) and \\(\\color{blue}{\\vec{\\Lambda_2(t)}}\\) starting at the two eigenvectors and plot out the \\(y(t)\\) component of the solution. Since we are anticipating an exponential form for the function, we will use semi-log axes, where an exponential will look like a straight line.\n\ntraj_eigen1 &lt;- integrateODE(dx ~ x + y, dy ~ 2*x, \n                            bounds(t=0:1), \n                            x=0.7071, y=0.7071)\n## Solution containing functions x(t), y(t).\ntraj_eigen2 &lt;- integrateODE(dx ~ x + y, dy ~ 2*x, \n                            bounds(t=0:1),\n                            x=-0.4472, y=0.8944)\n## Solution containing functions x(t), y(t).\ntraj_plot(y(t) ~ t, traj_eigen1, color=\"magenta\") %&gt;%\n traj_plot(y(t) ~ t, traj_eigen2, color=\"blue\") |&gt; \n  gf_refine(scale_y_log10(\n    breaks=c(0.3290, 0.7071, 0.8944, 5.2248)))\n\n\n\n\n\n\n\n\nWe have marked the \\(y\\) axis with the starting and ending values of each function, so that you can find the exponential parameter \\(k\\) for each function.\n\\(\\color{magenta}{y_1(t) = 0.7071 e^{k_1 t}}\\)\n\\(\\color{blue}{y_2(t)} = 0.8944 e^{k_2 t}\\).\nTo find \\(k_1\\) and \\(k_2\\), plug in \\(t=1\\) to the solution:\n\\(\\color{magenta}{y_1(1) = 5.2248 = 0.7071 e^{k_1}} \\implies k_1=2\\)\n\\(\\color{blue}{y_2(1) = 0.3290 = 0.8944 e^{k_2}} \\implies k_2 = -1\\)\nLook back at the results from the eigen(M) calculation. These values for \\(k_1\\) and \\(k_2\\) are exactly the eigenvalues that were computed from the matrix M. In standard notation, rather than \\(k_1\\) and \\(k_2\\), the notation \\(\\lambda_1 = k_1\\) and \\(\\lambda_2 = k_2\\) is preferred. (Remember, \\(\\lambda\\) is the Greek letter “lambda” in it is lower-case form.) Every solution to the differential equation has the form \\[m_1\\, e^{\\lambda_1 t} \\vec{\\Lambda_1} + m_2\\, e^{\\lambda_2 t} \\vec{\\Lambda_2}\\ .\\] The scalar coefficients \\(m_1\\) and \\(m_2\\) can be found from the initial condition. The stability of the system depends only on \\(\\lambda_1\\) and \\(\\lambda_2\\). If either one of these is positive, then the system is unstable.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Eigenvalues, eigenvectors</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-second-order.html",
    "href": "Dynamics/B6-second-order.html",
    "title": "47  Force-balance equations",
    "section": "",
    "text": "47.1 Ballistics\nA lot of the theory of second-order differential equations was developed in the setting of a ball being set off with an initial velocity from an initial position. Such a focus on the flight of balls might seem trivial. Fortunately, language allows us to construct a scientific-sounding word by adding the suffix “istic” to the root “ball.” This suffixing produces the word ballistics.\nThe importance of ballistics to Newton can be seen by a famous diagram he drew, shown in Figure 47.1. In the diagram, Newton traces the path of a ball shot horizontally from a cannon placed at the top of a mountain.\nFigure 47.1: Newton’s diagram showing ballistic motion under the force of gravity.\nSince the motion in Newton’s diagram has both vertical and horizontal components, we will need two second-order differential equations:\n\\[\\text{Horizontal}: \\ \\ \\partial_{tt} x = 0\\\\\n\\ \\ \\ \\text{Vertical}: \\ \\ \\ \\ \\ \\ \\partial_{tt} y = -g\\] The zero on the right-hand side of the equation of horizontal movement reflects that gravity does not act horizontally.\nWe found a solution for the vertical equation in the previous section, \\[y(t) = -\\frac{1}{2} g\\,t^2 + 0\\,t + y_0\\ .\\] The \\(0\\, t\\) component to the solution reflects that the vertical component of the ball, coming out of the cannon, is zero.\nThe solution for the horizontal component of motion can be found by anti-differentiating both sides of the equation of hortizontal motion: \\[\\int \\partial_{tt} x(t)\\, dt = \\partial_t x(t) = \\int 0\\, dt = v_0\\] where \\(v_0\\) is the initial horizontal velocity. A second stage of anti-differentiation gives \\(x(t)\\) itself: \\[\\int \\partial_t x(t) = \\int v_0 dt = v_0\\, t + x_0\\]\nRegrettably, symbolic anti-differentiation works only in simple cases. To support more realistic models of ballistics, let’s see how to translate the two second-order differential equations into sets of first-order equations. The state variables will be \\(x(t)\\) and \\(y(t)\\), but we also have to add another pair, \\(u(t)\\) and \\(v(t)\\) standing for the horizontal and vertical velocities respectively. The first-order equations will be: \\[\\partial_t x = u\\\\\n\\partial_t y = v\\\\\n\\partial_t u = 0\\\\\n\\partial_t v = -g\n\\] To illustrate, we will solve this set of four first-order equations numerically. We need to specify the initial values for \\(x_0\\), \\(y_0\\), \\(u_0\\) and \\(v_0\\). We will let the cannon be located at horizontal position \\(x_0 = 0\\) and vertical position \\(y_0 = 100\\) meters. The vertical velocity is, initially, zero, so \\(v_0 = 0\\). And suppose the cannon produces an initial horizontal velocity of \\(u_0 = 250\\) meters/sec. The constant \\(g\\) is known to be 9.8 meters/sec2.\nHere’s the trajectory:\ntraj &lt;- integrateODE(\n  dx ~ u, dy ~ v, du ~ 0, dv ~ -9.8, #dynamics\n  x=0, y=100, u = 250, v=0, #initial conditions\n  bounds(t=0:5)\n) \n# traj_plot(y(t) ~ x(t), traj)\n# traj_plot(v(t) ~ u(t), traj)\nThe left panel in ?fig-cannon-shot-1 shows that the trajectory is a parabola. At about \\(t=4.4\\) secs the \\(y\\) position is zero. Since zero is the location of the ground, the part of the trajectory for \\(4.4 &lt; t\\) is invalid, since the ball has already hit the ground. The ball travels a little more than 1100 meters horizontally before hitting the ground.\nThe right panel might seem somewhat strange. You can see that the vertical component of velocity, \\(v(t)\\) starts out at zero and increases linearly with time, becoming more and more negative as gravity continuous to accelerate the ball downward. The vertical velocity, \\(u(t)\\), stays constant at \\(u(t) = 250\\) meters per second. This is because there is no horizontal force on the ball.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Force-balance equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-second-order.html#sec-ballistics",
    "href": "Dynamics/B6-second-order.html#sec-ballistics",
    "title": "47  Force-balance equations",
    "section": "47.2 The harmonic oscillator",
    "text": "Trajectory of the cannon ball shot with an initial horizontal velocity and no initial vertical velocity. The trajectory is plotted in slices of state space: position \\((x, y)\\) and velocity \\((u, v)\\). The time at which the ball reaches the points marked in the boxes.\n\n\n\n\n\n\n\n\n\nCalculus history—Computing trajectories\n\n\n\nThe world’s first programmable, electronic, general-purpose digital computer was started up in 1945 at the University of Pennsylvania, where it is still on display. The date and location have something to say about why the computer was built. 1945 is, of course, at the end of World War II. The computer was built to carry out some important war-time calculations. The place, Philadelpha, Pennsylvania, has to do with the location of the US Army’s center for developing and testing ordnance: the Aberdeen Proving Ground which is only 75 miles from the University of Pennsylvania.\nThe name given to the computer, ENIAC, has a science-fiction flavor but is in fact rooted in its purpose: the Electronic Numerical Integrator and Computer. ENIAC was constructed to calculate the trajectories of artillery shells. Knowing the trajectory is essential to being able to fire artillery accurately.\nThe ballistics of real world artillery shells is more complex than the simple model we constructed earlier. What’s missing from that model is air resistance, which is a function of the shell’s velocity and altitude. To illustrate, let’s add in a simple model of air resistance to the earlier ballistic model. In this model, the force of air resistance is a vector pointing in the opposite direction to overall velocity and proportional to velocity squared.\nThe velocity vector is simply \\(\\left[\\begin{array}{c}u\\\\v\\end{array}\\right]\\). The air resistance force will be \\[-\\alpha\\sqrt{\\strut u^2 + v^2} \\left[\\begin{array}{c}u\\\\v\\end{array}\\right]\\ .\\] Consequently, the horizontal component of the air-resistance vector is \\(-\\alpha\\, u \\sqrt{\\strut u^2 + v^2}\\) and the vertical component is \\(-\\alpha\\, v \\sqrt{\\strut u^2 + v^2}\\).\nRepresenting air resistance by the function \\(r(u, v)  \\equiv \\alpha \\sqrt{\\strut u^2 + v^2}\\), the dynamics are \\[\\begin{eqnarray}\n\\partial_t x & = u\\\\\n\\partial_t y & = v\\\\\n\\partial_t u & = -u\\ r(u,v)\\\\\n\\partial_t v &= -g - v\\ r(u,v)\\\\\n\\end{eqnarray}\\]\nintegrateODE() carries out the calculation in R/mosaic.\n\nr &lt;- makeFun(alpha*sqrt(u^2 + v^2) ~ u & v, alpha=0.003)\ntraj2 &lt;- integrateODE(\n  dx ~ u, dy ~ v, du ~ -u*r(u,v), dv ~ -9.8 - v*r(u,v), #dynamics\n  x=0, y=100, u = 250, v=0, #initial conditions\n  bounds(t=0:6)\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 47.2: Adding air resistance to the model changes the trajectory. For reference, the trajectory without air resistance is plotted in \\(\\color{orange}{\\text{orange}}\\). Air resistance causes the cannon ball to travel a shorter horizontal distance before hitting the ground and to arrive with a much reduced velocity.\n\n\n\n\n47.2 The harmonic oscillator\nConsider the motion of a weight attached to a spring, as in ?fig-spring-mass. We will denote the vertical position of the mass by \\(y(t)\\). Such a spring-mass system has a fixed point where the spring is stretched just enough to cancel out gravity and the velocity is zero. We will measure \\(y\\) relative to this fixed point.\n\n\n\n\n\n\nFigure 47.3: A spring-mass system in motion. Source: Svjo CC BY-SA via Wikimedia Commons\n\n\n\nAccording to Hooke’s Law, a stretched or compressed spring exerts a force that is proportional to the amount of extension or compression. With our measuring \\(y\\) relative to the fixed point, the Hooke’s Law force will be \\[m\\, \\partial_{tt} y = - s\\, y\\ ,\\] where \\(m\\) is the amount of mass and \\(s\\) is the stiffness of the spring. This force-balance equation corresponds to the second-order differential equation \\[\\partial_{tt} y = - \\frac{s}{m} y\\ .\\]\nYou can see that the motion is oscillatory, which suggests that the solution to the differential equation will be of the form \\(y(t) = A \\sin(\\omega t)\\). Taking this as an ansatz leads to finding a value of \\(\\omega\\), which is called the angular frequency of the oscillation. (In terms of the period of oscillation \\(P\\), the angular frequency is \\(\\omega = 2 \\pi/P\\).)\nTo find \\(\\omega\\), plug in the ansatz to the differential equation:\n\\[\\partial_{tt} A \\sin(\\omega t) = - \\frac{s}{m}\\, A \\sin(\\omega t)\\] Differentiating \\(\\sin(\\omega t)\\) once let’s us re-write the left-hand side of the equation in terms of a first derivative\n\\[\\partial_{t} A \\omega\\, \\cos(\\omega t) = - \\frac{s}{m}\\, A \\sin(\\omega t)\\] Differentiating again gives \\[- \\omega^2 A\\sin(\\omega\\, t) = - \\frac{s}{m}\\, A\\sin(\\omega t)\\ .\\] Simplifying this by cancelling out the \\(A \\sin(\\omega t)\\) term gives \\(\\omega^2 = \\frac{s}{m}\\), where \\(\\omega\\) is the angular frequency of the oscillation.\n\n\n\n\n\n\nTip\n\n\n\nInstead of using \\(A \\sin(\\omega t)\\) as the ansatz we could have used \\(A \\sin(\\omega t) + B \\cos(\\omega t)\\). Working through this ansatz would produce the same result, that \\(\\omega^2 = \\frac{s}{m}\\). So the solution to the spring-mass system will be, in general, a linear combination of the sine and the cosine functions with angular frequency \\(\\omega\\).\n\n\n\n\n47.3 Exponential or sinusoid?\nIn Chapter 46, we established that solutions to second-order linear differential equations have the form \\(m_1 e^{\\lambda_1 t} + m_2 e^{\\lambda_2 t}\\). Yet in the previous section, we saw one linear second-order differential equation, \\(\\partial_{tt} y = - \\omega^2 y\\) where the solution is a linear combination of a sine and a cosine function: \\(y(t) = A \\sin(\\omega t) + B \\cos(\\omega t)\\) with \\(\\omega = \\sqrt{\\frac{s}{m}}\\).\nHow is it possible for the solution to be both in the form of a linear combination of exponentials and a linear combination of sine and cosine? Sinusoids oscillate up and down and up and down, whereas exponentials are monotonic.\nTo find out what might be the relationship between an exponential and a sinusoid, let’s plug an exponential ansatz \\(y(t) = A e^{\\lambda t}\\) into the spring-mass system \\(\\partial_{tt} y = -\\omega^2 y\\).\n\\[\\partial_{tt} A e^{\\lambda t} = \\lambda^2 A e^{\\lambda t} = -\\omega^2 A e^{\\lambda t}\\ .\\] As before, we will cancel out the common term \\(A e^{\\lambda t}\\) to get a simple relationship: \\[\\lambda^2 = -\\omega^2\\ \\ \\ \\implies\\ \\ \\ \\lambda = \\pm \\sqrt{\\strut-1}\\  \\omega \\ .\\] Generally, the symbol \\(i\\) is used to stand for \\(\\sqrt{\\strut -1}\\), so our eigenvalues can be written \\(\\lambda = \\pm i \\omega\\). The solution to the spring-mass system, according to this analysis, is: \\[y(t) = m_1 e^{i\\omega t} + m_2 e^{-i \\omega t}\\]\nIn other words, \\(e^{i \\omega t}\\)—notice the \\(i\\) in the argument to the exponential—is a sinusoid with angular frequency \\(\\omega\\).\n\n\n47.4 Exponentials with “imaginary” inputs\nThe “imaginary” in the section title is used in its mathematical sense. In interpreting the word “imaginary,” you should keep in mind a long history in mathematics of assigning insulting names to mathematical objects that, at the time they were first introduced. That is why some numbers are vilified as “negative,” and some as “irrational.” The insult is even more dire for numbers like \\(i\\), which are called the “imaginary” numbers. Regrettably, the word “imaginary” leads many people to shy away from them, just as many people avoid genres such as fantasy fiction. That imaginary numbers are introduced as kind of freakish—is there a numerical value for \\(\\sqrt{\\strut -1}\\)?—and rarely touched until advanced calculus, means that students are unused to them.\nYou will only get comfortable with “imaginary” numbers when you start to work with them extensively, as happens in physics and engineering courses. Our goal here is merely to increase your awareness of imaginary numbers and some of the ways they are used in the sciences. To that end, we offer three different approaches to understanding the function \\(e^{i\\omega t}\\).\n\nBasic, pragmatic understanding. This is the level of understanding that you must have to make sense of the rest of this chapter and ?sec-forcing. Here it is: \\[e^{i\\omega t}\\ \\text{is simply a shorthand for}\\ \\cos(\\omega t).\\] So whenever you see \\(e^{i \\omega t}\\), think of \\(\\cos(\\omega t)\\).\nAlgebraic understanding via Taylor Polynomials. (optional) This level of understanding can give you confidence that the basic, pragmatic understanding in (1) has honest roots. It also shows the way that (1) is not 100% on target (although good enough for a large fraction of mathematical work). But for many people, algebra is a rocky road to understanding.\n\nThe starting point for the algebraic understanding is the Taylor polynomial approximation for \\(e^{\\omega t}\\). Recall from Chapter 27 that \\[e^{\\omega t} = 1 + \\omega t + \\frac{1}{2!}\\omega^2 t^2 + \\frac{1}{3!}\\omega^3 t^3 + \\frac{1}{4!} \\omega^4 t^4 + \\frac{1}{5!} \\omega^5 t^5 + \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\] You may also recall the Taylor polynomial expansion of sine and cosine: \\[ \\cos(\\omega t) = 1 - \\frac{1}{2!} \\omega^2 t^2 + \\frac{1}{4!}\\omega^4 t^4 - \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\]\n\\[\\color{magenta}{\\sin(\\omega t) = \\omega t - \\frac{1}{3!}\\omega^3 t^3 + \\frac{1}{5!} \\omega^5 t^5 +  \\cdots}\\] You can see some association between \\(e^{wt}\\), \\(\\cos(\\omega t)\\), and \\(\\sin{\\omega t}\\) by looking at \\[\\cos(\\omega t) + \\color{magenta}{i \\sin(\\omega t)} = 1 + \\color{magenta}{i \\omega t} -\\frac{1}{2!} \\omega^2 t^2 - \\color{magenta}{i \\frac{1}{3!} \\omega^3 t^3} + \\frac{1}{4!}\\omega^4 t^4 + \\color{magenta}{i \\frac{1}{5!} \\omega^5 t^5} - \\frac{1}{6!}\\omega^6 t^6 + \\cdots\\] Now consider the Taylor polynomial for \\(e^{i\\omega t}\\). This will be the same as the Taylor polynomial for \\(e^{\\omega t}\\) but everywhere substituting \\(i \\omega\\) in place of the plain \\(\\omega\\). That is:\n\\[e^{i \\omega t} = 1 + \\color{magenta}{i\\omega t} + \\frac{1}{2!}i^2\\omega^2 t^2 + \\color{magenta}{\\frac{1}{3!}i^3\\omega^3 t^3} + \\frac{1}{4!} i^4\\omega^4 t^4 + \\color{magenta}{\\frac{1}{5!} i^5\\omega^5 t^5} + \\frac{1}{6!} i^6\\omega^6 t^6 + \\cdots\\] Since \\(i\\equiv \\sqrt{\\strut -1}\\), we have the following facts for the powers \\(i^n\\):\n\\[i^2 = -1\\ \\ \\ \\ \\ \\color{magenta}{i^3 = -i}\\ \\ \\ \\ \\ i^4 = 1\\ \\ \\ \\ \\ \\color{magenta}{i^5 = i}\\ \\ \\ \\ \\ i^6 = -1\\ \\ \\text{and so on}.\\] Substitute these facts about \\(i^n\\) into the Taylor polynomial for \\(e^{i\\omega t}\\):\n\\[e^{i \\omega t} = 1 + \\color{magenta}{i\\omega t} - \\frac{1}{2!}\\omega^2 t^2 - \\color{magenta}{i \\frac{1}{3!}\\omega^3 t^3} + \\frac{1}{4!} \\omega^4 t^4 + \\color{magenta}{i \\frac{1}{5!} \\omega^5 t^5} - \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\] which exactly matches the Taylor polynomial for \\(\\cos{\\omega t} + \\color{magenta}{i \\sin(\\omega t)}\\).\n\nThe arithmetic of complex numbers. (optional) A complex number is a number like \\(2 - 3i\\) which consists of two parts: the real-part \\(2\\) and the imaginary part \\(-3\\). When you multiply one complex number by another you get a complex number (although either the real or imaginary parts might happen to be zero.) For example: \\[(2 + 3i)^2 = (2+3i)(2+3i) = \\underbrace{4}_{2\\times 2} + \\underbrace{ \\ 6 i\\ }_{2 (3i)} +   \\underbrace{\\ 6 i\\ }_{(3i)2}\\ \\  \\underbrace{- 9}_{(3i)(3i)}\\  = -5 +12 i.\\] R knows the rules for arithmetic on complex numbers. Here’s a demonstration of the oscillations that result from raising a complex number to successive powers.\n\n\nlambda &lt;- 0.65 + 0.76i\nlambda^2\n## [1] -0.1551+0.988i\nlambda^3\n## [1] -0.851695+0.524324i\nlambda^4\n## [1] -0.952088-0.3064776i\nlambda^5\n## [1] -0.3859342-0.9227973i\nlambda^6\n## [1] 0.4504687-0.8931283i\nlambda^7\n## [1] 0.9715821-0.2381771i\nlambda^8\n## [1] 0.812543+0.5835873i\nlambda^9\n## [1] 0.0846266+0.9968644i\nlambda^10\n## [1] -0.7026097+0.7122781i\n\nNotice that the real part of the result oscillates between negative and positive. The imaginary part also oscillates, but delayed a bit from the real part. Just like sine and cosine.\nWe can get a clearer picture by plotting \\(e^{i\\omega t}\\) over the domain \\(0 &lt; t &lt; 10\\). As an example, in ?fig-complex-exponential-plot we will set \\(\\omega = 2\\). We need to be a little careful, since our plotting functions are not arranged to display complex numbers. But there is an easy workaround: plot the “real” and “imaginary” parts separately. The R operators Re() and Im() do this work.\n\nf &lt;- makeFun(exp(1i * omega * t) ~ t, omega = 2)\nslice_plot(Re(f(t)) ~ t, \n           bounds(t=0:10), color = \"magenta\") %&gt;%\n  slice_plot(Im(f(t)) ~ t, color=\"brown\")\n\n\n\n\nThe real and imaginary parts of \\(e^{i \\omega t}\\) plotted as a function of \\(t\\).\n\n\n\n\n\n\n47.5 Damping\nIt is common for there to be friction, called damping, in a spring mass system. To keep things very simple, we will consider that the friction is proportional to the velocity and, as in the cannonball example, in the direction opposite to velocity. That is: \\[\\partial_{tt} y = -r\\, \\partial_t y -b y\\ ,\\] where \\(b\\) would be the positive number \\(\\frac{s}{m}\\) and \\(r\\) is another positive number reflecting the magnitude of friction. (Think of \\(r\\) as standing for “resistance.”)\nAs always, this second-order differential equation can be written as a pair of first-order differential equations. One of the first-order differential equations will be \\[\\partial_t y = v\\ ,\\], which is just the definition of velocity \\(v\\). The other first-order equation will be \\[\\partial_t v = -r v  - b y\\ .\\] Both equations are linear.\nIn the previous chapter, we wrote such a pair of linear first-order differential equations in terms of a vector \\[\\vec{w(t)} = \\left[\\begin{array}{c}v(t)\\\\y(t)\\end{array}\\right]\\ .\\] In terms of the vector \\(\\vec{w(t)}\\) the dynamics can be written in vector/matrix form: \\[\\partial_t \\vec{w} = \\left[\\begin{array}{c}-r \\ \\ \\  -b\\ \\ \\\\1 \\ \\ \\ \\ \\ \\ \\ 0\\end{array}\\right]\\, \\vec{w}\\ .\\] This form suggests, at least to the avid reader of the previous chapter, that we look for a solution \\(y(t) = m_1\\, e^{\\lambda_1\\, t} + m_2\\, e^{\\lambda_2\\, t}\\) in terms of the eigenvectors and eigenvalues of the matrix \\(\\left[\\begin{array}{cc}r & b\\\\1 & 0\\end{array}\\right]\\).\nWe used the R function eigen() to compute the eigenvalues and eigenvectors of the matrix, given numerical values for \\(r\\) and \\(b\\). Let’s now try to find an algebraic formula for the eigenvalues. After all, it is the eigenvalues that determine the stability of the fixed point.\nAs an ansatz for the for the original second-order differential equation \\[\\partial_{tt} y = r\\, \\partial_t y + b y\\ ,\\] let’s use \\(y(t) = A e^{\\lambda t}\\), a simple exponential function. Plugging in the ansatz to the differential equation gives: \\[A \\lambda^2 e^{\\lambda t} = - r A \\lambda e^{\\lambda t} - b A e^{\\lambda t}\\ .\\] We can cancel out the common term \\(A e^{\\lambda t}\\) from all the terms in the equation, and bring all the terms to the left-hand side of the equation, leaving us with \\[\\lambda^2 + r \\lambda + b = 0\\ .\\] This is a quadratic polynomial in \\(\\lambda\\), so we can use the “quadratic formula” to find values for \\(\\lambda\\) that are consistent with the parameters \\(a\\) and \\(b\\). In applying the quadratic formula you have to remember that the standard statement is for the roots of \\(a x^2 + b x + c = 0\\) and make adjustment for the fact that our polynomial uses the parameter names differently: \\(\\lambda^2 + r \\lambda + b = 0\\).\n\\[\\lambda = \\frac{- r \\pm \\sqrt{\\strut r^2 - 4 b}}{2}\\ .\\] Recall that the parameter \\(r\\) describes the amount of friction or resistance in the system; it is a positive number. Similarly, the nature of springs is that \\(b\\) is a positive number. The relative values of \\(r\\) and \\(b\\) determine the motion of the system.\nSuppose the stiffness of the spring is much larger than the friction. Then \\(r^2 &lt; 4b\\). This being the case, the \\(\\sqrt{\\strut r^2 - 4 b}/2\\) will be an imaginary number. Altogether, the eigenvalues will be \\(\\lambda = -\\frac{r}{2} \\pm {i \\omega}\\). The solution will be \\[y = m_1 e^{\\lambda_1 t} + m_2 e^{\\lambda_2 t} \\\\\n= m_1 e^{-\\frac{r}{2}t + i \\omega t} + m_2 e^{\\frac{r}{2} - i\\omega t} \\\\\n= m_1 e^{-r t/2} e^{i\\omega t} + m_2 e^{-r t/2} e^{-i \\omega t} \\\\\n= e^{-r t/2}\\underbrace{\\left[m_1 e^{i \\omega t} + m2 e^{i\\omega t}\\right]}_{\\text{sinusoid}(\\omega t)}\\] Result: an exponentially decaying sinusoid.\nTo graph this function, we need to choose appropriate numerical values for \\(r\\) and \\(b\\). Let’s set \\(r=1\\). Since \\(r^2 &lt; 4b\\), we must have \\(\\frac{1}{4} &lt; b\\): we will choose \\(b = 6\\) which meets this criterion. Figure 47.4 shows the solution to the differential equation:\n\ntraj &lt;- integrateODE(dv~ -r*v - b*y, dy ~ v, \n                     v=10, y=0, r=1, b=6, \n                     bounds(t=0:20))\n## Solution containing functions v(t), y(t).\ntraj_plot(y(t) ~ t, traj)\n\n\n\n\n\n\n\nFigure 47.4: An exponentially decaying sinusoid arising from \\(r = 1\\) and \\(b = 6\\).\n\n\n\n\n\nThis is the situation with a swinging door. You shove it to swing open, after which it oscillates with a decreasing amplitude.\nIn contrast, suppose the spring is weak compared to the damping such that \\(4b &lt; r^2\\). Now \\(\\sqrt{\\strut r^2 - 4b}\\) is a positive number, not imaginary. What’s more, since \\(b\\) is positive, \\(\\sqrt{\\strut r^2 - 4 b} &lt; r\\). This means that both eigenvalues are negative. We will illustrate the situation with \\(r=1, b=0.2\\):\n\n\n\n\ntraj2 &lt;- integrateODE(dv~ -r*v - b*y, dy ~ v, \n                      v=10, y=0, r=1, b=0.1, \n                      bounds(t=0:20))\n## Solution containing functions v(t), y(t).\ntraj_plot(y(t) ~ t, traj2) %&gt;%\n  gf_lims(y = c(0, NA))\n\n\n\n\n\n\n\n\n\n\nFigure 47.5: A heavily damped spring-mass system with \\(r = 1\\) and \\(b = 0.1\\).\n\n\n\nThe situation in Figure 47.5 is the sort of behavior one expects when giving a shove to an exit door in theater or stadium. The shove causes the door to swing open, after which it slowly returns to the closed position. That gives plenty of time for the people following you to get to the door before it closes.\nFinally, consider the case where \\(r^2 - 4 b = 0\\), a balance between resistance and springiness. In this case, both eigenvalues are \\(\\lambda = -r/2\\).\n\n\n\n\ntraj3 &lt;- integrateODE(dv~ -r*v - b*y, dy ~ v, v=10, y=0, r=1, b=0.25, bounds(t=0:20))\n## Solution containing functions v(t), y(t).\ntraj_plot(y(t) ~ t, traj3) %&gt;%\n  gf_lims(y = c(0, NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 47.6: A critically damped oscillation with \\(r=1\\), \\(b=0.25\\).\n\n\n\nThis is a situation called critically damped. The door swings open, then closes as fast as it can without any oscillation.\n\nApplication area 47.1  \n\n\n\n\n\n\n\nApplication area 47.1 Stability and eigenvalues\n\n\n\nConsider the second-order linear differential equation \\[\\partial_{tt}\\ y + 2\\, \\partial_t\\, y - 3\\, y = 0\\ .\\] Is the equilibrium point for this system stable?\nFor this system, \\(a=2\\) and \\(b = - 3\\), so the eigenvalues are \\[\\lambda = \\left(-2 \\pm \\sqrt{\\strut 4 + 12}\\right)/2 = 1 \\pm \\sqrt{\\strut 16}/2 = -1 \\pm 2\\] In other words, \\(\\lambda_1 = -3\\) and \\(\\lambda_2 = +1\\). This indicates that the system is a saddle: unstable in one direction and stable in the other.\nTo confirm our work, let’s use eigen() to find the eigenvalues of the matrix \\(\\left[\\begin{array}{cc}2 & 3\\\\1 & 0\\end{array}\\right]\\):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAlthough R is doing all the calculations for us, it is possible to write the directions of the eigenvectors only in terms of the eigenvectors: \\[\\vec{\\Lambda_1} = \\left[\\begin{array}{c}\\lambda_1\\\\1\\end{array}\\right]\\ \\ \\text{and}\\ \\ \\vec{\\Lambda_2} = \\left[\\begin{array}{c}\\lambda_2\\\\1\\end{array}\\right]\\]\nFor the system with \\(\\lambda_1 = 3\\) and \\(\\lambda_2 = -1\\), you can confirm that the eigenvectors calculated with this formula point in the same directions as the eigenvectors reported by eigen().\n\n\nLet’s return to the car-following control system introduced in Chapter 46. Recall that \\(x\\) was defined to be the distance between two cars and \\(x_0\\) the distance to be maintained. In terms of \\(y = x - x_0\\) the system was \\[\\partial_{tt} y = - b y\\ .\\] You can see that this system has no damping; \\(y(t)\\) will be a sinusoidal oscillation. The ride will be more pleasant, however, if the oscillations can be damped out. To accomplish this, we should add a new term to the second-order differential equation, a damping term to give \\[\\partial_{tt} y = -a\\, \\partial_t y- b\\, y\\ .\\] We should set the parameters \\(a\\) and \\(b\\) to make the real part of the eigenvalues negative. Only then will we have designed a workable control system.\n\nApplication area 47.2 —Following the car in front using derivatives.\n\n\n\n\n\n\n\nApplication area 47.2 Driving a car\n\n\n\nFor a human driver, following a car at a steady distance requires careful attention but in practice is not too difficult a task. Could it be the case that drivers have an intuitive understanding of the need for damping? Perhaps complex eigenvalues ought to be a standard topic in driving schools? That might be, but there is a more down-to-earth explanation of how humans handle the car-following task.\nThe quantity \\(\\partial_{tt} y\\) is the acceleration, and the control pedal that leads to positive acceleration is called the “accelerator.” But the pedal does not set acceleration. In reality, the pedal sets velocity as well as acceleration. A simple model is \\(\\text{pedal} = r \\partial_t y + s \\partial_{tt} y\\), where \\(y\\) is the velocity of the car and \\(r\\) and \\(s\\) are positive parameters.\nTo understand this model of the pedal, think what happens when you press the accelerator and hold it. The car accelerates, but only up to the point where a steady state velocity is reached. Or, consider what happens if you partially release the pedal. The car slows down until it reaches a new, slower, steady-state velocity.\nWith a human driver, the control system is not \\(\\partial_{tt} y = - b y\\). Instead, the control system is \\[\\text{pedal} - p_0 =  - b y\\ .\\] For steady-state driving at the desired velocity \\(\\partial_t y\\) we press the pedal by an amount \\(p_0\\). To perform the car-following task, we push down or lighten up on the pedal, depending on whether we are farther or closer to the car ahead than our desired distance.\nCombining the models for how \\(\\text{pedal}\\) is controlled and how \\(\\text{pedal}\\) relates to velocity and acceleration, we have \\[r \\partial_t y + s \\partial_{tt} y  - p_0 = -b y\\] or, re-arranging terms \\[ \\partial_{tt} y = \\underbrace{- \\frac{r}{s} \\partial_t y}_{\\text{damping}} - \\frac{b}{s} y + p_0\\ .\\] The nature of the gas pedal itself leads to a damping term in the dynamics, without our having to think about it consciously.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Force-balance equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-second-order.html#the-harmonic-oscillator",
    "href": "Dynamics/B6-second-order.html#the-harmonic-oscillator",
    "title": "47  Force-balance equations",
    "section": "",
    "text": "Consider the motion of a weight attached to a spring, as in ?fig-spring-mass. We will denote the vertical position of the mass by \\(y(t)\\). Such a spring-mass system has a fixed point where the spring is stretched just enough to cancel out gravity and the velocity is zero. We will measure \\(y\\) relative to this fixed point.\n\n\n\n\n\n\nFigure 47.3: A spring-mass system in motion. Source: Svjo CC BY-SA via Wikimedia Commons\n\n\n\nAccording to Hooke’s Law, a stretched or compressed spring exerts a force that is proportional to the amount of extension or compression. With our measuring \\(y\\) relative to the fixed point, the Hooke’s Law force will be \\[m\\, \\partial_{tt} y = - s\\, y\\ ,\\] where \\(m\\) is the amount of mass and \\(s\\) is the stiffness of the spring. This force-balance equation corresponds to the second-order differential equation \\[\\partial_{tt} y = - \\frac{s}{m} y\\ .\\]\nYou can see that the motion is oscillatory, which suggests that the solution to the differential equation will be of the form \\(y(t) = A \\sin(\\omega t)\\). Taking this as an ansatz leads to finding a value of \\(\\omega\\), which is called the angular frequency of the oscillation. (In terms of the period of oscillation \\(P\\), the angular frequency is \\(\\omega = 2 \\pi/P\\).)\nTo find \\(\\omega\\), plug in the ansatz to the differential equation:\n\\[\\partial_{tt} A \\sin(\\omega t) = - \\frac{s}{m}\\, A \\sin(\\omega t)\\] Differentiating \\(\\sin(\\omega t)\\) once let’s us re-write the left-hand side of the equation in terms of a first derivative\n\\[\\partial_{t} A \\omega\\, \\cos(\\omega t) = - \\frac{s}{m}\\, A \\sin(\\omega t)\\] Differentiating again gives \\[- \\omega^2 A\\sin(\\omega\\, t) = - \\frac{s}{m}\\, A\\sin(\\omega t)\\ .\\] Simplifying this by cancelling out the \\(A \\sin(\\omega t)\\) term gives \\(\\omega^2 = \\frac{s}{m}\\), where \\(\\omega\\) is the angular frequency of the oscillation.\n\n\n\n\n\n\nTip\n\n\n\nInstead of using \\(A \\sin(\\omega t)\\) as the ansatz we could have used \\(A \\sin(\\omega t) + B \\cos(\\omega t)\\). Working through this ansatz would produce the same result, that \\(\\omega^2 = \\frac{s}{m}\\). So the solution to the spring-mass system will be, in general, a linear combination of the sine and the cosine functions with angular frequency \\(\\omega\\).",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Force-balance equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-second-order.html#exponential-or-sinusoid",
    "href": "Dynamics/B6-second-order.html#exponential-or-sinusoid",
    "title": "47  Force-balance equations",
    "section": "47.3 Exponential or sinusoid?",
    "text": "47.3 Exponential or sinusoid?\nIn Chapter 46, we established that solutions to second-order linear differential equations have the form \\(m_1 e^{\\lambda_1 t} + m_2 e^{\\lambda_2 t}\\). Yet in the previous section, we saw one linear second-order differential equation, \\(\\partial_{tt} y = - \\omega^2 y\\) where the solution is a linear combination of a sine and a cosine function: \\(y(t) = A \\sin(\\omega t) + B \\cos(\\omega t)\\) with \\(\\omega = \\sqrt{\\frac{s}{m}}\\).\nHow is it possible for the solution to be both in the form of a linear combination of exponentials and a linear combination of sine and cosine? Sinusoids oscillate up and down and up and down, whereas exponentials are monotonic.\nTo find out what might be the relationship between an exponential and a sinusoid, let’s plug an exponential ansatz \\(y(t) = A e^{\\lambda t}\\) into the spring-mass system \\(\\partial_{tt} y = -\\omega^2 y\\).\n\\[\\partial_{tt} A e^{\\lambda t} = \\lambda^2 A e^{\\lambda t} = -\\omega^2 A e^{\\lambda t}\\ .\\] As before, we will cancel out the common term \\(A e^{\\lambda t}\\) to get a simple relationship: \\[\\lambda^2 = -\\omega^2\\ \\ \\ \\implies\\ \\ \\ \\lambda = \\pm \\sqrt{\\strut-1}\\  \\omega \\ .\\] Generally, the symbol \\(i\\) is used to stand for \\(\\sqrt{\\strut -1}\\), so our eigenvalues can be written \\(\\lambda = \\pm i \\omega\\). The solution to the spring-mass system, according to this analysis, is: \\[y(t) = m_1 e^{i\\omega t} + m_2 e^{-i \\omega t}\\]\nIn other words, \\(e^{i \\omega t}\\)—notice the \\(i\\) in the argument to the exponential—is a sinusoid with angular frequency \\(\\omega\\).",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Force-balance equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-second-order.html#exponentials-with-imaginary-inputs",
    "href": "Dynamics/B6-second-order.html#exponentials-with-imaginary-inputs",
    "title": "47  Force-balance equations",
    "section": "47.4 Exponentials with “imaginary” inputs",
    "text": "47.4 Exponentials with “imaginary” inputs\nThe “imaginary” in the section title is used in its mathematical sense. In interpreting the word “imaginary,” you should keep in mind a long history in mathematics of assigning insulting names to mathematical objects that, at the time they were first introduced. That is why some numbers are vilified as “negative,” and some as “irrational.” The insult is even more dire for numbers like \\(i\\), which are called the “imaginary” numbers. Regrettably, the word “imaginary” leads many people to shy away from them, just as many people avoid genres such as fantasy fiction. That imaginary numbers are introduced as kind of freakish—is there a numerical value for \\(\\sqrt{\\strut -1}\\)?—and rarely touched until advanced calculus, means that students are unused to them.\nYou will only get comfortable with “imaginary” numbers when you start to work with them extensively, as happens in physics and engineering courses. Our goal here is merely to increase your awareness of imaginary numbers and some of the ways they are used in the sciences. To that end, we offer three different approaches to understanding the function \\(e^{i\\omega t}\\).\n\nBasic, pragmatic understanding. This is the level of understanding that you must have to make sense of the rest of this chapter and ?sec-forcing. Here it is: \\[e^{i\\omega t}\\ \\text{is simply a shorthand for}\\ \\cos(\\omega t).\\] So whenever you see \\(e^{i \\omega t}\\), think of \\(\\cos(\\omega t)\\).\nAlgebraic understanding via Taylor Polynomials. (optional) This level of understanding can give you confidence that the basic, pragmatic understanding in (1) has honest roots. It also shows the way that (1) is not 100% on target (although good enough for a large fraction of mathematical work). But for many people, algebra is a rocky road to understanding.\n\nThe starting point for the algebraic understanding is the Taylor polynomial approximation for \\(e^{\\omega t}\\). Recall from Chapter 27 that \\[e^{\\omega t} = 1 + \\omega t + \\frac{1}{2!}\\omega^2 t^2 + \\frac{1}{3!}\\omega^3 t^3 + \\frac{1}{4!} \\omega^4 t^4 + \\frac{1}{5!} \\omega^5 t^5 + \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\] You may also recall the Taylor polynomial expansion of sine and cosine: \\[ \\cos(\\omega t) = 1 - \\frac{1}{2!} \\omega^2 t^2 + \\frac{1}{4!}\\omega^4 t^4 - \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\]\n\\[\\color{magenta}{\\sin(\\omega t) = \\omega t - \\frac{1}{3!}\\omega^3 t^3 + \\frac{1}{5!} \\omega^5 t^5 +  \\cdots}\\] You can see some association between \\(e^{wt}\\), \\(\\cos(\\omega t)\\), and \\(\\sin{\\omega t}\\) by looking at \\[\\cos(\\omega t) + \\color{magenta}{i \\sin(\\omega t)} = 1 + \\color{magenta}{i \\omega t} -\\frac{1}{2!} \\omega^2 t^2 - \\color{magenta}{i \\frac{1}{3!} \\omega^3 t^3} + \\frac{1}{4!}\\omega^4 t^4 + \\color{magenta}{i \\frac{1}{5!} \\omega^5 t^5} - \\frac{1}{6!}\\omega^6 t^6 + \\cdots\\] Now consider the Taylor polynomial for \\(e^{i\\omega t}\\). This will be the same as the Taylor polynomial for \\(e^{\\omega t}\\) but everywhere substituting \\(i \\omega\\) in place of the plain \\(\\omega\\). That is:\n\\[e^{i \\omega t} = 1 + \\color{magenta}{i\\omega t} + \\frac{1}{2!}i^2\\omega^2 t^2 + \\color{magenta}{\\frac{1}{3!}i^3\\omega^3 t^3} + \\frac{1}{4!} i^4\\omega^4 t^4 + \\color{magenta}{\\frac{1}{5!} i^5\\omega^5 t^5} + \\frac{1}{6!} i^6\\omega^6 t^6 + \\cdots\\] Since \\(i\\equiv \\sqrt{\\strut -1}\\), we have the following facts for the powers \\(i^n\\):\n\\[i^2 = -1\\ \\ \\ \\ \\ \\color{magenta}{i^3 = -i}\\ \\ \\ \\ \\ i^4 = 1\\ \\ \\ \\ \\ \\color{magenta}{i^5 = i}\\ \\ \\ \\ \\ i^6 = -1\\ \\ \\text{and so on}.\\] Substitute these facts about \\(i^n\\) into the Taylor polynomial for \\(e^{i\\omega t}\\):\n\\[e^{i \\omega t} = 1 + \\color{magenta}{i\\omega t} - \\frac{1}{2!}\\omega^2 t^2 - \\color{magenta}{i \\frac{1}{3!}\\omega^3 t^3} + \\frac{1}{4!} \\omega^4 t^4 + \\color{magenta}{i \\frac{1}{5!} \\omega^5 t^5} - \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\] which exactly matches the Taylor polynomial for \\(\\cos{\\omega t} + \\color{magenta}{i \\sin(\\omega t)}\\).\n\nThe arithmetic of complex numbers. (optional) A complex number is a number like \\(2 - 3i\\) which consists of two parts: the real-part \\(2\\) and the imaginary part \\(-3\\). When you multiply one complex number by another you get a complex number (although either the real or imaginary parts might happen to be zero.) For example: \\[(2 + 3i)^2 = (2+3i)(2+3i) = \\underbrace{4}_{2\\times 2} + \\underbrace{ \\ 6 i\\ }_{2 (3i)} +   \\underbrace{\\ 6 i\\ }_{(3i)2}\\ \\  \\underbrace{- 9}_{(3i)(3i)}\\  = -5 +12 i.\\] R knows the rules for arithmetic on complex numbers. Here’s a demonstration of the oscillations that result from raising a complex number to successive powers.\n\n\nlambda &lt;- 0.65 + 0.76i\nlambda^2\n## [1] -0.1551+0.988i\nlambda^3\n## [1] -0.851695+0.524324i\nlambda^4\n## [1] -0.952088-0.3064776i\nlambda^5\n## [1] -0.3859342-0.9227973i\nlambda^6\n## [1] 0.4504687-0.8931283i\nlambda^7\n## [1] 0.9715821-0.2381771i\nlambda^8\n## [1] 0.812543+0.5835873i\nlambda^9\n## [1] 0.0846266+0.9968644i\nlambda^10\n## [1] -0.7026097+0.7122781i\n\nNotice that the real part of the result oscillates between negative and positive. The imaginary part also oscillates, but delayed a bit from the real part. Just like sine and cosine.\nWe can get a clearer picture by plotting \\(e^{i\\omega t}\\) over the domain \\(0 &lt; t &lt; 10\\). As an example, in ?fig-complex-exponential-plot we will set \\(\\omega = 2\\). We need to be a little careful, since our plotting functions are not arranged to display complex numbers. But there is an easy workaround: plot the “real” and “imaginary” parts separately. The R operators Re() and Im() do this work.\n\nf &lt;- makeFun(exp(1i * omega * t) ~ t, omega = 2)\nslice_plot(Re(f(t)) ~ t, \n           bounds(t=0:10), color = \"magenta\") %&gt;%\n  slice_plot(Im(f(t)) ~ t, color=\"brown\")\n\n\n\n\nThe real and imaginary parts of \\(e^{i \\omega t}\\) plotted as a function of \\(t\\).",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Force-balance equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-second-order.html#damping",
    "href": "Dynamics/B6-second-order.html#damping",
    "title": "47  Force-balance equations",
    "section": "47.5 Damping",
    "text": "47.5 Damping\nIt is common for there to be friction, called damping, in a spring mass system. To keep things very simple, we will consider that the friction is proportional to the velocity and, as in the cannonball example, in the direction opposite to velocity. That is: \\[\\partial_{tt} y = -r\\, \\partial_t y -b y\\ ,\\] where \\(b\\) would be the positive number \\(\\frac{s}{m}\\) and \\(r\\) is another positive number reflecting the magnitude of friction. (Think of \\(r\\) as standing for “resistance.”)\nAs always, this second-order differential equation can be written as a pair of first-order differential equations. One of the first-order differential equations will be \\[\\partial_t y = v\\ ,\\], which is just the definition of velocity \\(v\\). The other first-order equation will be \\[\\partial_t v = -r v  - b y\\ .\\] Both equations are linear.\nIn the previous chapter, we wrote such a pair of linear first-order differential equations in terms of a vector \\[\\vec{w(t)} = \\left[\\begin{array}{c}v(t)\\\\y(t)\\end{array}\\right]\\ .\\] In terms of the vector \\(\\vec{w(t)}\\) the dynamics can be written in vector/matrix form: \\[\\partial_t \\vec{w} = \\left[\\begin{array}{c}-r \\ \\ \\  -b\\ \\ \\\\1 \\ \\ \\ \\ \\ \\ \\ 0\\end{array}\\right]\\, \\vec{w}\\ .\\] This form suggests, at least to the avid reader of the previous chapter, that we look for a solution \\(y(t) = m_1\\, e^{\\lambda_1\\, t} + m_2\\, e^{\\lambda_2\\, t}\\) in terms of the eigenvectors and eigenvalues of the matrix \\(\\left[\\begin{array}{cc}r & b\\\\1 & 0\\end{array}\\right]\\).\nWe used the R function eigen() to compute the eigenvalues and eigenvectors of the matrix, given numerical values for \\(r\\) and \\(b\\). Let’s now try to find an algebraic formula for the eigenvalues. After all, it is the eigenvalues that determine the stability of the fixed point.\nAs an ansatz for the for the original second-order differential equation \\[\\partial_{tt} y = r\\, \\partial_t y + b y\\ ,\\] let’s use \\(y(t) = A e^{\\lambda t}\\), a simple exponential function. Plugging in the ansatz to the differential equation gives: \\[A \\lambda^2 e^{\\lambda t} = - r A \\lambda e^{\\lambda t} - b A e^{\\lambda t}\\ .\\] We can cancel out the common term \\(A e^{\\lambda t}\\) from all the terms in the equation, and bring all the terms to the left-hand side of the equation, leaving us with \\[\\lambda^2 + r \\lambda + b = 0\\ .\\] This is a quadratic polynomial in \\(\\lambda\\), so we can use the “quadratic formula” to find values for \\(\\lambda\\) that are consistent with the parameters \\(a\\) and \\(b\\). In applying the quadratic formula you have to remember that the standard statement is for the roots of \\(a x^2 + b x + c = 0\\) and make adjustment for the fact that our polynomial uses the parameter names differently: \\(\\lambda^2 + r \\lambda + b = 0\\).\n\\[\\lambda = \\frac{- r \\pm \\sqrt{\\strut r^2 - 4 b}}{2}\\ .\\] Recall that the parameter \\(r\\) describes the amount of friction or resistance in the system; it is a positive number. Similarly, the nature of springs is that \\(b\\) is a positive number. The relative values of \\(r\\) and \\(b\\) determine the motion of the system.\nSuppose the stiffness of the spring is much larger than the friction. Then \\(r^2 &lt; 4b\\). This being the case, the \\(\\sqrt{\\strut r^2 - 4 b}/2\\) will be an imaginary number. Altogether, the eigenvalues will be \\(\\lambda = -\\frac{r}{2} \\pm {i \\omega}\\). The solution will be \\[y = m_1 e^{\\lambda_1 t} + m_2 e^{\\lambda_2 t} \\\\\n= m_1 e^{-\\frac{r}{2}t + i \\omega t} + m_2 e^{\\frac{r}{2} - i\\omega t} \\\\\n= m_1 e^{-r t/2} e^{i\\omega t} + m_2 e^{-r t/2} e^{-i \\omega t} \\\\\n= e^{-r t/2}\\underbrace{\\left[m_1 e^{i \\omega t} + m2 e^{i\\omega t}\\right]}_{\\text{sinusoid}(\\omega t)}\\] Result: an exponentially decaying sinusoid.\nTo graph this function, we need to choose appropriate numerical values for \\(r\\) and \\(b\\). Let’s set \\(r=1\\). Since \\(r^2 &lt; 4b\\), we must have \\(\\frac{1}{4} &lt; b\\): we will choose \\(b = 6\\) which meets this criterion. Figure 47.4 shows the solution to the differential equation:\n\ntraj &lt;- integrateODE(dv~ -r*v - b*y, dy ~ v, \n                     v=10, y=0, r=1, b=6, \n                     bounds(t=0:20))\n## Solution containing functions v(t), y(t).\ntraj_plot(y(t) ~ t, traj)\n\n\n\n\n\n\n\nFigure 47.4: An exponentially decaying sinusoid arising from \\(r = 1\\) and \\(b = 6\\).\n\n\n\n\n\nThis is the situation with a swinging door. You shove it to swing open, after which it oscillates with a decreasing amplitude.\nIn contrast, suppose the spring is weak compared to the damping such that \\(4b &lt; r^2\\). Now \\(\\sqrt{\\strut r^2 - 4b}\\) is a positive number, not imaginary. What’s more, since \\(b\\) is positive, \\(\\sqrt{\\strut r^2 - 4 b} &lt; r\\). This means that both eigenvalues are negative. We will illustrate the situation with \\(r=1, b=0.2\\):\n\n\n\n\ntraj2 &lt;- integrateODE(dv~ -r*v - b*y, dy ~ v, \n                      v=10, y=0, r=1, b=0.1, \n                      bounds(t=0:20))\n## Solution containing functions v(t), y(t).\ntraj_plot(y(t) ~ t, traj2) %&gt;%\n  gf_lims(y = c(0, NA))\n\n\n\n\n\n\n\n\n\n\nFigure 47.5: A heavily damped spring-mass system with \\(r = 1\\) and \\(b = 0.1\\).\n\n\n\nThe situation in Figure 47.5 is the sort of behavior one expects when giving a shove to an exit door in theater or stadium. The shove causes the door to swing open, after which it slowly returns to the closed position. That gives plenty of time for the people following you to get to the door before it closes.\nFinally, consider the case where \\(r^2 - 4 b = 0\\), a balance between resistance and springiness. In this case, both eigenvalues are \\(\\lambda = -r/2\\).\n\n\n\n\ntraj3 &lt;- integrateODE(dv~ -r*v - b*y, dy ~ v, v=10, y=0, r=1, b=0.25, bounds(t=0:20))\n## Solution containing functions v(t), y(t).\ntraj_plot(y(t) ~ t, traj3) %&gt;%\n  gf_lims(y = c(0, NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 47.6: A critically damped oscillation with \\(r=1\\), \\(b=0.25\\).\n\n\n\nThis is a situation called critically damped. The door swings open, then closes as fast as it can without any oscillation.\n\nApplication area 47.1  \n\n\n\n\n\n\n\nApplication area 47.1 Stability and eigenvalues\n\n\n\nConsider the second-order linear differential equation \\[\\partial_{tt}\\ y + 2\\, \\partial_t\\, y - 3\\, y = 0\\ .\\] Is the equilibrium point for this system stable?\nFor this system, \\(a=2\\) and \\(b = - 3\\), so the eigenvalues are \\[\\lambda = \\left(-2 \\pm \\sqrt{\\strut 4 + 12}\\right)/2 = 1 \\pm \\sqrt{\\strut 16}/2 = -1 \\pm 2\\] In other words, \\(\\lambda_1 = -3\\) and \\(\\lambda_2 = +1\\). This indicates that the system is a saddle: unstable in one direction and stable in the other.\nTo confirm our work, let’s use eigen() to find the eigenvalues of the matrix \\(\\left[\\begin{array}{cc}2 & 3\\\\1 & 0\\end{array}\\right]\\):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAlthough R is doing all the calculations for us, it is possible to write the directions of the eigenvectors only in terms of the eigenvectors: \\[\\vec{\\Lambda_1} = \\left[\\begin{array}{c}\\lambda_1\\\\1\\end{array}\\right]\\ \\ \\text{and}\\ \\ \\vec{\\Lambda_2} = \\left[\\begin{array}{c}\\lambda_2\\\\1\\end{array}\\right]\\]\nFor the system with \\(\\lambda_1 = 3\\) and \\(\\lambda_2 = -1\\), you can confirm that the eigenvectors calculated with this formula point in the same directions as the eigenvectors reported by eigen().\n\n\nLet’s return to the car-following control system introduced in Chapter 46. Recall that \\(x\\) was defined to be the distance between two cars and \\(x_0\\) the distance to be maintained. In terms of \\(y = x - x_0\\) the system was \\[\\partial_{tt} y = - b y\\ .\\] You can see that this system has no damping; \\(y(t)\\) will be a sinusoidal oscillation. The ride will be more pleasant, however, if the oscillations can be damped out. To accomplish this, we should add a new term to the second-order differential equation, a damping term to give \\[\\partial_{tt} y = -a\\, \\partial_t y- b\\, y\\ .\\] We should set the parameters \\(a\\) and \\(b\\) to make the real part of the eigenvalues negative. Only then will we have designed a workable control system.\n\nApplication area 47.2 —Following the car in front using derivatives.\n\n\n\n\n\n\n\nApplication area 47.2 Driving a car\n\n\n\nFor a human driver, following a car at a steady distance requires careful attention but in practice is not too difficult a task. Could it be the case that drivers have an intuitive understanding of the need for damping? Perhaps complex eigenvalues ought to be a standard topic in driving schools? That might be, but there is a more down-to-earth explanation of how humans handle the car-following task.\nThe quantity \\(\\partial_{tt} y\\) is the acceleration, and the control pedal that leads to positive acceleration is called the “accelerator.” But the pedal does not set acceleration. In reality, the pedal sets velocity as well as acceleration. A simple model is \\(\\text{pedal} = r \\partial_t y + s \\partial_{tt} y\\), where \\(y\\) is the velocity of the car and \\(r\\) and \\(s\\) are positive parameters.\nTo understand this model of the pedal, think what happens when you press the accelerator and hold it. The car accelerates, but only up to the point where a steady state velocity is reached. Or, consider what happens if you partially release the pedal. The car slows down until it reaches a new, slower, steady-state velocity.\nWith a human driver, the control system is not \\(\\partial_{tt} y = - b y\\). Instead, the control system is \\[\\text{pedal} - p_0 =  - b y\\ .\\] For steady-state driving at the desired velocity \\(\\partial_t y\\) we press the pedal by an amount \\(p_0\\). To perform the car-following task, we push down or lighten up on the pedal, depending on whether we are farther or closer to the car ahead than our desired distance.\nCombining the models for how \\(\\text{pedal}\\) is controlled and how \\(\\text{pedal}\\) relates to velocity and acceleration, we have \\[r \\partial_t y + s \\partial_{tt} y  - p_0 = -b y\\] or, re-arranging terms \\[ \\partial_{tt} y = \\underbrace{- \\frac{r}{s} \\partial_t y}_{\\text{damping}} - \\frac{b}{s} y + p_0\\ .\\] The nature of the gas pedal itself leads to a damping term in the dynamics, without our having to think about it consciously.",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Force-balance equations</span>"
    ]
  },
  {
    "objectID": "Dynamics/B6-second-order.html#footnotes",
    "href": "Dynamics/B6-second-order.html#footnotes",
    "title": "47  Force-balance equations",
    "section": "",
    "text": "it is remarkable that the same \\(m\\) appears both in Newton’s Second Law and in the description of the force of gravity. There was no mathematical theory for this until Albert Einstein (1879-1955)↩︎\nAnother bit of physics which is still not included in the differential equation is that it will only hold until the object hits the ground, at which point the force of gravity will be counter-acted by the force of the ground on the object.↩︎",
    "crumbs": [
      "BLOCK V. Dynamics",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Force-balance equations</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-operations.html",
    "href": "Manifestations/B4-operations.html",
    "title": "48  Operations on functions",
    "section": "",
    "text": "48.1 Task: Solve\nStarting materials:\nIdeal result from the algorithm: A new candidate \\(\\color{magenta}{x^\\star}\\) such that \\(f(\\color{magenta}{x^\\star}) = v\\) or, equivalently, that \\[\\left\\|\\strut f(\\color{magenta}{x^\\star}) - v \\right\\| = 0\\ .\\]\nRealistic result from the algorithm: The new candidate \\(\\color{magenta}{x^\\star}\\) will be better than \\(x_0\\), that is, \\[ \\left\\|\\strut f(\\color{magenta}{x^\\star}) - v\\right\\|\\ \\  {\\mathbf &lt;}\\ \\  \\left\\|\\strut f(\\color{brown}{x_0}) - v\\right\\|\\] One algorithm for the operation involves approximating the function \\(f(x)\\) with a straight-line function \\(\\widehat{f}(x) = a x + b\\). For straight-line functions, the solution \\(x^\\star\\) can be found by simple arithmetic:\n\\[a x^\\star + b - v = 0 \\ \\ \\implies \\ \\ \\ x^\\star = \\frac{b-v}{a}\\] You saw in Block 2 how to construct the straight-line approximation to a function \\(f()\\) in a region of interest near \\(x_0\\) by evaluating the function and its derivative at \\(x_0\\). In other words, \\[\\widehat{f}(x) \\equiv f(x_0) + \\partial_x f(x_0) \\left[\\strut x - x_0 \\right]\\ .\\]\nBecause \\(\\widehat{f}(x)\\) is a straight-line function, it is easy to find an input \\(x_1\\) that will generate exactly the desired output value \\(v\\). In other words, to solve \\(\\widehat{f}(x_1) = v\\) for \\(x_1\\).\n\\[\\begin{equation}\nx_1 = x_0 + \\frac{v-f(x_0)}{\\partial_x f(x_0)}\n\\end{equation}\\]\nAlthough \\(x_1\\) is an exact solution to the approximate problem, all we can hope is that for nonlinear \\(f(x)\\), \\(x_1\\) will be an approximate solution to the actual problem. In particular, we want \\(x_1\\) to be a better guess than \\(x_0\\): \\[\\|f(x_1) - v\\| \\underbrace{\\ \\ &lt;\\ \\ }_\\text{We hope!} \\|f(x_0) - v\\|\\]\nThis (hopefully) improved solution \\(x_1\\) can become the starting guess for a new round of improvement based on the straight-line approximation to \\(f(x)\\) around \\(x_1\\). The refinement of \\(x_1\\) will be calculated as \\[\\begin{equation}\nx_2 = x_1 + \\frac{v-f(x_1)}{\\partial_x f(x_1)}\n\\end{equation}\\]\nEach round of improvement—that is, “iteration”—calculates a new value \\(x_{i+1}\\) from the previous \\(x_i\\). The improvement can be encapsulated as a function, which we will call solve_step(): \\[\\text{solve-step}(z) \\equiv z + \\frac{v-f(z)}{\\partial_x f(z)}\\ .\\]\nThis particular form of solve_step() is called a Newton step. The idea is to take successive steps, each refining the previous approximation, to get closer and closer (hopefully!) to the actual answer \\(x^\\star\\):\n\\[x_1 = \\text{solve-step}(x_0)\\\\\nx_2 = \\text{solve-step}(x_1)\\\\\nx_3 = \\text{solve-step}(x_2)\\\\\n\\vdots\\\\\nx_{i+1} = \\text{solve-step}(x_{i})\\\\\\ \\\\\n\\text{until eventually}\\ \\|f(x_{i+1}) - v\\|\\ \\text{is practically zero.}\\]\nNewton’s method involves creating a custom solve_step() function for each new problem. The process is simple enough that we can create such functions automatically:\nmake_solve_step_fun &lt;- function(tilde, v) {\n  f &lt;- makeFun(tilde)\n  df &lt;- D(tilde)\n  custom_fun &lt;- function(z) {z + (v-f(z))/df(z)}\n\n  return(custom_fun)\n}\nLet’s test it out with this function:\nf &lt;- makeFun(x^2 - x ~ x)\nConstruct the take-a-step function:\ntake_step &lt;- make_solve_step_fun(f(x) ~ x, v=4)\nTake three steps starting at \\(x_0 = 3\\):\nx0 &lt;- 3\nx1 &lt;- take_step(x0)\nx2 &lt;- take_step(x1)\nx3 &lt;- take_step(x2)\nf(x3)\n## [1] 4\nThe Newton-step process is not guaranteed to work. By exploring cases where it fails, computational mathematicians1 have developed strategies for increasing the range of situations for which it works. Some of these strategies are incorporated in the R/mosaic function Zeros().",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Operations on functions</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-operations.html#task-solve",
    "href": "Manifestations/B4-operations.html#task-solve",
    "title": "48  Operations on functions",
    "section": "48.2 Task: Argmax",
    "text": "a function \\(f(x)\\),\n\na known output value \\(v\\), and\n\na candidate for a suitable input value \\(\\color{brown}{x_0}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 48.1: A Newton-step calculation seen graphically. The brown function is approximated as a straight-line function at the initial point \\(x_0\\). The resulting \\(x_1\\) is where that straight line crosses the value \\(v\\) on the output scale. Here, \\(x_1\\) is a little to the left of the actual place where \\(f()\\) crosses \\(v\\). The Newton step produced an improved guess, since \\(\\|x_1 - x^\\\\star\\|\\) is smaller than \\(\\| x_0 - x^\\star\\|\\).\n\n\n\n\n\n\n\n\n\n\n\nTry it! 48.1\n\n\n\n\n\n\n\n\n\nTry it! 48.1 Taking a Newton step\n\n\n\nConstruct the Newton-step function for finding zeros of the function \\[f(x) \\equiv x^2 - x\\ \\]\nSince \\(\\partial_x f(x) = 2 x - 1\\), the custom-built Newton-step function will be: \\[\\text{solve-step}(z) = z - \\frac{z^2 - z - 4}{2 z - 1}\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe algorithm requires a starting guess. We will use \\(x_0 = 2\\). After each application of solve_step(), we will print out the refined value as well as the function output at that refined value.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe output \\(f(x_3)\\) is practically the desired \\(v=4\\) so we have our result: \\(x^\\star = 2.56155\\)!\nAfter the first Newton step, producing \\(x_1 = 2.666666\\), the function output and \\(f(x_1) = 4.44444\\) was not sufficiently close to the desired output for us to take \\(x_1\\) as the solution. You can think of the problem like the task of digging a well. You need to start with the first shovelful. Then take another and another and … until you have your well.\n\n\n\n\n\n\n\n\n\n\n\n\nZeros() takes two arguments: a function and a domain. The function is specified, as with other R/mosaic operators such as D(), slice_plot(), etc., as a tilde expression. Zeros() searches the domain for an input which makes the value of the function zero. If, instead, you want to find an input that makes the function value some other value, say \\(f(x^\\star) = v\\), you construct an intermediate expression f(x) - v ~ x. Finding the zero of the intermediate function corresponds to finding \\(f(x^star) = v\\).\nSometimes there will be multiple zeros on the specified domain. To handle such situations, Zeros() returns a data frame with two columns. The first gives input values that correspond to an output near zero. The second column, named .output. calculates the output (and will be near zero). We will illustrate by solving \\(x^3 = 6\\) for \\(x\\).\n\n\n\n\n\n\n\n\nTry it! 48.2\n\n\n\n\n\n\n\n\n\nTry it! 48.2 “Solving” by finding zeros.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n48.2 Task: Argmax\nThe task of finding the input value that corresponds to a local maximum is called argmax finding. We don’t need to know the value of the local maximum to solve this problem. Instead, we designate a locale by specifying an initial guess \\(x_0\\) for the argmax. For argmax finding of an objective function \\(f(x)\\), we seek a \\(x^\\star\\) such that \\(f(x^\\star) &gt; f(x_0)\\).\nTo accomplish this, we will approximate \\(f(x)\\) with a low-order polynomial, as we so often do. We will call the approximation \\(\\widehat{f(x)}\\). In the solving task, the approximation was with a first-order polynomial. But first-order polynomials—that is, straight-line functions—don’t have a local argmax. We need to use a second-order polynomial. Easy enough: construct the second-order Taylor polynomial around \\(x_0\\):\n\\[\\widehat{f}(x) \\equiv f(x_0) + f'(x_0) \\left[x - x_0\\right] + \\frac{1}{2} f''(x_0) \\left[x-x_0\\right]^2\\] Remember that \\(f(x_0)\\), \\(f'(x_0)\\) and \\(f''(x_0)\\) are all fixed quantities; the output of the functions for the specific input \\(x_0\\).\nTo find the argmax of \\(\\widehat{f}(x)\\), differentiate it with respect to \\(x\\) and find the zero of the derivative: \\[\\partial_x \\widehat{f(x)} = f'(x_0) \\underbrace{\\partial_x\\left[x - x_0\\right]}_{{\\large\\strut}1} +\n\\frac{1}{2} f''(x_0) \\underbrace{\\partial_x\\left[x-x_0\\right]^2}_{2 \\left[x - x_0\\right]} = 0\n\\]\nThis gives \\[f'(x_0) + f''(x_0) \\left[x - x_0\\right] = 0\\ .\\] We will solve this equation for \\(x\\) and, having in mind the iterative process of the previous section, call the result \\(x_1\\) \\[x_1 = x_0 - \\frac{f'(x_0)}{f''(x_0)}\\ .\\] In other words, our new guess \\(x_1\\) will be a step away from the old guess \\(x_0\\), with the step being \\(-f'(x_0) / f''(x_0)\\). This also is called a Newton step. What’s different from the Newton step of the previous section is that the function whose zeros are being sought is not \\(f(x)\\) but \\(f'(x)\\).\n\n\n\n\n\n\n\n\nTry it! 48.3\n\n\n\n\n\n\n\n\n\nTry it! 48.3 Searching for an argmax\n\n\n\nUse the R/mosaic argM() function to find argmaxes and argmins. Like other R/mosaic calculus functions, the first argument is a tilde expression defining the objective function. The second argument is the domain to search.\nTo illustrate, the following code creates a randomly shaped function (displayed in ?fig-argm-ex1) and calls argM() to generate the argmaxes and argmins.\n\nf &lt;- doodle_fun(~ x, 3215)\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice that argM() identified both a local maximum and a local minimum, that is, one argmax and one argmin. Visually, it is easy to tell which one is which. In terms of the data frame returned by argM(), the sign of the concavity does the identification for you: positive concavity points to an argmin, negative concavity to an argmax. The name argM() refers to this versatility of finding both argmins and argmaxes.\n\n\n\n\n48.3 Task: Iterate\nIn everyday language, to iterate means simply to repeat: to do something over and over again. In mathematics and in computing, “iterate” has a more specific meaning: to repeatedly perform an operation, each time taking the output from the previous round as the input to the current round.\nFor our purposes, it suffices to define iteration in terms of the use of a function \\(g(x)\\). The function must be such that the output of the function can be used as an input to the function; the output must be the same kind of thing as the input. The iteration starts with a specific value for the input. We will call this value \\(x_0\\). Iteration then means simply to compose the function with itself starting with \\(x_0\\) as the initial input. Here, for instance, is a four-step iteration: \\[g(g(g(g(x_0))))\\] Or, you might choose to iterate for ten steps: \\[g(g(g(g(g(g(g(g(g(g(x_0))))))))))\\] However many iteration steps you take, the output from the final step is what you work with.\nIteration is the mathematical engine behind many function operations. You’ve already seen it at work for the “solve” task and the “argmax” task.\n\n\n\n\n\n\n\n\nTry it! 48.4\n\n\n\n\n\n\n\n\n\nTry it! 48.4 Iterating automatically\n\n\n\nThe R/mosaic function Iterate() provides a very simple way to see the results of iteration. Typically when iteration is used as part of a function operation, the software has been written specifically for that task and includes logic about when to stop or start over or handle a variety of troublesome cases. The function Iterate() is provided in R/mosaic just for demonstration purposes.\nIterate() takes arguments specifying the function to be iterated (as a tilde expression), the starting \\(x_0\\), and the number \\(n\\) of steps to take. To illustrate, we will iterate a famous function called the logistic map: \\(f(x) \\equiv \\mu x (1-x)\\). Depending on the value of the parameter \\(\\mu\\), the iterates can show different patterns.\nEventually reaching a fixed point:\n\nIterate(2*x*(1-x) ~ x, x0=0.3, n=10)\n##     n         x\n## 1   0 0.3000000\n## 2   1 0.4200000\n## 3   2 0.4872000\n## 4   3 0.4996723\n## 5   4 0.4999998\n## 6   5 0.5000000\n## 7   6 0.5000000\n## 8   7 0.5000000\n## 9   8 0.5000000\n## 10  9 0.5000000\n## 11 10 0.5000000\n\nEventually reaching a periodic oscillation:\n\nIterate(3.2*x*(1-x) ~ x, x0=0.3, n=50) |&gt; tail()\n##     n         x\n## 46 45 0.5130445\n## 47 46 0.7994555\n## 48 47 0.5130445\n## 49 48 0.7994555\n## 50 49 0.5130445\n## 51 50 0.7994555\n\nA never-ending, random-seeming fluctuation, called mathematical chaos:\n\nIterate(4.0*x*(1-x) ~ x, x0=0.3, n=5000) |&gt; tail()\n##         n          x\n## 4996 4995 0.56824790\n## 4997 4996 0.98136889\n## 4998 4997 0.07313595\n## 4999 4998 0.27114833\n## 5000 4999 0.79050766\n## 5001 5000 0.66242119\n\n\n\n\n\n48.4 Software for the tasks\nEvaluation of a function—number one in the list at the head of this chapter—is so central to the use of computer languages generally that every language provides a direct means for doing so. In R, as you know, the evaluation syntax involves following the name of the functions by a pair of parentheses, placing in those parenthesis the values for the various arguments to the function. Example: log(5)\nThe other six operations on functions listed above, there is one (or sometimes more) specific R/mosaic functions. Every one of them takes, as a first argument, a tilde expression describing the function on which the operation is to be formed; on the left side is a formula for the function (which can be in terms of other, previously defined functions), on the right side is the with-respect-to input.\n\nDifferentiate: D(). Returns a function.\nAnti-differentiate: antiD(). Returns a function.\nIntegrate: Integrate(). Returns a number.\nSolve: Zeros(). Returns a data frame with one row for each solution found.\nArgmax: argM() Finds one argmax and one argmin in the domain. local_argM() looks for all the local argmaxes and argmins. Returns a data frame with one row for each argmax or argmin found.\nIterate: Iterate() Returns a data frame with the value of the initial input and the output after each iteration.\n\nEach of operations 4-6 involves the specification of a domain. For Integrate(), this is, naturally, the domain of integration: the upper and lower bounds of the integral\nFor Zeros() and argM() the domain specifies where to search for the answer. Iterate() is slightly different. After the tilde expression comes an initial value \\(x_0\\) and then n= which you use to set the number of times to iterate.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Operations on functions</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-operations.html#task-argmax",
    "href": "Manifestations/B4-operations.html#task-argmax",
    "title": "48  Operations on functions",
    "section": "",
    "text": "The task of finding the input value that corresponds to a local maximum is called argmax finding. We don’t need to know the value of the local maximum to solve this problem. Instead, we designate a locale by specifying an initial guess \\(x_0\\) for the argmax. For argmax finding of an objective function \\(f(x)\\), we seek a \\(x^\\star\\) such that \\(f(x^\\star) &gt; f(x_0)\\).\nTo accomplish this, we will approximate \\(f(x)\\) with a low-order polynomial, as we so often do. We will call the approximation \\(\\widehat{f(x)}\\). In the solving task, the approximation was with a first-order polynomial. But first-order polynomials—that is, straight-line functions—don’t have a local argmax. We need to use a second-order polynomial. Easy enough: construct the second-order Taylor polynomial around \\(x_0\\):\n\\[\\widehat{f}(x) \\equiv f(x_0) + f'(x_0) \\left[x - x_0\\right] + \\frac{1}{2} f''(x_0) \\left[x-x_0\\right]^2\\] Remember that \\(f(x_0)\\), \\(f'(x_0)\\) and \\(f''(x_0)\\) are all fixed quantities; the output of the functions for the specific input \\(x_0\\).\nTo find the argmax of \\(\\widehat{f}(x)\\), differentiate it with respect to \\(x\\) and find the zero of the derivative: \\[\\partial_x \\widehat{f(x)} = f'(x_0) \\underbrace{\\partial_x\\left[x - x_0\\right]}_{{\\large\\strut}1} +\n\\frac{1}{2} f''(x_0) \\underbrace{\\partial_x\\left[x-x_0\\right]^2}_{2 \\left[x - x_0\\right]} = 0\n\\]\nThis gives \\[f'(x_0) + f''(x_0) \\left[x - x_0\\right] = 0\\ .\\] We will solve this equation for \\(x\\) and, having in mind the iterative process of the previous section, call the result \\(x_1\\) \\[x_1 = x_0 - \\frac{f'(x_0)}{f''(x_0)}\\ .\\] In other words, our new guess \\(x_1\\) will be a step away from the old guess \\(x_0\\), with the step being \\(-f'(x_0) / f''(x_0)\\). This also is called a Newton step. What’s different from the Newton step of the previous section is that the function whose zeros are being sought is not \\(f(x)\\) but \\(f'(x)\\).\n\n\n\n\n\n\n\n\nTry it! 48.3\n\n\n\n\n\n\n\n\n\nTry it! 48.3 Searching for an argmax\n\n\n\nUse the R/mosaic argM() function to find argmaxes and argmins. Like other R/mosaic calculus functions, the first argument is a tilde expression defining the objective function. The second argument is the domain to search.\nTo illustrate, the following code creates a randomly shaped function (displayed in ?fig-argm-ex1) and calls argM() to generate the argmaxes and argmins.\n\nf &lt;- doodle_fun(~ x, 3215)\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice that argM() identified both a local maximum and a local minimum, that is, one argmax and one argmin. Visually, it is easy to tell which one is which. In terms of the data frame returned by argM(), the sign of the concavity does the identification for you: positive concavity points to an argmin, negative concavity to an argmax. The name argM() refers to this versatility of finding both argmins and argmaxes.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Operations on functions</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-operations.html#task-iterate",
    "href": "Manifestations/B4-operations.html#task-iterate",
    "title": "48  Operations on functions",
    "section": "48.3 Task: Iterate",
    "text": "48.3 Task: Iterate\nIn everyday language, to iterate means simply to repeat: to do something over and over again. In mathematics and in computing, “iterate” has a more specific meaning: to repeatedly perform an operation, each time taking the output from the previous round as the input to the current round.\nFor our purposes, it suffices to define iteration in terms of the use of a function \\(g(x)\\). The function must be such that the output of the function can be used as an input to the function; the output must be the same kind of thing as the input. The iteration starts with a specific value for the input. We will call this value \\(x_0\\). Iteration then means simply to compose the function with itself starting with \\(x_0\\) as the initial input. Here, for instance, is a four-step iteration: \\[g(g(g(g(x_0))))\\] Or, you might choose to iterate for ten steps: \\[g(g(g(g(g(g(g(g(g(g(x_0))))))))))\\] However many iteration steps you take, the output from the final step is what you work with.\nIteration is the mathematical engine behind many function operations. You’ve already seen it at work for the “solve” task and the “argmax” task.\n\n\n\n\n\n\n\n\nTry it! 48.4\n\n\n\n\n\n\n\n\n\nTry it! 48.4 Iterating automatically\n\n\n\nThe R/mosaic function Iterate() provides a very simple way to see the results of iteration. Typically when iteration is used as part of a function operation, the software has been written specifically for that task and includes logic about when to stop or start over or handle a variety of troublesome cases. The function Iterate() is provided in R/mosaic just for demonstration purposes.\nIterate() takes arguments specifying the function to be iterated (as a tilde expression), the starting \\(x_0\\), and the number \\(n\\) of steps to take. To illustrate, we will iterate a famous function called the logistic map: \\(f(x) \\equiv \\mu x (1-x)\\). Depending on the value of the parameter \\(\\mu\\), the iterates can show different patterns.\nEventually reaching a fixed point:\n\nIterate(2*x*(1-x) ~ x, x0=0.3, n=10)\n##     n         x\n## 1   0 0.3000000\n## 2   1 0.4200000\n## 3   2 0.4872000\n## 4   3 0.4996723\n## 5   4 0.4999998\n## 6   5 0.5000000\n## 7   6 0.5000000\n## 8   7 0.5000000\n## 9   8 0.5000000\n## 10  9 0.5000000\n## 11 10 0.5000000\n\nEventually reaching a periodic oscillation:\n\nIterate(3.2*x*(1-x) ~ x, x0=0.3, n=50) |&gt; tail()\n##     n         x\n## 46 45 0.5130445\n## 47 46 0.7994555\n## 48 47 0.5130445\n## 49 48 0.7994555\n## 50 49 0.5130445\n## 51 50 0.7994555\n\nA never-ending, random-seeming fluctuation, called mathematical chaos:\n\nIterate(4.0*x*(1-x) ~ x, x0=0.3, n=5000) |&gt; tail()\n##         n          x\n## 4996 4995 0.56824790\n## 4997 4996 0.98136889\n## 4998 4997 0.07313595\n## 4999 4998 0.27114833\n## 5000 4999 0.79050766\n## 5001 5000 0.66242119",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Operations on functions</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-operations.html#software-for-the-tasks",
    "href": "Manifestations/B4-operations.html#software-for-the-tasks",
    "title": "48  Operations on functions",
    "section": "48.4 Software for the tasks",
    "text": "48.4 Software for the tasks\nEvaluation of a function—number one in the list at the head of this chapter—is so central to the use of computer languages generally that every language provides a direct means for doing so. In R, as you know, the evaluation syntax involves following the name of the functions by a pair of parentheses, placing in those parenthesis the values for the various arguments to the function. Example: log(5)\nThe other six operations on functions listed above, there is one (or sometimes more) specific R/mosaic functions. Every one of them takes, as a first argument, a tilde expression describing the function on which the operation is to be formed; on the left side is a formula for the function (which can be in terms of other, previously defined functions), on the right side is the with-respect-to input.\n\nDifferentiate: D(). Returns a function.\nAnti-differentiate: antiD(). Returns a function.\nIntegrate: Integrate(). Returns a number.\nSolve: Zeros(). Returns a data frame with one row for each solution found.\nArgmax: argM() Finds one argmax and one argmin in the domain. local_argM() looks for all the local argmaxes and argmins. Returns a data frame with one row for each argmax or argmin found.\nIterate: Iterate() Returns a data frame with the value of the initial input and the output after each iteration.\n\nEach of operations 4-6 involves the specification of a domain. For Integrate(), this is, naturally, the domain of integration: the upper and lower bounds of the integral\nFor Zeros() and argM() the domain specifies where to search for the answer. Iterate() is slightly different. After the tilde expression comes an initial value \\(x_0\\) and then n= which you use to set the number of times to iterate.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Operations on functions</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-operations.html#footnotes",
    "href": "Manifestations/B4-operations.html#footnotes",
    "title": "48  Operations on functions",
    "section": "",
    "text": "A traditional name for such a person is “numerical analyst.”↩︎",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Operations on functions</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-mechanics.html",
    "href": "Manifestations/B4-mechanics.html",
    "title": "53  Mechanics",
    "section": "",
    "text": "53.1 Work\n“Work” is a familiar, everyday concept, but a nuanced one; one person’s work can be another person’s play. In mechanics, work has a much more specific meaning stemming from the study of simple machines. A lever, for instance, can be used to move an object that is otherwise too heavy to handle. It still takes toil and effort to move the object, but the effort is eased by the mechanics of the lever.\nOur intuitive sense of work is perhaps rooted in physiology: effort, fatigue, muscle pain. For instance, it takes work to pick up a heavy object, but it is also work to hold the object steady even without moving it. Generations of thinking about machines has brought us to a different notion of work that does not involve human subjectivity. In mechanics, holding an object steady, no matter how heavy, does not involve work. Although a human tasked to hold a heavy load will become exhausted, the same duty can be accomplished by placing the load on a table, completely eliminating the effort. In mechanics, work and motion go hand in hand; without motion there is no mechanical work.\nThe table holding the heavy load does no work. Work is done only when the load is moved, and the amount of work depends on how the load is moved. For instance, moving a block along level ground involves a lot of work, but pulling a cart filled with blocks can be almost effortless. In mechanics, work combines both the amount of motion and the force needed to accomplish the motion.\nConsider, for instance, the work involved in lifting a mass \\(m\\) to table height \\(h\\).\nThe lifting is accomplished by applying an upward force to counter the force of gravity. The gravitational force on the mass is \\(m g\\), where \\(g\\) is the instantaneous acceleration of an object released to fall freely (about 9.8 m/s2 near the Earth’s surface). The distance traveled is \\(h\\). So the work performed on the mass is \\(m g h\\).\nNotice that the mechanical work has nothing to do with the speed with which the mass is moved up to the table. Lift it fast or lift it slow, it amounts to the same mechanical work. (Of course, to human perception, lifting an object very slowly up to table height involves more effort than snapping it up quickly. But human effort is only peripherally related to mechanical work.)\nLet’s introduce a machine to the situation in the form of a ramp or a pulley. The purpose of the machine is to ease human labor by changing the strength or direction of forces. You can perhaps intuit that rolling the mass up the ramp will be an easier task than lifting it. How so?\nThe ramp can be seen as a sort of partial table. The ramp does most of what’s needed to hold the mass up. To keep the mass in place on the ramp the human worker need only supply a modest additional force parallel to the ramp surface. Calculating that modest additional force can be accomplished by a basic mathematical technique in mechanics: decomposing a vector.\nYou encountered vectors (in Section 24.003) in the context of the gradient vector of a function, say, \\(f(x,y)\\). At any given input \\((x,y)\\) the gradient vector, written \\(\\nabla f(x,y)\\), points in the steepest uphill direction of the function \\(f(x,y)\\). Recall that the gradient vector was written as a set of values; the partial derivative of \\(f()\\) with respect to each of its inputs in turn. That is, \\[\\nabla f(x,y) = \\left({\\large\\strut} \\partial_x f(x,y),\\ \\  \\partial_y f(x,y)\\right)\\ .\\] In this representation, the vector \\(\\nabla f(x, y)\\) is decomposed into two components: \\(\\partial_x f(x,y)\\) and \\(\\partial_y f(x,y)\\).\nTo decompose the vector of gravitational forces, we can place a coordinate grid over the gravity vector. In Figure 53.1 this grid has been arranged so that one cardinal direction is aligned with the ramp itself and the other is perpendicular—that is, “normal”—to the ramp. Merely by noting the coordinates of the gravitational vector in the coordinate grid, we decompose that vector into two components, one along the surface of the ramp and the other perpendicular to the ramp.\nWe return to the idea of vector decomposition in much more detail in Block 5 of this course; it has a major (though perhaps unexpected) role to play in fitting models to data. But for now, we will simply examine the right triangle in Figure 53.1. In that right triangle, the gravitational force vector \\(F_{gravity} = m g\\) is the hypotenuse. The component tangential to the ramp is \\(m \\sin(\\theta) g\\). The worker pushing the mass up the ramp need provide only tangential component of force which is smaller than the force imposed on the worker picking up the mass without a ramp. Thus human effort is reduced by the machine.\nWhat about the mechanical work? Is that also reduced? Remember that mechanical work is the product of force times distance. The force has been reduced to \\(m \\sin(\\theta) g\\), but the distance \\(D_{ramp}\\) along the ramp is much longer than the distance \\(h\\) from floor to table top.\nAgain, referring to the ramp itself as a right triangle, you can see that \\(D_{ramp}\\sin(\\theta) = h\\) or, \\(D_{ramp} = h / \\sin(\\theta)\\). The total mechanical work, the product of applied force times distance moved is \\[m \\sin(\\theta) g \\times D_{ramp} = m \\sin(\\theta) g \\times \\frac{h}{\\sin(\\theta)} = m g h\\ .\\] The ramp does nothing to reduce the mechanical work needed to lift the mass!\nWe usually think of ramps as an inclined plane. But, from Blocks 1 to 3 we have the tools to figure out the work for a (smooth) ramp with any shape at all. We will do this not because odd-shaped ramps are encountered frequently, but to provide an example in a relatively familiar setting of some techniques we will use elsewhere in this chapter.\nThe ramp we have in mind has a surface whose height \\(f(x)\\) is zero at the foot (\\(x=a\\)) and reaches \\(f(x=b) = h\\) where it joins the table.\nThe slope of the ramp at any location \\(x\\) is, as you know, \\(\\partial_x f(x)\\). It is helpful to convert this rise/run formulation of slope into the slope-angle form we used to study the simple ramp. As you can see from the diagram, which zooms in on one place on the ramp, rise over run amounts to \\(L\\sin(\\theta) / L\\cos(\\theta) = \\partial_x f(x) = \\tan(\\theta)\\), with the result: \\[\\theta = \\arctan({\\large\\strut}\\partial_x f(x))\\ .\\] Consequently, the force that needs to be applied parallel to the ramp’s surface is \\(m \\sin(\\arctan(\\partial_x f(x))) g = m \\sin(\\theta) g\\). To find the work done in pushing the mass an infinitesimal distance along the ramp we need to know the instantaneous length of the ramp. This is potentially confusing to the reader since we’ve already said that the distance is infinitesimal. As you know, infinitesimal is different from zero. We will write \\(dx\\) as an infinitesimal increment along the floor, but the zoomed-in length \\(dL\\) of the corresponding part of the ramp is the hypotenuse of a right triangle where one leg has length \\(dx\\) and the other leg has length \\(\\partial_x f(x) dx\\): slope times distance.\nThe hypotenuse of the infinitesimal segment of the ramp has length \\(dL = \\sqrt{\\strut dx + \\partial_x f(x) dx}\\), or \\(dL = \\sqrt{\\strut 1 + \\partial_x f(x)}\\ dx\\). Things are a bit simpler if we write \\(dL\\) in terms of the slope angle \\(\\theta(x)\\). Since \\(dx = \\cos(\\theta(x)) dL\\), we know \\(dL = dx/\\cos(\\theta(x))\\). Consequently the infinitesimal of work is \\[dW \\ = \\ m g \\frac{\\sin(\\theta(x))}{\\cos(\\theta(x))}\\ dx\\  = \\ m g \\tan(\\theta(x)) dx \\ .\\]\nThe total work is the accumulation of \\(dW\\) over the extent of the ramp. In other words, \\[\\int_a^b m g \\tan(\\theta(x))\\ dx\\ = \\ \\int_a^b m g \\tan(\\arctan(\\partial_x f(x)))\\ dx = \\int_a^b m g \\partial_x f(x) dx\\ ,\\] where we’ve used the formula \\(\\theta(x) = \\arctan(\\partial_x f(x))\\). From the “fundamental theorem of calculus” we know that\n\\[\\int_a^b m g\\ \\partial_x f(x)\\ dx \\ = \\ \\left.m g \\ f(x){\\Large\\strut}\\right|_a^b = mg \\left[\\strut f(b) - f(a)\\right] = mg h\\ .\\]\nWhat’s remarkable is that pushing the mass up the \\(f(x)\\)-shaped ramp involves an amount of work, \\(m g h\\), that does not depend on \\(f(x)\\), only on \\(f(b) - f(a)\\), the net height comprised by the ramp.\nWe haven’t yet said what this notion of work is good for and we’ve given no detailed justification for the definition of mechanical work as force times distance. You could imagine a dictatorial authority deciding to measure work as the square-root of force times distance squared. But … that particular measure is not going to make sense if we think about the dimension of the quantity. Force has dimension [force] = M L T-2. Square root of force times length squared would have dimension [sqrt(force) \\(\\times\\) length-squared] = M1/2 L5/2 T-2. The non-integer exponents mean that this is not a legitimate physical quantity.\nThe dimension of force-times-length are straightforward: [force \\(\\times\\) length] = M L2 T-2, that is, energy. The particular definition of work as force times length will make sense in the context of a more comprehensive mechanical theory of energy. The significance of energy itself is that, as a fundamental proposition of physics, the various forms of energy are interchangeable but conserved; energy is neither created nor destroyed, just moved around from one form to another and one place to another.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Mechanics</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#work",
    "href": "Manifestations/B4-mechanics.html#work",
    "title": "53  Mechanics",
    "section": "",
    "text": "Work is force times displacement.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 53.1: Decomposing the vector of gravitational force into two perpendicular components, one tangent to the ramp and the other perpendicular to it. For clarity, the right triangle of decomposition is shown twice, once without the grid.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplication area 53.1  \n\n\n\n\n\n\n\nApplication area 53.1 Lifting very high\n\n\n\nNear the surface of the Earth, gravitational acceleration is approximately constant regardless of latitude or longitude. But gravity varies with distance \\(r\\) from the Earth’s center. Newton’s law of universal gravitation gives the force on an object of mass \\(m\\) due to the Earth’s gravity as \\[F = \\frac{m M_e G}{r^2}\\] where \\(M_e = 5.972 \\times 10^{24}\\) kg is the mass of the Earth and \\(G = 6.674 \\times 10^{-11}\\) N m2 / kg2 is the universal gravitational constant. The Earth’s radius is roughly \\(6,370,000\\) m, so the force on a 1 kg object near the surface of the Earth is \\(F = 1 \\text{kg} (5.972 \\times 10^{24} \\text{kg}) (6.674 \\times 10^{-11})/ (6.37 \\times 10^6 \\text{m})^2\\) N m2 kg-2. Carrying out the arithmetic and consolidating the units gives \\[F = 9.823 N\\] for the 1 kg object.\nSuppose we want to lift the 1 kg object from the Earth’s surface to 10000 km away, that is, to a distance of 1,6370,000 m from the center of the Earth. For the purpose of the example, we will ignore the gravitational force exerted by the Sun, Moon, planets, and other galaxies, etc. The work performed in the lifting is\n\\[\\int_{6.47\\times 10^6}^{16.47\\times 10^6} \\frac{1 \\text{kg}\\ M_e\\ G}{r^2}\\ dr = -\\left.  {\\Large\\strut}\\frac{1 \\text{kg}\\ M_e\\ G}{r}\\right|_{6.47\\times 10^6}^{16.47\\times 10^6} \\\\\\ \\\\\\ \\\\=\n-\\ 3.986 \\times 10^{14}\\left[\\strut \\frac{1}{16.47 \\times 10^6} - \\frac{1}{6.47 \\times 10^6}\\right] \\text{N m} \\\\\\ \\\\\\ \\\\= 37,405,840\\ \\text{J}.\\]\nA Newton-meter (N m) is also known as a Joule (J), a unit of energy. With 37,000,000 J, you could toast about 2000 pieces of bread. (A toaster uses about 300 W of power and takes about 60 seconds to process a slice of bread. \\(\\text{300 W} \\times \\text{60 s} = 18,000 \\text{J}\\).",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Mechanics</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#energy",
    "href": "Manifestations/B4-mechanics.html#energy",
    "title": "53  Mechanics",
    "section": "53.2 Energy",
    "text": "53.2 Energy\nMechanical work, as discussed in the previous section, is a form of energy. When we lift a object, we put energy into the object. But we cannot say from examining the object how much work was done to place it on the table. The amount of work depends on how the object came to be on the table: lifted from the floor (positive work; force is positive upward, displacement is also positive upward) or perhaps lowered from a helicopter (negative work: force exerted by the cable is positive upward but the displacement is downward, therefore negative). We might call the work energy latent, the word meaning “unobservable,” “hidden,” “concealed,” “dormant.” To have an operational meaning, the work-energy that we assign to an object at rest must be with respect to some “ground state.” A convenient ground state here is to imagine the object resting on the ground. The assigned energy will then be the work that would have to be performed to raise the object to table height. Once at table height, the energy is again latent.\nHow then to measure the work energy that is latent in the object resting on the table? The idea is to return the object to its ground state, which we could do by lowering it—a negative displacement—to the ground, measuring the force needed to support the object (upward, so positive) and multiplying this by the displacement.\nAnother idea for measuring the latent energy is to let the object fall freely back toward its ground state and see what changes about the object. Perhaps you have already caught on to what will happen: the object’s speed increases steadily until the instant before it hits the ground.\n“Latent” is an apt but unusual word to express the energy imbued in the object resting on the table. We might equally say that the energy is “associated with position (at the height the table),” or we could call it “gravitational energy.” The term that is generally used is a near synonym of “latent.” We call the energy of the stationary object on the table potential energy. More precisely it can be called gravitational potential energy to distinguish it from the potential energy created by other forms of work, for instance pulling apart magnets or electric charges or compressing a gas into a cylinder.\nThere is also a form of energy associated with motion. We could call this “energy of motion,” but the conventional term is kinetic energy. (A dictionary definition of “kinetic” is “relating to or resulting from motion.” so we might as well say simply that kinetic energy is “energy relating to motion.)\nVelocity is a good way to observe motion. We can use dimensional analysis to anticipate how velocity and kinetic energy are related. Recall that energy has dimension M L2 T-2 and velocity has dimension L/T. Consequently, if an object’s kinetic energy at any instant stems from its mass and its velocity, then the energy must be mass times velocity squared, perhaps multiplied by a scalar, that is: \\[E_{kinetic} = \\alpha\\, m v^2\\ .\\]\nTo find the scalar \\(\\alpha\\), we can use calculus and accumulation. We know that the acceleration of a free-falling object due to gravity is \\(-g\\) (where the negative sign reflects the downward direction). Starting from rest (that is zero velocity so zero kinetic energy) the newly released mass will have a velocity that is the accumulated acceleration over time. In other words: \\[v(t) = \\int_0^t - g\\ dt = -\\left.g \\ t{\\large\\strut}\\right|_0^t = -g\\ t\\ .\\] Correspondingly, the position at time \\(t\\) will be the accumulated velocity: \\[x(t) = x(t=0) + \\int_0^t v(t) dt \\\\ =\nh  + \\int_0^t -g\\ t\\ dt \\\\\n= h - \\frac{1}{2} \\left.g\\ t^2{\\Large\\strut}\\right|_0^t \\ \\ =\\ \\  h - \\frac{1}{2} g\\ t^2 \\ .\\] The mass reaches the ground at time \\(t_g\\) such that \\(h - \\frac{1}{2} g\\ t_g^2 = 0\\). Solving this for \\(t_g\\) gives \\(t_g = \\sqrt{\\strut 2 h/g}\\).\nNow that we know the time when the object reaches its ground state, we can calculate the velocity at that instant: \\[v(t_g) = -g\\ t_g = - g\\ \\sqrt{\\strut 2 h / g} = - \\sqrt{\\strut 2 g h}\\] As the object reaches its ground state, its gravitation potential energy is zero (because it is at the ground state) and, since total energy is conserved, the kinetic energy will be the same size as the potential energy at \\(t=0\\) when the object was released from the table, that is \\[E_{kinetic}(t_g) = \\alpha\\ m\\ v(t_g)^2 =\n= \\alpha\\ m \\left(\\sqrt{\\strut 2 g h\\ }\\ \\right)^2 = \\\\\\ \\\\2\\, \\alpha\\, m\\, g\\, h\\  = m\\, g\\, h = E_{potential}(t=0)\\]\nSolving \\(2 \\alpha\\ m\\,g\\,h = m\\,g\\,h\\) gives \\(\\alpha = \\frac{1}{2}\\). Thus, the kinetic energy as a function of mass \\(m\\) and velocity \\(v\\) is \\(\\frac{1}{2} m\\, v^2\\).\n\nApplication area 53.2  \n\n\n\n\n\n\n\nApplication area 53.2 … getting there\n\n\n\nIn the previous section, we calculated the potential energy of a 1 kg object at an altitude of 10,000 km above the Earth’s surface: 37,405,840 J. How fast would the 1 kg object need to be moving to have this much kinetic energy?\n\\[\\frac{1}{2} (1 \\text{kg}) v^2 = 37,\\!405,\\!840 \\text{J} = 37,\\!405,\\!840 \\ \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\]\nSolving for \\(v\\) we get \\(v^2 = 2 \\times 37,\\!405,\\!840 \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\ \\text{kg}^{-1}\\) or \\[v = 8649.4\\ \\text{m}/\\text{s}\\ ,\\] about eight-and-a-half kilometers per second.\n\n\n\nApplication area 53.3 —Mechanical work always involves movement, even when it doesn’t seem like it.\n\n\n\n\n\n\n\nApplication area 53.3 Work without movement?\n\n\n\nFigure 53.2 shows a simple exercise: holding a dumbbell out horizontally.\n\n\n\n\n\n\nFigure 53.2: Is he working even when the barbells are held still? Of course! Photo source\n\n\n\nAs anyone who does this exercise can tell you, even when there is no movement of the dumbbell, there is a strong sense of work being done. Your muscle fatigues and, for most people, the dumbbells can be held in place for only a short time.\nWe’ve said that mechanical work always involves motion; no motion, no work. So how come the exercise feels like work even though the hands do not move?\nTo perform the exercise, you contract the muscles of the shoulder and upper arm. There is no skeletal joint that can be locked in place (unlike, say, the knee). It is only the muscle force that holds the arms in place.\nOn the size scale that we normally perceive, it can appear that nothing is moving during the exercise. But zoom in to the molecular scale to see the action by which force is generated by muscle. The functional unit of muscle force involves two proteins, actin and myosin, that interact in a complicated way. The animation (from the online textbook by Michael D. Mann, The Nervous System in Action, chapter 14) shows the situation. The “head” of a myosin unit (red) acts like an oar. It attaches to a site on the actin molecule (orange) causing the head to contract and pull on the actin. Once contracted, a molecule of ATP (green sphere) binds to the myosin, releasing the head and preparing it for another stroke. ATP is an organic molecule that serves as a primary energy carrier and is found in all known forms of life. Transformation of ATP to ADP releases the energy. The ADP is then cycled, though other metabolic processes, back into ATP. This happens rapidly. Humans recycle approximately their own body weight in ATP each day.\n\n\n\n\n\n\nFigure 53.3: Animation of the generation of force by the interaction of actin and myosin, from The Nervous System in Action.\n\n\n\nWhen muscle is under tension, the actin can slip back in between strokes of the myosin head. Thus, a constant-length muscle in tension on a macroscopic scale is steadily consuming energy, in much the same way as an oarsman on an anchored boat can do work via the movement of oars against the water even when the boat itself is not moving.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Mechanics</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#momentum",
    "href": "Manifestations/B4-mechanics.html#momentum",
    "title": "53  Mechanics",
    "section": "53.3 Momentum",
    "text": "53.3 Momentum\nIn the previous sections we looked at force \\(\\times\\) distance. Dimensional analysis showed that [force \\(\\times\\) distance] = energy and, in the setting of lifting an object and letting it fall back toward its ground state, we traced out the conversion of the energy of position (“potential energy”) into the energy of velocity (“kinetic energy”).\nNow consider a somewhat different quantity: force \\(\\times\\) time. Dimensional analysis gives \\[\\underbrace{M^1 L^1 \\ T^{-2}}_\\text{[force]}\\  \\times\\ \\underbrace{T}_\\text{[time]} = \\underbrace{M^1}_\\text{[mass]} \\underbrace{L^1 T^{-1}}_\\text{[velocity]} \\] The product of force times time is dimensionally equivalent to the product of mass times velocity. The quantity is called momentum. Newton’s second law of motion, often written in terms of acceleration, \\(F = m a\\), is more fundamentally written in terms of momentum: \\(F = \\partial_t\\, m\\, v\\). The conservation of momentum refers to the situation when outside forces on a system are nil. In such case, momentum of the system does not change with time; momentum is constant or “conserved.”\nAn example of such a system is a deep-space probe, sufficiently far from other matter that gravitational force is negligible. to speed up or slow down (or turn), the probe is made to throw out fast moving molecules of burnt fuel. These particles have “new” momentum, but since momentum of the whole system is conserved, the body of the probe gains “new” momentum in the opposite direction. This is the operating principle of the rocket engine.\n\n\n\n\n\n\n\n\nTurbojet\n\n\n\n\n\n\n\n\n\nTurbofan\n\n\n\n\n\n\nFigure 53.4: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air.\n\n\n\nAircraft jet engines work in a similar matter, burning fuel to create energy. Whereas the force generated by a rocket engine is entirely produced by the newly created momentum of the burnt fuel, aircraft engines have an additional material to work with: air. The earliest jet engines, turbojet engines, were small in diameter, bringing in air mainly as a fuel for combustion. (Figure 53.4 (left)1 Today’s more efficient engines are large diameter: turbofan engines. (Figure 53.4 (right)2) In addition to using air for combustion, they use large fan blades to convert the energy of combustion into a large mass of relatively slowly moving, uncombusted air. This moving air carries momentum; more than that contained in the fast moving particles generated directly through combustion.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Mechanics</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#sec-center-of-mass",
    "href": "Manifestations/B4-mechanics.html#sec-center-of-mass",
    "title": "53  Mechanics",
    "section": "53.4 Center of mass",
    "text": "53.4 Center of mass\nIn considering a physical object of extended shape, it can be a great simplification to be able to treat the whole extended object as if it were a simple point object at a single location. For instance, Figure 53.5 imagines a space probe (orange dot) coasting through the edge of a galaxy.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 53.5: An imagined space probe (orange dot) on the outer edges of a galaxy.\n\n\n\nWhat is the gravitational attraction of the galaxy on the probe? One way to find this is by adding up the individual gravitational attractions of the individual stars. Another is to find the center of mass of the galaxy and calculate the force as if all the mass were at that point. The two calculations give the same answer.\nFor the galaxy, the center of mass is located at a point \\((\\bar{x},\\bar{y})\\) where \\[\\bar{x} \\equiv \\sum_\\text{galaxy} m_i x_i\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\equiv \\sum_\\text{galaxy} m_i y_i\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 53.6: An irregular shape used in the example. The \\((x,y)\\) coordinates of closely spaced points on the boundary are available as Blob1 in the sandbox software.\n\n\n\nFor a continuous shape, such as in Figure 53.6 (left) we can describe the center-of-mass calculation as an accumulation of the mass-density function \\(\\rho(x, y)\\) over the entire shape \\(S\\). The mass of the object is the accumulation of mass-density itself \\[M = \\int_\\text{S} \\rho(x,y)\\ d\\text{S}\\] while the components of the center of mass are the accumulation of \\(x\\ \\rho(x,y)\\) and \\(y\\ \\rho(x,y)\\), that is: \\[\n\\bar{x} = \\int_\\text{S} x\\ \\rho(x,y)\\ d\\text{S} / M\\\\\n\\bar{y} = \\int_\\text{S} y\\ \\rho(x,y)\\ d\\text{S} / M\n\\] where \\(S\\) refers to the whole object and \\(d\\)S is a differential of the object, that is, a tiny piece of the object.\nThere are many ways to split an object up into differentials so that they can be accumulated to give the whole integral. One simple way, shown in Figure 53.6 (right), is to divide the object into a set of discrete, non-overlapping, adjacent rectangles (or cubes for a three-dimensional object). Then, as with adding up the stars, just add up \\(x \\rho(x, y) d\\)S or \\(y \\rho(x,y) d\\)S contained in each of the rectangular \\(d\\)A regions. For the rectangle located at $(x_i, y_i), the mass \\(m_i\\) will be \\(m_i = \\rho(x_i, y_i) d\\)S: density times area of each rectangle. This turns the integrals in Eq. @ref(eq:cm-integral) into a sum:\n\\[\\bar{x} \\approx \\sum_\\text{rectangles} m_i x_i/ M\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\approx \\sum_\\text{rectangles} m_i y_i / M\\] where \\[M = \\sum_\\text{rectangles} m_i\\ .\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 53.7: A continuous shape can be approximated by a set of rectangles within the borders of the shape. Integrating over the shape is a matter of adding up across all of the rectangles the relevant quantity for each rectangle.\n\n\n\nFor the center of mass calculation, the relevant quantity for \\(\\bar{x}\\) for each rectangle is the mass times the \\(x\\)-position. Similarly, for \\(\\bar{y}\\) the relevant quanty is the mass times the \\(y\\)-position.\n\n\n\n\n\n\n\n\n\n\\(y\\) component\n\n\n\n\n\n\n\n\\(x\\) component\n\n\n\n\n\n\n\nFigure 53.8: For the \\(y\\)-component of the center of mass (left panel), the \\(x\\)-coordinate of each rectangle is irrelevant. It is as if all the rectangles were moved to \\(x=0\\). Similarly for the \\(x\\)-component of the center of mass (right panel).\n\n\n\n\n\n\n\n\n\n\n\n\nTry it! 53.1\n\n\n\n\n\n\n\n\n\nTry it! 53.1 Center of mass\n\n\n\nCompute the center of mass of the object Blob1 shown in Figure 53.6, assuming the mass-density \\(\\rho(x,y) = 10\\).\nThe mass of the object is \\[M = \\int_\\text{Blob1} \\rho(x, y)\\, dA\\] The \\(x\\)-component of the center of mass is\n\\[\\bar{x} = \\int_\\text{Blob1} x \\rho(x, y)\\, dA / M\\] and similarly for \\(\\bar{y}\\).\nTo find the center of mass, we first need to know the total mass of the object. We will carry out the calculation by dividing the object into a series of rectangles, computing the mass of each rectangle, then adding together the masses. The R/mosaic function box_set() takes as input the density function, a data frame with points on the boundary of the object, and a size for the boxes, which we will set to \\(dx=0.1\\).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nEach row of Boxes is one box. The x and y columns give the location of the center of that box, dx and dy are the lengths of the box sides in the \\(x\\) and \\(y\\) directions. The value ofthe function being accumulated is in the column labelled .output. column dA gives the area of each box (which is simply \\(dA = dx\\, dy\\)).\nAs the notation \\[\\int_\\text{Blob1} \\rho(x, y) dx dy\\] suggests, to accumulate the results for the individual boxes we just multiply the .output. by dA and sum.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nComputing the \\(x\\)-component of the center of mass, \\(\\bar{x}\\), is much the same but now the function being integrated is \\(x \\rho(x,y)\\) instead of just \\(\\rho(x,y)\\):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe \\(y\\) component of the center of mass, \\(\\bar{y}\\) is computed almost identically, but substituting 10*y ~ x & y as the function to be integrated. In the next line, we will tell box_set() to do the summation over all the boxes directly, instead of our having to do it with the with(..., sum(.output. * dA)) command.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nTip\n\n\n\nRecall that the summation over the boxes provides an approximation to the integral. The quality of the approximation depends on the boxes being small enough. It is responsible to check the result by using smaller box size. (This involves more calculation, so be patient.)\n\n\n\nActive R chunk 53.1\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nFrom this, we conclude that a box size dx = 0.01 gives 4 digits precision, but dx = 0.1 was not small enough.\nRepeat the calculation for \\(\\bar{x}\\) to get the same precision:\n\n\n\nActive R chunk 53.2\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nThere is more than one way to describe the perimeter of an object, and the manner of integration has to be selected to match the description.\n\n\nConsider this shape that might be the design of a panel in a large sculpture. The panel will be cut out of 3mm thick sheet aluminum \\(x\\) and \\(y\\) are given in meters. In order for the panel to be balanced, it will be mounted at its center of mass\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 53.9: A panel to locate center of mass\n\n\n\nThe shape is defined by two functions, \\(f(x)\\) and \\(g(x)\\), one of which sets the top edge and the other the bottom edge. The side edges are defined by the leftmost and rightmost values of \\(x\\). Here, that is \\(x_\\text{left} = - 1.5\\) and \\(x_\\text{right} = 4.0\\).\nThe area of the object can be found using the integration techniques from Block 3. For the purpose of finding the center of mass, we need to calculate the mass of the object. For 3mm sheet aluminum the density is about 8.1 kg/m2. Here, that is simply \\[\\text{mass} = \\int_{-1.5}^{4.0} 8.1 \\left[\\strut f(x) - g(x)\\right] dx \\approx 880 \\text{kg}\\ .\\]\nWhat about the center of mass? Because the shape is not described as a set of boxes, as we did earlier in this section, we need a way to perform the accumulation that uses only the information in the functions.\nThe differential \\(8.1 \\left[\\strut f(x) - g(x)\\right] dx\\) gives the mass of each vertical slice of the object, several of which are shown in \\(\\color{magenta}{\\text{magenta}}\\) in ?fig-cm-fun-diff. The tops and bottoms of those slices don’t align exactly with the boundaries of the object. That is because we’ve drawn them at a finite width so that you can see them. But the actual differentials being accumulated will have negligible width, and so will fit exactly.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 53.10: The panel can be divided into vertical slices, a few of which are shown here. The vertical mid-point of each slice is marked with a blue dash. Accumulating the slices’ mid-point coordinates times the slices’ mass, and dividing by the panel’s mass, gives the \\(y\\)-component of the center of mass.\n\n\n\nThe horizontal positions of the vertical slices are given by \\(x\\). The \\(x\\)-component of the center of mass of each individual vertical slice will be \\[x \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx\\ .\\] The center of mass of the entire object will be the accumulation \\[\\bar{x}= \\frac{1}{\\text{mass}}\\int_{-1.5}^{4.0} x\\ \\text{density} \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx \\approx 1.72 \\text{m}\\ .\\]\nFinding the \\(y\\)-component of the center of mass could be done in a similar way, by constructing horizontal slices. However, we would have to calculate the functions \\(\\text{left}(y)\\) and \\(\\text{right}(y)\\) that bound each slice.\nAn easier way is to find the vertical center of each slice. For a slice at position \\(x\\), the vertical center is \\[y_{\\text{mid}}(x) \\equiv\\left[\\strut \\text{top}(x) + \\text{bottom}(x)\\right]/ 2\\ ,\\] the average of the top and bottom positions. (These are marked in \\(\\color{blue}{\\text{blue}}\\) in Figure 53.10.) The \\(y\\)-component of the center of mass is \\[\\begin{eqnarray}\n\\bar{y} &=& \\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ y_\\text{mid}(x)\\ \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx = \\\\\n&=&\\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ \\frac{\\left[\\strut \\text{top}(x) + \\text{bottom}(x) \\right]}{2}\\ \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx =\\\\\n&=&\\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ \\frac{\\left[\\strut \\text{top}(x)^2 - \\text{bottom}(x)^2 \\right]}{2}\\ \\approx -5.43 \\text{m}\\ .\n\\end{eqnarray}\\]\nThe center of mass, \\((x=1.72, y=-5.43)\\), is plotted as \\(\\color{blue}{\\Large\\mathbf{\\text{+}}}\\) on the object.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Mechanics</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#angular-momentum-and-torque",
    "href": "Manifestations/B4-mechanics.html#angular-momentum-and-torque",
    "title": "53  Mechanics",
    "section": "53.5 Angular momentum and torque",
    "text": "53.5 Angular momentum and torque\nThe relationship between force and momentum is familiar: \\[F = \\partial_t\\, m\\, v =\\ \\underbrace{m \\ \\partial_t\\  v}_\\text{if mass is constant}\\ .\\] Of course, the derivative of velocity with respect to time is also called “acceleration.”\nConsider the following situation. A space probe is being acted on by a constant force, as in ?fig-probe-constant. The mass of the probe is \\(m\\), the thrust from the rocket engine provides the force \\(F\\). Starting from velocity \\(\\partial_t y(t=0)\\) and position \\(y(t=0) = 0\\), the thrust produces an acceleration \\(\\partial_{tt} y(t) = F/m\\). Integrating the acceleration gives the velocity as a function of time \\[\\partial_t y(t) = \\frac{F}{m} t + C\\ .\\] ::: {#fig-probe-constant} \nA space probe accelerating along a linear course. The position at time \\(t\\) can be written as \\(y(t)\\) or as \\(\\theta(t)\\). :::\nThe function \\(y(t)\\) is not the only way to represent where the probe is as a function of \\(t\\). Suppose that the probe is being observed by a telescope which measures the angle \\(\\theta(t)\\) with respect to the equatorial plane. If the distance to the probe is \\(D(t)\\), then the pair \\(\\left(\\strut\\theta(t), D(t)\\right)\\) gives the position of the probe. As \\(y(t)\\) increases, so do \\(\\theta(t)\\) and \\(D(t)\\).\nWe know the laws of motion in terms of \\(y(t)\\). Can we translate these laws to an expression in terms of \\(\\theta(t)\\) and \\(D(t)\\)? That is, can we find the function \\[\\partial_{t} \\theta(t) = {\\Large ?}\\] If we can find the laws of motion in terms of \\(\\theta(t)\\) and \\(D(t)\\), we will have a way to describe the motion of spinning bodies.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 53.11: A space probe (orange) accelerating in a straight line, but observed as a change in angle \\(\\theta\\) seen from a planet (green).\n\n\n\nThe derivation of \\(\\partial_{t} \\theta(t)\\) will not be obvious, but you will be able to see how calculus operations come into play.\nThree points in the diagram describe a right triangle: the probe’s position at \\(t=0\\), the center of the planet, and the probe’s position at time \\(t\\). The length of the horizontal leg of the triangle is \\(D(t=0)\\) which not a function of time, so we will drop the unnecessary parentheses and write it as \\(D_0\\). The vertical leg has length \\(y(t)\\), and the hypotenuse has length \\(D(t)\\). The Pythagorean theorem tells us that \\[D(t)^2 = y(t)^2 + D_0^2\\ .\\]\nStep 1: Differentiate both sides with respect to \\(t\\): \\[\\partial_t \\left[\\strut D(t)^2\\right] = \\partial_t \\left[\\strut y(t)^2\\right] \\ . \\] Using the chain rule and the fact that \\(D_0\\) does not depend on \\(t\\), gives \\[2\\, D(t)\\, \\partial_t D(t) = 2\\, y(t)\\ \\partial_t y(t)\\ \\ \\implies\\ \\ \\partial_t y(t) = \\frac{D(t)}{y(t)}\\,\\partial_t D(t)\\ .\\]\nStep 2: Trigonometry allows us to see a relationship among the functions \\(y(t)\\), \\(\\theta(t)\\), and \\(D(t)\\):\n\\[y(t) = D(t) \\sin\\left(\\strut\\theta(t)\\right) \\ .\\] Plugging this form of \\(y(t)\\) into the equation for \\(\\partial_t y(t)\\) in Step 1 produces \\[\\partial_t y(t) = \\frac{1}{\\sin(\\theta(t))} \\partial_t D(t)\\] and \\[D_0 = D(t) \\cos\\left(\\strut\\theta(t)\\right)\\ \\ \\implies\\ \\ D(t) = \\frac{D_0}{\\cos\\left(\\strut\\theta(t)\\right)}\\]\nStep 3: Another fact from trigonometry is that \\[D(t) = D_0/\\cos(\\theta(t))\\ .\\] Differentiating both sides (chain rule again!) with respect to \\(t\\) gives another form for \\(\\partial_t D(t)\\): \\[\\partial_t D(t) = D_0\\, \\partial_t \\left(\\frac{1}{\\cos\\left(\\strut\\theta(t)\\right)}\\right) = D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\]\nStep 4: Combining the results from Steps 1 and 3 gives \\[\\partial_t y(t) =  \\frac{1}{\\sin\\left(\\strut\\theta(t)\\right)}D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\ .\\] Cancelling out the \\(\\sin(\\theta(t))\\) terms and remembering that \\(\\partial_t y(t) = \\frac{F}{m} t\\) gives\n\\[\\frac{F}{m} t = \\frac{D_0}{\\cos\\left(\\strut \\theta(t)\\right)^2}\\, \\partial_t\\theta(t) \\] Multiplying both sides by \\(D_0\\) and recalling that \\(D(t) = D_0/\\cos(\\theta(t))\\) we arrive at \\[\\frac{F D_0}{m} t = \\frac{D_0^2}{\\cos\\left(\\strut \\theta(t)\\right)^2}\\, \\partial_t\\theta(t) = D(t)^2 \\partial_t \\theta(t)\\ . \\]\nAgain re-arranging to find \\(\\partial_t\\, \\theta(t)\\): \\[\\partial_t\\,\\theta(t) = \\frac{F\\, D_0}{m D(t)^2}\\ t\\ .\\]\nTo summarize, we have two equivalent expressions for the dynamics of the space probe:\n\\[\\partial_t y(t) = \\frac{\\overbrace{\\ F}^\\text{force}}{\\underbrace{M}_\\text{mass}} t \\ \\ \\text{and}\\ \\ \\partial_t \\theta(t) = \\frac{\\overbrace{F\\, D_0}^\\text{torque}}{\\underbrace{m D(t)^2}_\\text{moment of inertia}}\\ t\\ .\\] In rectangular \\((x,y)\\) coordinates, the velocity is the accumulation of force divided by mass: the usual statement of Newton’s second law of motion. In the angular coordinates \\((\\theta, D)\\) the angular velocity is the accumulation of torque divided by ***moment of inertia.\nThe angular coordinate representation is helpful when studying the rotation of objects. To illustrate, imagine a different configuration for the system than that in in ?fig-probe-constant where the space probe was free to accelerate in a straight line. Instead, suppose the rocket is mounted on a carousel, that is a wheel whose axle goes through the center as in Figure 53.12.\n\n\n\n\n\n\nFigure 53.12: The space probe mounted on a rigid wheel that can spin around its center.\n\n\n\nIn the rocket-on-wheel configuration, \\(D(t)\\) is a constant; the rocket stays the same distance from the center. Therefore, the moment of inertia is \\(m D_0^2\\). Following the previous formula, \\[\\partial_t \\theta(t) = \\frac{F D_0}{m D_0^2} t\\] which is easily differentiated to give the angular acceleration \\[\\partial_{tt} \\theta(t) = \\frac{F D_0}{m D_0^2}\\ .\\]\nIn a typical wheel, there is mass density throughout the wheel, not just at distance \\(D_0\\). To find the moment of inertia of such a distributed mass system, break the wheel down into small pieces and find the moment of inertia due to each bit. Then accumulate the pieces’ moments of inertia to find the total moment of inertia:\n\\[\\text{moment of inertia} = \\int_\\text{wheel} \\rho(x,y) \\left(\\strut x^2 + y^2\\right) d \\text{wheel}\\ .\\]\n\n\n\n\n\n\n\n\nTry it! 53.2\n\n\n\n\n\n\n\n\n\nTry it! 53.2 Calculating the moment of inertia\n\n\n\nCompute the moment of inertia of Blob1.\nIt is not enough to say, “compute the moment of inertia.” We also have to specify what is the reference location—the wheel axle in the configuration. We will first do the calculation around the center of mass \\((\\bar{x}, \\bar{y})\\) which we computed earlier as xbar and ybar. (Make sure you have run the code in Interactive R chunks 53.2 and 53.1 before running this code.)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Mechanics</span>"
    ]
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#footnotes",
    "href": "Manifestations/B4-mechanics.html#footnotes",
    "title": "53  Mechanics",
    "section": "",
    "text": "Source: Jeff Dahl, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=3235265↩︎\nSource: https://commons.wikimedia.org/wiki/File:Geared_Turbofan_NT.PNG↩︎",
    "crumbs": [
      "BLOCK VI. Manifestations",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Mechanics</span>"
    ]
  },
  {
    "objectID": "Modeling/08-parameters.html",
    "href": "Modeling/08-parameters.html",
    "title": "8  Parameters",
    "section": "",
    "text": "8.1 Matching numbers to quantities\nThe coordinate axes in Figure 8.1 represent quantities. On the horizontal axis is time, measured in days. The vertical axis is denominated in “10000 cases,” meaning that the numbers on the vertical scale should be multiplied by 10000 to get the number of cases.\nThe exponential function takes as input a pure number and produces an output that is also a pure number. This is true for all the pattern-book functions. Since the graph axes don’t show pure numbers, it is no surprise then that the pattern-book exponential function doesn’t align with the COVID case data.\nIf we want the input to the model function \\(\\text{cases}(t)\\) to be denominated in days, we will have to convert \\(t\\) to a pure pure number (e.g. 10, not “10 days”) before the quantity is handed off as the argument to \\(\\exp()\\). We do this by introducing a parameter.\nThe standard parameterization for the exponential function is \\(e^{kt}\\). The parameter \\(k\\) will be a quantity with units of “per-day.” Suppose we set \\(k=0.2\\) per day. Then \\(k\\, t{\\LARGE\\left.\\right|}_{t=10 days} = 2\\). This “2” is a pure number because the units on the 0.2 (“per day”) and on the 10 (days) cancel out: \\[0.2\\, \\text{day}^{-1} \\cdot 10\\, \\text{days} = 2\\ .\\] The use of a parameter like \\(k\\) does more than handle the formality of converting input quantities into pure numbers. Having a choice for \\(k\\) allows us to stretch or compress the function to align with the data. Figure 8.2 plots the modeling version of the exponential function to the COVID-case data:\nFigure 8.2: Using the function form \\(A e^{kt}\\) with parameters \\(k=0.19\\) per day and \\(A = 0.0573\\) cases (in 10000s) matches the COVID-case data well.",
    "crumbs": [
      "BLOCK I. Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Parameters</span>"
    ]
  },
  {
    "objectID": "Modeling/08-parameters.html#matching-numbers-to-quantities",
    "href": "Modeling/08-parameters.html#matching-numbers-to-quantities",
    "title": "8  Parameters",
    "section": "",
    "text": "Recall that pure numbers, like 17.32, do not have units. Quantities, on the other hand, usually do have units, as in 17.3 days or 34 meters.\n\nIn every case, these parameters are arranged to translate a with-units quantity into a pure number suitable as an input to the pattern-book function. Similarly, parameters will translate the pure-number output from the pattern-book function into a quantity with units.",
    "crumbs": [
      "BLOCK I. Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Parameters</span>"
    ]
  },
  {
    "objectID": "Modeling/08-parameters.html#parallel-scales",
    "href": "Modeling/08-parameters.html#parallel-scales",
    "title": "8  Parameters",
    "section": "8.2 Parallel scales",
    "text": "8.2 Parallel scales\nAt the heart of how we use the pattern-book functions to model the relationship between quantities is the idea of conversion between one scale and another. Consider these everyday objects: a thermometer and a ruler.\n\n\n\n\n\n\n\n\n\n\n\n(a) A thermometer\n\n\n\n\n\n\n\n\n\n\n\n(b) A ruler\n\n\n\n\n\n\n\nFigure 8.3: Two everyday objects that facilitate conversion from one scale to another.\n\n\n\nEach object presents a read-out of what’s being measured—temperature or length—on two different scales. At the same time, the objects provide a way to convert one scale to another.\nA function gives the output for any given input. We represent the input value as a position on a number line—which we call an “axis”—and the output as a position on another output line, almost always drawn perpendicular to one another. But the two number lines can just as well be parallel to one another. To evaluate the function, find the input value on the input scale and read off the corresponding output.\nWe can translate the correspondance between one scale and the other into the form of a straight-line function. For instance, if we know the temperature in Fahrenheit (\\(^\\circ\\)F) and want to convert it to Celsius (\\(^\\circ C\\)) we have the following function: \\[C(F) \\equiv {\\small\\frac{5}{9}}(F-32)\\ .\\] Similarly, converting inches to centimeters can be accomplished with \\[\\text{cm(inches)} \\equiv 2.54 \\, (\\text{inches}-0)\\ .\\] Both of these scale conversion functions have the form of the straight-line function, which can be written as \\[f(x) \\equiv a x + b\\ \\ \\ \\text{or, equivalently as}\\ \\ \\ \\ f(x) \\equiv a(x-x_0)\\ ,\\] where \\(a\\), \\(b\\), and \\(x_0\\) are parameters.\nIn Section 8.3, we will use the \\(ax + b\\) form of scale conversion, to scale the input to pattern-book functions, but we could equally well have used \\(a(x-x_0)\\).\nIn Section 8.4 we will introduce a second scale conversion function, for the output from pattern-book functions. That scaling will also be in the form of a straight-line function: \\(A x + B\\). The use of the lower-case parameter names (\\(a\\), \\(b\\)) versus the upper-case parameter names (\\(A\\), \\(B\\)) will help us distinguish the two different uses for scale conversion, namely input scaling versus output scaling.",
    "crumbs": [
      "BLOCK I. Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Parameters</span>"
    ]
  },
  {
    "objectID": "Modeling/08-parameters.html#sec-input-scaling",
    "href": "Modeling/08-parameters.html#sec-input-scaling",
    "title": "8  Parameters",
    "section": "8.3 Input scaling",
    "text": "8.3 Input scaling\nFigure 8.4 is based on the data frame RI-tide, a minute-by-minute record of the tide level in Providence, Rhode Island (USA) for the period April 1 to 5, 2010. The level variable is measured in meters; the hour variable gives the time of the measurement in hours after midnight at the start of April 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8.4: Tide levels oscillate up and down over time. This is analogous to the \\(\\\\sin(t)\\) pattern-book function.\n\n\n\nThe pattern-book \\(\\sin()\\) and the function \\(\\color{magenta}{\\text{level}}\\color{blue}{(hour)}\\) have similar shapes, so it seems reasonable to model the tide data as a sinusoid. However, the scale of the axes is different on the two graphs.\nTo model the tide with a sinusoid, we need to modify the sinusoid to change the scale of the input and output. First, let’s look at how to accomplish the input scaling. Specifically, we want the pure-number input \\(t\\) to the sinusoid be a function of the quantity \\(hour\\). Our framework for this re-scaling is the straight-line function. We will replace the pattern-book input \\(t\\) with a function \\[t(\\color{blue}{hour}) \\equiv a\\, \\color{blue}{hour} + b\\ .\\]\nThe challenge is to find values for the parameters \\(a\\) and \\(b\\) that will transform the \\(\\color{blue}{\\mathbf{\\text{blue}}}\\) horizontal axis into the black horizontal axis, like this:\n\n\n\n\n\n\n\n\n\nBy comparing the two axes, we can estimate that \\(\\color{blue}{10} \\rightarrow 4\\) and \\(\\color{blue}{100} \\rightarrow 49\\). With these two coordinate points, we can find the straight-line function that turns \\(\\color{blue}{\\mathbf{\\text{blue}}}\\) into black by plotting the coordinate pairs \\((\\color{blue}{0},1)\\) and \\((\\color{blue}{100}, 51)\\) and finding the straight-line function that connects the points.\n\n\n\n\n\n\n\n\nFigure 8.5: The input scaling function must transform 10 into 4 and transform 100 into 49 to properly arrange the time scale with the scale for the pattern-book function.\n\n\n\n\n\nYou can calculate for yourself that the function that relates \\(\\color{blue}{\\mathbf{\\text{blue}}}\\) to black is \\[t(\\color{blue}{time}) = \\underbrace{\\frac{1}{2}}_a \\color{blue}{time}  \\underbrace{-1\\LARGE\\strut}_b\\]\nReplacing the pure number \\(t\\) as the input to pattern-book \\(\\sin(t)\\) with the transformed \\(\\frac{1}{2} \\color{blue}{time}\\) we get a new function: \\[g(\\color{blue}{time}) \\equiv \\sin\\left(\\strut {\\small\\frac{1}{2}}\\color{blue}{time} - 1\\right)\\ .\\] Figure 11.6 plots \\(g()\\) along with the actual tide data.\n\n\n\n\n\n\n\n\nFigure 8.6: The sinusoid with input scaling (black) aligns nicely with the tide-level data.",
    "crumbs": [
      "BLOCK I. Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Parameters</span>"
    ]
  },
  {
    "objectID": "Modeling/08-parameters.html#sec-output-scaling",
    "href": "Modeling/08-parameters.html#sec-output-scaling",
    "title": "8  Parameters",
    "section": "8.4 Output scaling",
    "text": "8.4 Output scaling\nJust as the natural input needs to be scaled before it reaches the pattern-book function, so the output from the pattern-book function needs to be scaled before it presents a result suited for interpreting in the real world.\n\n\n\n\n\n\nFigure 8.7: Natural quantities must be scaled to pure numbers before being suited to the pattern-book functions. The output from the pattern-book function is a pure number which is scaled to the natural quantity of interest.\n\n\n\nThe overall result of input and output scaling is to tailor the pattern-book function so that it is ready to be used in the real world.\nLet’s return to Figure 11.6 which shows that the function \\(g(\\color{blue}{time})\\), which scales the input to the pattern-book sinusoid, has a much better alignment to the tide data. Still, the vertical axes of the two graphs in the figure are not the same.\nThis is the job for output scaling, which takes the output of \\(g(\\color{blue}{time})\\) (bottom graph) and scales it to match the \\(\\color{magenta}{level}\\) axis on the top graph. That is, we seek to align the black vertical scale with the \\(\\color{magenta}{\\mathbf{\\text{magenta}}}\\) vertical scale. To do this, we note that the range of the \\(g(\\color{blue}{time})\\) is -1 to 1, whereas the range of the tide-level is about 0.5 to 1.5. The output scaling will take the straight-line form \\[{\\color{magenta}{\\text{level}}}({\\color{blue}{time}}) = A\\, g({\\color{blue}{time}}) + B\\] or, in graphical terms\n\n\n\n\n\n\n\n\n\nWe can figure out parameters \\(A\\) and \\(B\\) by finding the straight-line function that connects the coordinate pairs \\((-1, \\color{magenta}{0.5})\\) and \\((1, \\color{magenta}{1.5})\\) as in Figure 8.8.\n\n\n\n\n\n\n\n\nFigure 8.8: Finding the straight-line function that converts \\(-1 \\rightarrow \\color{magenta}{0.5}\\) and converts \\(1 \\rightarrow \\color{magenta}{1.5}\\)\n\n\n\n\n\nYou can confirm for yourself that the function that does the job is \\[{\\color{magenta}{\\text{level}}} = 0.5 g({\\color{blue}{time}}) + 1\\ .\\]\nPutting everything together, that is, scaling both the input to pattern-book \\(\\sin()\\) and the output from pattern-book \\(\\sin()\\), we get\n\\[{\\color{magenta}{\\text{level}}}({\\color{blue}{time}}) = \\underbrace{0.5}_A \\sin\\left(\\underbrace{\\small\\frac{1}{2}}_a {\\color{blue}{time}}  \\underbrace{-1}_b\\right) + \\underbrace{1}_B\\]",
    "crumbs": [
      "BLOCK I. Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Parameters</span>"
    ]
  },
  {
    "objectID": "Modeling/08-parameters.html#a-procedure-for-building-models",
    "href": "Modeling/08-parameters.html#a-procedure-for-building-models",
    "title": "8  Parameters",
    "section": "8.5 A procedure for building models",
    "text": "8.5 A procedure for building models\nWe’ve been using pattern-book functions as the intermediaries between input scaling and output scaling, using this format.\n\\[f(x) \\equiv A e^{ax + b} + B\\ .\\] We can use the other pattern-book functions—the gaussian, the sigmoid, the logarithm, the power-law functions—in the same way. That is, the basic framework for modeling is this:\n\\[\\text{model}(x) \\equiv A\\, {g_{pattern\\_book}}(ax + b) + B\\ ,\\] where \\(g_{pattern\\_book}()\\) is one of the pattern-book functions. To construct a basic model, you task has two parts:\n\nPick the specific pattern-book function whose shape resembles that of the relationship you are trying to model. For instance, we picked \\(e^x\\) for modeling COVID cases versus time (at the start of the pandemic). We picked \\(\\sin(x)\\) for modeling tide levels versus time.\nFind numerical values for the parameters \\(A\\), \\(B\\), \\(a\\), and \\(b\\). In Chapter 11 shows some ways to make this part of the task easier.\n\nIt is remarkable that models of a very wide range of real-world relationships between pairs of quantities can be constructed by picking one of a handful of functions, then scaling the input and the output. As we move on to other Blocks in MOSAIC Calculus, you will see how to generalize this to potentially complicated relationships among more than two quantities. That is a big part of the reason you’re studying calculus.",
    "crumbs": [
      "BLOCK I. Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Parameters</span>"
    ]
  },
  {
    "objectID": "Modeling/08-parameters.html#other-formats-for-scaling",
    "href": "Modeling/08-parameters.html#other-formats-for-scaling",
    "title": "8  Parameters",
    "section": "8.6 Other formats for scaling",
    "text": "8.6 Other formats for scaling\nOften, modelers choose to use input scaling in the form \\(a (x - x_0)\\) rather than \\(a x + b\\). The two are completely equivalent when \\(x_0 = - b/a\\). The choice between the two forms is largely a matter of convention. But almost always the output scaling is written in the format \\(A y + B\\).\n\nApplication area 8.1 —Shifting an exponential horizontally is the same as scaling vertically.\n\n\n\n\n\n\n\nApplication area 8.1 The start of COVID\n\n\n\nFor the COVID case-number data shown in Figure 8.2, we found that a reasonable match to the data can be had by input- and output-scaling the exponential: \\[\\text{cases}(t) \\equiv  \\underbrace{573}_A e^{\\underbrace{0.19}_a\\ t}\\ .\\]\nYou might wonder why the parameters \\(B\\) and \\(b\\) aren’t included in the model. One reason is that cases and the exponential function already have the same range: zero and upwards. So there is no need to shift the output with a parameter B.\nAnother reason has to do with the algebraic properties of the exponential function. Specifically, \\[e^{a x + b}= e^b e^{ax} = {\\cal A} e^{ax}\\] where \\({\\cal A} \\equiv e^b\\).\nIn the case of exponentials, writing the input scaling in the form \\(e^{a(x-x_0)}\\) can provide additional insight.\nA bit of symbolic manipulation of the model can provide some additional insight. As you know, the properties of exponentials and logarithms are such that \\[A e^{at} = e^{\\lb(A)} e^{at} = e^{a t + \\ln(A)} = e^{a\\left(\\strut t + \\lb(A)/a\\right)} = e^{a(t-t_0)}\\ ,\\] where \\[t_0 = - \\ln(A)/a = - \\ln(593)/0.19 = -33.6\\ .\\] You can interpret \\(t_0\\) as the starting point of the pandemic. When \\(t = t_0\\), the model output is \\(e^{k 0} = 1\\): the first case. According to the parameters we matched to the data for March, the pandemic’s first case would have happened about 33 days before March 1, which is late January. We know from other sources of information, the outbreak began in late January. It is remarkable that even though the curve was constructed without any data from January or even February, the data from March, translated through the curve-fitting process, pointed to the start of the outbreak. This is a good indication that the exponential form for the model is fundamentally correct.",
    "crumbs": [
      "BLOCK I. Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Parameters</span>"
    ]
  },
  {
    "objectID": "Modeling/08-parameters.html#parameterization-conventions",
    "href": "Modeling/08-parameters.html#parameterization-conventions",
    "title": "8  Parameters",
    "section": "8.7 Parameterization conventions",
    "text": "8.7 Parameterization conventions\nThere are conventions for the symbols used for input-scaling parameterization of the pattern-book functions. Knowing these conventions makes it easier to read and assimilate mathematical formulas. In several cases, there is more than one conventional option. For instance, the sinusoid has a variety of parameterization forms that get used depending on which feature of the function is easiest to measure. Table 8.1 list several that are frequently used in practice.\n\n\n\nTable 8.1: Some standard forms of input scaling parameterizations\n\n\n\n\n\n\n\n\n\n\n\nFunction\nWritten form\nParameter 1\nParameter 2\n\n\n\n\nExponential\n\\(e^{kt}\\)\n\\(k\\)\nNot used\n\n\nExponential\n\\(e^{t/\\tau}\\)\n\\(\\tau\\) “time constant”\nNot used\n\n\nExponential\n\\(2^{t/\\tau_2}\\)\n\\(\\tau_2\\) “doubling time”\nNot used\n\n\nExponential\n\\(2^{-\\tau_{1/2}}\\)\n\\(-\\tau_{1/2}\\) “half life”\nNot used\n\n\nPower-law\n\\([x - x_0]^p\\)\n\\(x_0\\) x-intercept\nexponent\n\n\nSinusoid\n\\(\\sin\\left(\\frac{2 \\pi}{P} (t-t_0)\\right)\\)\n\\(P\\) “period”\n\\(t_0\\) “time shift”\n\n\nSinusoid\n\\(\\sin(\\omega t + \\phi)\\)\n\\(\\omega\\) “angular frequency”\n\\(\\phi\\) “phase shift”\n\n\nSinusoid\n\\(\\sin(2 \\pi \\omega t + \\phi)\\)\n\\(\\omega\\) “frequency”\n\\(\\phi\\) “phase shift”\n\n\nGaussian\ndnorm(x, mean, sd)\n“mean” (center)\nsd “standard deviation”\n\n\nSigmoid\npnorm(x, mean, sd)\n“mean” (center)\nsd “standard deviation”\n\n\nStraight-line\n\\(mx + b\\)\n\\(m\\) “slope”\n\\(b\\) “y-intercept”\n\n\nStraight-line\n\\(m (x-x_0)\\)\n\\(m\\) “slope”\n\\(x_0\\) “center”",
    "crumbs": [
      "BLOCK I. Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Parameters</span>"
    ]
  },
  {
    "objectID": "Accumulation/33-intro.html",
    "href": "Accumulation/33-intro.html",
    "title": "34  Change & accumulation",
    "section": "",
    "text": "34.1 Accumulation\nImagine a simple setting: water flowing out of a tap into a basin or tank. The amount of water in the basin will be measured in a unit of volume, say liters. Measurement of the flow \\(f(t)\\) of water from the tap into the tank has different units, say liters per second. If volume \\(V(t)\\) is the volume of water in the tank as a function of time, \\(f(t)\\) at any instant is \\(f(t) = \\partial_t V(t)\\).\nThere is a relationship between the two functions \\(f(t)\\) and \\(V(t)\\). With derivatives, we can give a good description of that relationship: \\[f(t) = \\partial_t V(t)\\] This description will be informative if we have measured the volume of water in the basin as a function of time and want to deduce the rate of flow from the tap. Now suppose we have measured the flow \\(f(t)\\) and want to figure out the volume. The volume at any instant is the past flow accumulated to that instant. As a matter of notation, we write this view of the relationship as \\[V(t) = \\int f(t) dt,\\] which you can read as “volume is the accumulated flow.”\nOther examples of accumulation and change:",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Change & accumulation</span>"
    ]
  },
  {
    "objectID": "Accumulation/33-intro.html#accumulation",
    "href": "Accumulation/33-intro.html#accumulation",
    "title": "34  Change & accumulation",
    "section": "",
    "text": "velocity is the rate of change of position with respect to time. Likewise, position is the accumulation of velocity over time.\nforce is the rate of energy with respect to position. Likewise energy is the accumulation of force as position changes.\ndeficit is the rate of change of debt with respect to time. Likewise, debt is the accumulation of deficit over time.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Change & accumulation</span>"
    ]
  },
  {
    "objectID": "Accumulation/33-intro.html#notation-for-anti-differentiation",
    "href": "Accumulation/33-intro.html#notation-for-anti-differentiation",
    "title": "34  Change & accumulation",
    "section": "34.2 Notation for anti-differentiation",
    "text": "34.2 Notation for anti-differentiation\nFor differentiation we are using the notation \\(\\partial_x\\) as in \\(\\partial_x f(x)\\). Remember that the subscript on \\(\\partial\\) names the with-respect-to input. There are three pieces of information this notation:\n\nThe \\(\\color{magenta}{\\partial}\\) symbol which identifies the operation as partial differentiation.\nThe name of the with-respect-to input \\(\\partial_{\\color{magenta}{x}}\\) written as a subscript to \\(\\partial\\).\nThe function to be differentiated, \\(\\partial_x \\color{magenta}{f(x)}\\).\n\nFor anti-differentiation, our notation must also specify the three pieces of information. It might be tempting to use the same notation as differentiation but replace the \\(\\partial\\) symbol with something else, perhaps \\(\\eth\\) or \\(\\spadesuit\\) or \\(\\forall\\), giving us something like \\(\\spadesuit_x f(x)\\).\nConvention has something different in store. The notation for anti-differentiation is \\[\\large \\int f(x) dx\\] 1. The \\(\\color{magenta}{\\int}\\) is the marker for anti-differentiation. 2. The name of the with-respect-to input is contained in the “dx” at the end of the notation: \\(\\int f(x) d\\color{magenta}{x}\\) 3. The function being anti-differentiated is in the middle \\(\\int \\color{magenta}{f(x)} dx\\).\nFor those starting out with anti-differentiation, the conventional notation can be confusing, especially the \\(dx\\) part. It is easy confuse \\(d\\) for a constant and \\(x\\) for part of the function being anti-differentiated.\nThink of the \\(\\int\\) and the \\(dx\\) as brackets around the function. You need both brackets for correct notation, the \\(\\int\\) and the \\(dx\\) together telling you what operation to perform.\nRemember that just as \\(\\partial_x f(x)\\) is a function, so is \\(\\int f(x) dx\\).",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Change & accumulation</span>"
    ]
  },
  {
    "objectID": "Accumulation/33-intro.html#rmosaic-notation",
    "href": "Accumulation/33-intro.html#rmosaic-notation",
    "title": "34  Change & accumulation",
    "section": "34.3 R/mosaic notation",
    "text": "34.3 R/mosaic notation\nRecall that the notation for differentiation in R/mosaic is D(f(x) ~ x). The R/mosaic notation for anti-differentiation is very similar:\nD(f(x) ~ x)\nThis has the same three pieces of information as \\(\\partial_x f(x)\\)\n\nD() signifies differentiation whereas antiD() signifies anti-differentiation.\n~ x identifies the with-respect-to input.\nf(x) ~ is the function on which the operation is to be performed.\n\nRemember that just as D(f(x) ~ x) creates a new function out of f(x) ~ x, so does antiD(f(x) ~ x).",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Change & accumulation</span>"
    ]
  },
  {
    "objectID": "Accumulation/33-intro.html#dimension-and-anti-differentiation",
    "href": "Accumulation/33-intro.html#dimension-and-anti-differentiation",
    "title": "34  Change & accumulation",
    "section": "34.4 Dimension and anti-differentiation",
    "text": "34.4 Dimension and anti-differentiation\nThis entire block will be about anti-differentiation, its properties and its uses. You already know that anti-differentiation (as the name suggests) is the inverse of differentiation. There is one consequence of this that is helpful to keep in mind as we move on to other chapters. This being calculus, the functions that we construct and operate upon have inputs that are quantities and outputs that are also quantities. Every quantity has a dimension, as discussed in Chapter 15. When you are working with any quantity, you should be sure that you know its dimension and its units.\nThe dimension of the input to a function does not by any means have to be the same as the dimension of the output. For instance, we have been using many functions where the input has dimension time and the output is position (dimension L) or velocity (dimension L/T) or acceleration (dimension L/T\\(^2\\)).\nImagine working with some function \\(f(y)\\) that is relevant to some modeling project of interest to you. Returning to the bracket notation that we used in Chapter 15, the dimension of the input quantity will be [\\(y\\)]. The dimension of the output quantity is [\\(f(y)\\)]. (Remember from 16 that [\\(y\\)] means “the dimension of quantity \\(y\\)” and that [\\(f(y)\\)] means “the dimension of the output from \\(f(y)\\).”)\nThe function \\(\\partial_y f(y)\\) has the same input dimension \\([y]\\) but the output will be \\([f(y)] / [y]\\). For example, suppose \\(f(y)\\) is the mass of fuel in a rocket as a function of time \\(y\\). The output of \\(f(y)\\) has dimension M. The input dimension \\([y]\\) is T.\nThe output of the function \\(\\partial_y f(y)\\) has dimension \\([f(y)] / [y]\\), which in this case will be M / T. (Less abstractly, if the fuel mass is given in kg, and time is measured in seconds, then \\(\\partial_y f(y)\\) will have units of kg-per-second.)\nHow about the dimension of the anti-derivative \\(F(y) = \\int f(y) dy\\)? Since \\(F(y)\\) is the anti-derivative of \\(f(y)\\) (with respect to \\(y\\)), we know that \\(\\partial_y F(y) = f(y)\\). Taking the dimension of both sides \\[[\\partial_y F(y)] = \\frac{[F(y)]}{[y]} = \\frac{[F(y)]}{\\text{T}} = [f(y)] = \\text{M}\\] Consequently, \\([F(y)] = \\text{M}\\).\nTo summarize:\n\nThe dimension of derivative \\(\\partial_y f(y)\\) will be \\([f(y)] / [y]\\).\nThe dimension of the anti-derivative \\(\\int f(y) dy\\) will be \\([f(y)]\\times [y]\\).\n\nOr, more concisely:\n\nDifferentiation is like division, anti-differentiation is like multiplication.\n\nPaying attention to the dimensions (and units!) of input and output can be a boon to the calculus student. Often students have some function \\(f(y)\\) and they are wondering which of the several calculus operations they are supposed to do: differentiation, anti-differentiation, finding a maximum, finding an argmax or a zero. Start by figuring out the dimension of the quantity you want. From that, you can often figure out which operation is appropriate.\nTo illustrate, imagine that you have constructed \\(f(y)\\) for your task and you know, say, \\[[f(y)] = \\text{M       and} \\  \\ \\ \\ \\ [y] = \\text{T}\\ .\\] Look things up in the following table:\n\n\n\nDimension of result\nCalculus operation\n\n\n\n\nM / T\ndifferentiate\n\n\nM T\nanti-differentiate\n\n\nM\nfind max or min\n\n\nT\nfind argmax/argmin or a function zero\n\n\nM T\\(^2\\)\nanti-differentiate twice in succession\n\n\nM / T\\(^2\\)\ndifferentiate twice in succession\n\n\n\nFor example, suppose the output of the accelerometer on your rocket has dimension L / T\\(^2\\). You are trying to figure out from the accelerometer reading what is your altitude. Altitude has dimension L. Look up in the table to see that you want to anti-differentiate acceleration twice in succession.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Change & accumulation</span>"
    ]
  },
  {
    "objectID": "Accumulation/33-intro.html#sec-preliminary-terrors",
    "href": "Accumulation/33-intro.html#sec-preliminary-terrors",
    "title": "34  Change & accumulation",
    "section": "34.5 From Calculus Made Easy",
    "text": "34.5 From Calculus Made Easy\nCalculus Made Easy, by Silvanus P. Thompson, is a classic, concise, and elegant textbook from 1910. It takes a common-sense approach, sometimes lampooning the traditional approach to teaching calculus.\n\nSome calculus-tricks are quite easy. Some are enormously difficult. The fools who write the textbooks of advanced mathematics—and they are mostly clever fools—seldom take the trouble to show you how easy the easy calculations are. On the contrary, they seem to desire to impress you with their tremendous cleverness by going about it in the most difficult way. — From the preface\n\nThompson’s first chapter starts with the notation of accumulation, which he calls “the preliminary terror.”\n\nThe preliminary terror … can be abolished once for all by simply stating what is the meaning—in common-sense terms—of the two principal symbols that are used in calculating.\nThese dreadful symbols are:\n\n\\(\\Large\\  d\\) which merely means “a little bit of.”\n\nThus \\(dx\\) means a little bit of \\(x\\); or \\(du\\) means a little bit of \\(u\\). Ordinary mathematicians think it more polite to say “an element of,” instead of “a little bit of.” Just as you please. But you will find that these little bits (or elements) may be considered to be indefinitely small.\n\n\\(\\ \\ \\large\\int\\) which is merely a long \\(S\\), and may be called (if you like) “the sum of.”\n\nThus \\(\\ \\int dx\\) means the sum of all the little bits of \\(x\\); or \\(\\ \\int dt\\) means the sum of all the little bits of \\(t\\). Ordinary mathematicians call this symbol “the integral of.” Now any fool can see that if \\(x\\) is considered as made up of a lot of little bits, each of which is called \\(dx\\), if you add them all up together you get the sum of all the \\(dx\\)’s, (which is the same thing as the whole of \\(x\\)). The word “integral” simply means “the whole.” If you think of the duration of time for one hour, you may (if you like) think of it as cut up into \\(3600\\) little bits called seconds. The whole of the \\(3600\\) little bits added up together make one hour.\nWhen you see an expression that begins with this terrifying symbol, you will henceforth know that it is put there merely to give you instructions that you are now to perform the operation (if you can) of totaling up all the little bits that are indicated by the symbols that follow.\n\n\nThe next chapter shows what it means to “total up all the little bits” of a function.",
    "crumbs": [
      "BLOCK IV. Accumulation",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Change & accumulation</span>"
    ]
  }
]