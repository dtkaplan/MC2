# Low-order polynomials {#sec-low-order}

```{r include=FALSE}
source("../starter.R")
```

@sec-fitting-by-feature looked at the task of modifying a pattern-book function to display a desired pattern, focusing on patterns originating in graphs of data. The procedure involved identifying an appropriate pattern-book function, then using input and output scaling to stretch, flip, and lift that function so that it overlays, as much as possible, the desired pattern.

In this chapter, we will take on a different strategy for constructing appropriately shaped functions using linear combinations of a handful of simple functions: the monomials.

## Polynomials

Recall that the monomials are the power-law functions with non-negative, integer exponents: $x^0$, $x^1$, $x^2$, $x^3$, and so on. The "and so on" refers to even higher integer exponents such as $x^4$ or $x^{51}$ or $x^{213}$, to name but a few. The more common name for a linear combination of monomials is ***polynomial***. 

:::{.column-margin}
The first two terms in the polynomial $g(t)$ could be written using exponents, like this:
$$ g(t) \equiv a_0 t^0 + a_1 t^1 + \cdots$$
In practice, nobody writes out explicitly the $t^0$ function. Instead, recognizing that $t^0 = 1$, we write the first term simply as $a_0$. Similarly, rather than writing $t^1$ in the second term, we write $a_1 t$, without the exponent. This practice makes the formulas for polynomials more concise but at the cost of failing to remind the reader that all the functions in the linear combination are monomials.
:::

For instance, a fifth-order polynomial consists of a linear combination of monomials up to ***order*** 5. That is, up to $x^5$. This will have six terms because we count the order of the monomials starting with 0.
$$g(t) \equiv a_0 + a_1 t + a_2 t^2 + a_3 t^3 + a_4 t^4 + a_5 t^5\ .$$

The challenge in shaping a polynomial is to find the scalar multipliers---usually called ***coefficients*** when it comes to polynomials---that give us the shape we want. This might seem to be a daunting task, and it is for a human. But it can easily be handled using volumes of arithmetic, too much arithmetic for a human to take on but ideally suited for computing machines.

## Low-order polynomial models

Polynomials in general can show a wide variety of snake-like patterns. A fifth-order polynomial can have up to four internal curves. A tenth-order polynomial can have 9 internal curves, and so. There is, however, rarely a need for generating functions with all those curves. Instead, a great deal of modeling work can be accomplished with just first-order polynomials (no internal curves) or second-order polynomials (one internal curve). 

\begin{eqnarray}
\textbf{First-order: }\ \ \ \ \ & f_1(t) \equiv b_0 + b_1 t\\
\textbf{Second-order: }\ \ \ \ \ & f_2(t) \equiv c_0 + c_1 t + c_2 t^2
\end{eqnarray}

::: {.column-margin}
Note that we are using different names for the coefficients in each of the polynomial examples. The only significance of this is a reminder that each of the coefficients can be any number at all and isn't necessarily related to any of the other coefficients. In addition to the usual $a$, $b$, $c$, we've used the Greek alpha, beta, and gamma, that is $\alpha$, $\beta$, and $\gamma$. The subscript on the coefficient name indicates which term it belongs to. For instance, the coefficient on the $y^2$ term of the $h_c$ polynomial is named $\gamma_{yy}$ while the coefficient on the $x y$ term has the subscript $_{xy}$. Always, the coefficients are constant quantities and not functions of $x$ or any other input. 

In high-school mathematics, polynomials are often written without subscript, for instance $a x^2 + b x + c$. This can be fine when working with only one polynomial at a time, but in modeling we often need to compare multiple, related polynomials.
:::

You may prefer to think about a first-order polynomial as a straight-line function. Similarly, a second-order polynomial is also known as a "quadratic" or even a "parabola." Nonetheless, it is good to see them as polynomials distinguished by their order. This puts them into a general framework, all of which can be handled by the technology of linear combinations. And polynomials can also involve more than one input. For instance, here are three polynomial forms that involve inputs $x$ and $y$:



\begin{eqnarray}
h_a(x, y) &\equiv & \alpha_0 + \alpha_x\, x + \alpha_y\, y\\
h_b(x, y) &\equiv & \beta_0 + \beta_x\, x + \beta_y\, y + \beta_{xy}\, x y\\
h_c(x, y) &\equiv & \gamma_0 + \gamma_x\, x + \gamma_y\, y + \gamma_{xy}\, x y + \gamma_{xx}\, x^2 + \gamma_{yy}\, y^2
\end{eqnarray}

The reason to work with first- and second-order polynomials is rooted in the experience of modelers. Second-order polynomials provide a useful amount of flexibility while remaining simple and avoiding pitfalls.



## Eight simple shapes

An easy way to think about how to use low-order polynomials in modeling is to think about the shapes of their graphs. @fig-eight-simple-shapes shows eight simple shapes for functions with a single input that occur often in modeling.

```{r echo=FALSE, fig.show="keep"}
#| label: fig-eight-simple-shapes
#| out-width: "160%"
#| fig-width: 15
#| fig-height: 10
#| fig-pos: "h"
#| column: page-inset-right
#| fig-cap: "The ***eight simple shapes*** of functions with one input."
g <- makeFun(a + b*x + c*x^2 ~ x, a=-1, b=2, c=1)
Pa <- slice_plot(-g(x, c=0) ~ x, bounds(x=c(-3,1)), size=2  ) %>%
  gf_labs(y="", x="", subtitle="(A) downward sloping line")
Pb <- slice_plot(g(x, c=0) ~ x, bounds(x=c(-3,1)), size=2  ) %>%
  gf_labs(y="", x="", subtitle="(B) upward sloping line")
Pc <- slice_plot(g(x) ~ x, bounds(x=c(-3,-1)), size=2) %>%
  gf_labs(y="", x="", subtitle="(C) downward sloping, concave up; steep then shallow")
Pd <- slice_plot(g(x) ~ x, bounds(x=c(-1,1)), size=2) |> 
  gf_labs(y="", x="", subtitle="(D) upward sloping, concave up; shallow then steep")
Pe <- slice_plot(-g(x) ~ x, bounds(x=c(-3,-1)), size=2) |> 
  gf_labs(y="", x="", subtitle="(E) upward sloping, concave down; steep then shallow")
Pf <- slice_plot(-g(x) ~ x, bounds(x=c(-1,1)), size=2) %>%
  gf_labs(y="", x="", subtitle="(F) downward sloping, concave down; shallow then steep")
Pg <- slice_plot(g(x) ~ x, bounds(x=c(-3,1)), size=2) %>%
  gf_labs(y="", x="", subtitle="(G) local minimum")
Ph <- slice_plot(-g(x) ~ x, bounds(x=c(-3,1)), size=2) |> 
  gf_labs(y="", x="", subtitle="(H) local maximum")
gridExtra::grid.arrange(Pa, Pb, Pc, Pd, Pe, Pf, Pg, Ph, ncol=3)
```

Recall that @sec-describing-functions introduced terms such as concavity, monotonicity, and slope for describing functions. To choose among these shapes, consider your modeling context: 

- is the relationship positive (slopes up) or negative (slopes down)?
- is the relationship monotonic or not?
- is the relationship concave up, concave down, or neither?

Each of the eight simple shapes corresponds to a particular set of answers to these equations. Consider these modeling contexts as examples:

* How many minutes can you run as a function of speed? Concave down and downward sloping: Shape (F).  In everyday terms, you wear out faster if you run at high speed. 

* How much fuel is consumed by an aircraft as a function of distance? For long flights, the function is concave up and positive sloping: Shape (D).  In everyday terms: fuel use increases with distance, but the amount of fuel you have to carry also increases with distance. A heavy aircraft uses more fuel per mile.

* How far can you walk as a function of time? Steep-then-shallow and concave down: Shape (E). Your pace slows as you get tired.

* How does the stew taste as a function of saltiness? There is a local maximum: Shape (H). The taste improves as the amount of salt increases ... up to a point. Too much salt and the stew is unpalatable.
 

* The incidence of an out-of-control epidemic versus time is concave up, but shallow-then-steep. As the epidemic is brought under control, the decline is steep-then-shallow and concave up. Over the whole course of an epidemic, there is a maximum incidence. Experience shows that epidemics can have a phase where incidence reaches a local minimum: a decline as people practice social distancing followed by an increase as people become complacent. 

* In micro-economic theory there are ***production functions*** that describe how much of a good is produced at any given price, and ***demand functions*** that describe how much of the good will be purchased as a function of price. As a rule, production increases with price and demand decreases with price. 

- In the short term, production functions tend to be concave down, since it is hard to squeeze increased production out of existing facilities. Production functions are Shape (E).   
    - For demand in the short term, functions will be concave up when there is some group of consumers who have no other choice than to buy the product. Downward sloping and concave up: Shape (C).  In the long term, consumption functions can be concave down as consumers find alternatives to the high-priced good. For example, high prices of gasoline may, in the long term, prompt a switch to more efficient cars, hybrids, or electric vehicles. This will push demand down steeply.  

Remarkably, all the eight simple shapes can be generated by appropriate choices for the coefficients in a second-order polynomial: $g(x) = a_0 + a_1 x + a_2 x^2$. So long as $a_2 \neq 0$, the graph of the second-order polynomial will be a parabola. 

- The parabola opens upward if $0 < a_2$. That is the shape of a ***local minimum***.
- The parabola opens downward if $a_2 < 0$. That is the shape of a ***local maximum***

Consider what happens if $a_2 = 0$. The function becomes simply $a_0 + a_1\, x$, the straight-line function. 

- When $0 < a_1$ the line slopes upward.
- When $a_1 < 0$ the line slopes downward.

To produce the steep-then-shallow or shallow-then-steep shapes, you also need to restrict the function domain to be on one side or another of the turning point of the parabola as shown in @fig-four-shapes.



```{r echo=FALSE, warning=FALSE}
#| label: fig-four-shapes
#| fig-cap: "Four of the ***eight simple shapes*** correspond to the sides of the parabola. The labels refer to the graphs in  @fig-eight-simple-shapes."
f1 <- makeFun(a + b*x + c*x^2 ~ x, a=-2, b=1, c=1)
f2 <- makeFun(a + b*x + c*x^2 ~ x, a=-2, b=1, c=-1)
P1 <- graph_with_boxes(f1, domain=bounds(x=-1.1:0.1), 
                       my_letters = c("C", "D"), 
                       intervals = tibble(x = c(-1, -.45), xend=c(-.55, 0)))
P2 <- graph_with_boxes(f2, domain=bounds(x=-.3:1.4), 
                       my_letters = c("E", "F"),
                       intervals = tibble(x = c(-.2, .55), xend=c(.45, 1.25))) %>%
  gf_lims(y=c(-2.6, -1.4))
gridExtra::grid.arrange(P1, P2, nrow=2)
```




## Polynomials with two inputs {#sec-low-order-two}

For functions with two inputs, the low-order polynomial approximation looks like this:

$$g(x, y) \equiv a_0 + a_x x + a_y y + a_{xy} x y + a_{yy} y^2 + a_{xx} x^2$$

It helps to have different names for the various terms. It is not too bad to say something like, "the $a_{xy}$ term." (Pronunciation: "a sub x y" or  "a x y") But the proper names are: ***linear terms***, ***quadratic terms***, and ***interaction term***. And a shout out to $a_0$, the ***constant term***. 

$$g(x, y) \equiv a_0 + \underbrace{a_x x + a_y y}_\text{linear terms} \ \ \ + 
\underbrace{a_{xy} x y}_\text{interaction term} +\ \ \  \underbrace{a_{yy} y^2 + a_{xx} x^2}_\text{quadratic terms}$$


The interaction term arises in models of phenomena such as the spread of epidemics, the population dynamics of predator and prey animals, and the rates of chemical reactions. In each of these situations, one thing is interacting with another: a predator killing a prey animal, an infective individual meeting a person susceptible to the disease, one chemical compound reacting with another. 

Under certain circumstances, modelers include one or both ***quadratic terms***, as in
$$h_3(x, y) \equiv c_0 + c_x\, x + c_y\, y + c_{xy}\,x\, y + \underbrace{c_{yy}\, y^2}_\text{quadratic in y}$$
The skilled modeler can often deduce which terms to include from basic facts about the system being modeled. We will need some additional calculus concepts before we can explain this straightforwardly.




```{r echo=FALSE, warning=FALSE}
make_gxy <- function(seed=1) {
  set.seed(seed)
  f <- makeFun(a0 + ax*x + ay*y + axy*x*y + axx*x^2 + ayy*y^2 ~ x + y,
               a0 = runif(1, -1, 1), 
               ax = runif(1, -1, 1), ay = runif(1, -1, 1), 
               axy = runif(1, -1, 1), 
               ayy = runif(1, -1, 1), axx = runif(1, -1, 1)
  )
}
show_poly2 <- function(seed=1, 
                       domain=bounds(x= -2 : 2, y= -2 : 2)) {
  f <- make_gxy(seed)
  list(P1 = contour_plot(f(x, y) ~ x + y, domain=domain),
  P2 = interactive_plot(f(x, y) ~ x + y, domain=domain))
}
Bowl <- makeFun(x + y - 1*x*y + x^2 + 2*y^2 ~ x & y)
Pbowl <- contour_plot(Bowl(x, y) ~ x & y, bounds(x=-3:3, y=-3:3)) %>%
  gf_refine(coord_fixed())

Phill <- contour_plot(40-Bowl(x, y) ~ x & y, bounds(x=-3:3, y=-3:3)) %>%
  gf_refine(coord_fixed()) 
Saddle <- show_poly2(104)
```

```{r echo=FALSE}
# function to strip the axes off a plot.
strip_axes <- function(P) {
  P %>%
    gf_theme(panel.grid = element_blank(), 
           axis.text.x = element_blank(),
           axis.title.x = element_blank(),
           axis.text.y = element_blank(),
           axis.title.y = element_blank())
}
```

A second-order polynomial with two inputs can take on any one of three shapes: a bowl, a hilltop, or a saddle.

```{r echo=FALSE, warning=FALSE}
#| label: fig-xy-poly-graph
#| fig-cap: "The three forms for a second-order polynomial with two inputs."
#| out-width: "150%"
#| column: page-inset-right

Pa <- Pbowl |> gf_labs(subtitle="Bowl") |> strip_axes()
  
Pb <- Phill |> gf_labs(subtitle="Hill") |> strip_axes()

Pc <- Saddle$P1 %>%
  gf_refine(coord_fixed()) |> gf_labs(subtitle="Saddle") |> strip_axes()
gridExtra::grid.arrange(Pa, Pb, Pc, ncol=3)
```

Other shapes for modeling can be extracted from these three basic shapes. For example, the lower-right quadrant of the Saddle has the shape of seats in an amphitheater.

## Theory out of a hat

The start of @sec-fitting-by-feature introduced a little mystery. Newton introduced his Law of Cooling in the 17th century: The rate at which an object cools depends on the difference in temperature between the object and its ambient environment. But in the 17th century, there was no precise way to measure a rate of temperature change. So how did Newton do it?

Even with primitive thermometers, one can confirm that a mug of hot water will cool and a glass of cold water will warm to room temperature and stay there. So Newton could deduce that the rate of temperature change is zero when the object's temperature is the same as the environment. Similarly, it is easy to observe with a primitive thermometer that a big difference in temperature between an object and its environment produces a rapid change in temperature, even if you cannot measure the rate precisely. So the rate of cooling is a function of the temperature difference $\Delta T$ between object and environment.

What kind of function?

Low-order polynomials to the rescue! The simplest model is that the rate of cooling will be $a_0 + a_1 \Delta T$, a first-order polynomial. But we know that the rate of cooling is zero when $\Delta T = 0$, implying that $a_0=0$. All that is  left is the first-order term $\Delta T$, which you can recognize as the proportional() function.

